// CareerWiki AI Analyzer - Vectorize Pipeline
// Version: v1.1.0 (Freeze v1.1)
//
// ============================================
// ğŸš¨ [ë¶ˆë³€ ì›ì¹™] Vectorize ì—­í•  ê²½ê³„ (ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€)
// ============================================
// 1. Vectorize scoreëŠ” ì¶”ì²œ ì ìˆ˜ì— ì§ì ‘ ì‚¬ìš© ê¸ˆì§€
//    - ìœ ì‚¬ë„ ì ìˆ˜ëŠ” í›„ë³´ í’€ í•„í„°ìš©ì¼ ë¿, ë­í‚¹ì— ì˜í–¥ ì—†ìŒ
//
// 2. ìš©ë„ ì œí•œ: ì§ˆë¬¸ ì„¤ê³„ / í›„ë³´ í’€ ìƒì„± / ì„¤ëª… ë³´ì¡°
//    - Interview Mode: QSP ìƒì„± (ì§ì—…ëª… ë¹„ë…¸ì¶œ)
//    - Recommendation Mode: í›„ë³´ í’€ TopK=800
//
// 3. ë­í‚¹ ê²°ì •: LLM Judgeë§Œ ë‹´ë‹¹
//    - ìµœì¢… ì¶”ì²œ ìˆœìœ„ëŠ” Fit/Desire/Feasibility ì ìˆ˜ë¡œ ê²°ì •
//    - "500ê°œë§Œ ë³´ë©´ ì¶©ë¶„"ì´ë¼ëŠ” ìœ í˜¹ì— ë„˜ì–´ê°€ì§€ ë§ ê²ƒ
// ============================================
//
// âš ï¸ ì„¤ê³„ ì›ì¹™
// ============================================
// 1. í›„ë³´êµ° í™•ì¥: 80ê°œ â†’ 500-1000ê°œ
// 2. íƒœê¹… ëŒ€ì‹  ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ì»¤ë²„ë¦¬ì§€ í™•ë³´
// 3. Evidence Generatorì™€ í†µí•©
// ============================================

import type { D1Database, VectorizeIndex, Ai } from '@cloudflare/workers-types'
import { preFilterByHardConstraints, type PreFilterResult } from './tag-filter'
import type { UserConstraints } from './types'
import type { MiniModuleResult } from './mini-module-questions'
import { TOKEN_TO_ENGLISH } from './mini-module-questions'
import { generateOpenAIEmbedding, OPENAI_EMBEDDING_DIMENSIONS } from './openai-client'
import { calculatePersonalizedBaseScores } from './personalized-scoring'
import { calculateMajorPersonalizedBaseScores } from './personalized-scoring-major'
import type { ScoredMajor, MajorAttributes } from './types'
import { 
  JOB_PROFILE_COMPACT_VERSION, 
  getFullEmbeddingVersion 
} from '../../constants/embedding-versions'

// ============================================
// Vectorize ID ìœ í‹¸ë¦¬í‹° (64ë°”ì´íŠ¸ ì œí•œ ëŒ€ì‘)
// ============================================
// Vectorize IDëŠ” UTF-8 64ë°”ì´íŠ¸ ì´ë‚´ì—¬ì•¼ í•¨
// í•œê¸€ major ID(ì˜ˆ: "major:ì¶•ì‚°ê³„ì—´ì¶•ì‚°ì „ê³µ-ë‚™ë†í•œìš°ì „ê³µ-ì–‘ëˆì–‘ê³„ì „ê³µ")ê°€ ì´ˆê³¼í•  ìˆ˜ ìˆìŒ
// prefix:ë¥¼ ìœ ì§€í•˜ë©´ì„œ IDë¥¼ ì˜ë¼ 64ë°”ì´íŠ¸ì— ë§ì¶¤
// ê²€ìƒ‰ ì‹œ metadata.original_idë¡œ ì›ë³¸ DB ID ë³µêµ¬
function toVectorizeId(prefix: string, id: string | number): string {
  const full = `${prefix}:${id}`
  const encoder = new TextEncoder()
  if (encoder.encode(full).length <= 64) return full
  // prefix: ë¶€ë¶„ì€ ìœ ì§€í•˜ë©´ì„œ idë¥¼ ë’¤ì—ì„œë¶€í„° ìë¦„
  const prefixPart = `${prefix}:`
  let truncated = String(id)
  while (encoder.encode(prefixPart + truncated).length > 64) {
    truncated = truncated.slice(0, -1)
  }
  return prefixPart + truncated
}

// ============================================
// íƒ€ì… ì •ì˜
// ============================================

export interface VectorizeJobData {
  job_id: string
  job_name: string
  description: string
  category?: string
  tags?: string[]
}

export interface VectorSearchResult {
  job_id: string
  job_name: string
  score: number
  metadata?: Record<string, any>
}

export interface CandidateExpansionResult {
  candidates: VectorSearchResult[]
  total_searched: number
  search_duration_ms: number
  fallback_used: boolean
}

// ============================================
// ì„ë² ë”© ëª¨ë¸ ì„¤ì • (OpenAI text-embedding-3-small)
// ============================================
// ê¸°ì¡´: '@cf/baai/bge-base-en-v1.5' (768ì°¨ì›, ì˜ì–´ ê¸°ë°˜)
// ë³€ê²½: OpenAI 'text-embedding-3-small' (1536ì°¨ì›, ë‹¤êµ­ì–´ ì§€ì›)
const VECTOR_DIMENSIONS = OPENAI_EMBEDDING_DIMENSIONS  // 1536

// ============================================
// ë¯¸ë‹ˆëª¨ë“ˆ ê¸°ë°˜ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (ì˜ì–´ í‚¤ì›Œë“œ ë§¤í•‘)
// ============================================
export function buildSearchQueryFromMiniModule(
  miniModule: MiniModuleResult
): string {
  const parts: string[] = []
  
  // í¥ë¯¸ í† í° â†’ ì˜ì–´ í‚¤ì›Œë“œ
  if (miniModule.interest_top.length > 0) {
    const interestKeywords = miniModule.interest_top
      .map(token => TOKEN_TO_ENGLISH[token] || token)
      .join(' ')
    parts.push(`interest: ${interestKeywords}`)
  }
  
  // ê°€ì¹˜ í† í° â†’ ì˜ì–´ í‚¤ì›Œë“œ
  if (miniModule.value_top.length > 0) {
    const valueKeywords = miniModule.value_top
      .map(token => TOKEN_TO_ENGLISH[token] || token)
      .join(' ')
    parts.push(`value: ${valueKeywords}`)
  }
  
  // ê°•ì  í† í° â†’ ì˜ì–´ í‚¤ì›Œë“œ
  if (miniModule.strength_top.length > 0) {
    const strengthKeywords = miniModule.strength_top
      .map(token => TOKEN_TO_ENGLISH[token] || token)
      .join(' ')
    parts.push(`strength: ${strengthKeywords}`)
  }
  
  // ì œì•½ í”Œë˜ê·¸ â†’ ì˜ì–´ í‚¤ì›Œë“œ (í”¼í•´ì•¼ í•  ê²ƒ)
  if (miniModule.constraint_flags.length > 0) {
    const constraintKeywords = miniModule.constraint_flags
      .map(token => TOKEN_TO_ENGLISH[token] || token)
      .join(' ')
    parts.push(`avoid: ${constraintKeywords}`)
  }
  
  // ì˜ì–´ ì¿¼ë¦¬ ìƒì„± (BGE ëª¨ë¸ì´ ì˜ì–´ ê¸°ë°˜)
  if (parts.length === 0) {
    return 'career recommendation job matching'
  }

  return parts.join(' ').substring(0, 500)
}

/**
 * MiniModuleResult â†’ SearchProfile ë³€í™˜
 * E2E í…ŒìŠ¤íŠ¸ ë° /v3/recommendì—ì„œ ë²¡í„° ê²€ìƒ‰ ì‹œ ì‚¬ìš©
 */
export function buildSearchProfileFromMiniModule(
  miniModule: MiniModuleResult
): SearchProfile {
  // í† í°ì„ í•œêµ­ì–´ë¡œ ë³€í™˜í•˜ëŠ” ë§µ (ë²¡í„° ê²€ìƒ‰ìš©)
  const interestKorean: Record<string, string> = {
    data_numbers: 'ë°ì´í„° ë¶„ì„ í†µê³„',
    problem_solving: 'ë¬¸ì œ í•´ê²° ë…¼ë¦¬',
    research: 'ì—°êµ¬ ì¡°ì‚¬ ë¶„ì„',
    tech: 'ê¸°ìˆ  ê°œë°œ IT',
    creative: 'ì°½ì‘ ë””ìì¸ ì˜ˆìˆ ',
    helping: 'ë„ì›€ ìƒë‹´ ë³µì§€ ì„œë¹„ìŠ¤ ëŒë´„',
    helping_teaching: 'ë„ì›€ ê°€ë¥´ì¹¨ ìƒë‹´ êµìœ¡ ë³µì§€',
    organizing: 'ì¡°ì§ ê´€ë¦¬ í–‰ì • ì‚¬ë¬´ ê²½ì˜ì§€ì›',
    routine: 'í–‰ì • ì‚¬ë¬´ ê³µë¬´ì› ì •í˜•í™”ëœ ì—…ë¬´',
    design: 'ë””ìì¸ ì‹œê° ê·¸ë˜í”½',
    art: 'ì˜ˆìˆ  ì°½ì‘ ë¬¸í™”',
  }

  const valueKorean: Record<string, string> = {
    autonomy: 'ììœ¨ì„± ììœ  ë…ë¦½',
    growth: 'ì„±ì¥ ë°œì „ ê²½ë ¥ê°œë°œ',
    expertise: 'ì „ë¬¸ì„± ìˆ™ë ¨ ì „ë¬¸ê°€',
    stability: 'ì•ˆì • ì •ê·œì§ ê³µë¬´ì› ê³µê³µê¸°ê´€',
    wlb: 'ì›Œë¼ë°¸ ê· í˜• ì •ì‹œí‡´ê·¼',
    income: 'ì†Œë“ ì—°ë´‰ ë³´ìˆ˜',
    creativity: 'ì°½ì˜ì„± ì°½ì‘',
    recognition: 'ì¸ì • ì„±ì·¨',
    meaning: 'ì˜ë¯¸ ë³´ëŒ ì‚¬íšŒê³µí—Œ',
  }

  const strengthKorean: Record<string, string> = {
    analytical: 'ë¶„ì„ë ¥ ë…¼ë¦¬ ë°ì´í„°',
    fast_learning: 'ë¹ ë¥¸ í•™ìŠµ ìŠµë“',
    persistence: 'ëˆê¸° ì¸ë‚´ ê¾¸ì¤€í•¨',
    communication: 'ì†Œí†µ ëŒ€ì¸ê´€ê³„ ìƒë‹´ ê³ ê°ì‘ëŒ€',
    creative: 'ì°½ì˜ì„± ë…ì°½',
    structured_execution: 'ì²´ê³„ì  ì‹¤í–‰ ì—…ë¬´ì²˜ë¦¬ ì‚¬ë¬´',
    leadership: 'ë¦¬ë”ì‹­ í†µì†” ê´€ë¦¬',
    empathy: 'ê³µê° ì´í•´ ëŒë´„',
    adaptability: 'ì ì‘ë ¥ ìœ ì—°',
    detail_oriented: 'ê¼¼ê¼¼í•¨ ì •ë°€ ê²€ìˆ˜',
  }

  // desiredThemes: í¥ë¯¸ + ê°€ì¹˜
  const desiredThemes: string[] = [
    ...miniModule.interest_top.map(t => interestKorean[t] || t),
    ...miniModule.value_top.map(t => valueKorean[t] || t),
  ]

  // strengthsHypothesis: ê°•ì 
  const strengthsHypothesis: string[] = miniModule.strength_top.map(t => strengthKorean[t] || t)

  // hardConstraints: ì œì•½ í”Œë˜ê·¸
  const hardConstraints: string[] = miniModule.constraint_flags || []

  // keywords: ê²€ìƒ‰ í‚¤ì›Œë“œ (ì˜ì–´ + í•œêµ­ì–´ í˜¼í•©, ê°€ì¹˜ í•œêµ­ì–´ í¬í•¨)
  const keywords: string[] = [
    ...miniModule.interest_top.map(t => TOKEN_TO_ENGLISH[t] || t),
    ...miniModule.strength_top.map(t => TOKEN_TO_ENGLISH[t] || t),
    ...miniModule.interest_top.map(t => interestKorean[t] || t),
    ...miniModule.value_top.map(t => valueKorean[t] || t),
  ]

  // dislikedThemes: ì—ë„ˆì§€ ì†Œëª¨ í”Œë˜ê·¸ì—ì„œ ì¶”ì¶œ
  const energyDrainKorean: Record<string, string> = {
    people_drain: 'ì‚¬ëŒ ìƒí˜¸ì‘ìš© ë§ì€ ì¼',
    routine_drain: 'ë°˜ë³µ ë‹¨ìˆœ ì‘ì—…',
    time_pressure_drain: 'ì‹œê°„ ì••ë°• ë§ˆê°',
    bureaucracy_drain: 'ê´€ë£Œì  ì ˆì°¨',
    conflict_drain: 'ê°ˆë“± ì¶©ëŒ',
    multitask_drain: 'ë©€í‹°íƒœìŠ¤í‚¹',
    uncertainty_drain: 'ë¶ˆí™•ì‹¤ì„±',
  }
  const dislikedThemes: string[] = (miniModule.energy_drain_flags || []).map(t => energyDrainKorean[t] || t)

  return {
    desiredThemes,
    dislikedThemes,
    strengthsHypothesis,
    environmentPreferences: miniModule.workstyle_top || [],
    hardConstraints,
    riskSignals: [],
    keywords: [...new Set(keywords)],  // ì¤‘ë³µ ì œê±°
  }
}

// ============================================
// P2: Can/Like ê°€ì¤‘ ê²€ìƒ‰ ì¿¼ë¦¬ ì‹œìŠ¤í…œ
// ê²€ì¦ëœ Canì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬
// ============================================
export interface WeightedSearchQuery {
  primary_keywords: string[]      // ê°€ì¤‘ì¹˜ ë†’ì€ í‚¤ì›Œë“œ (ê²€ì¦ëœ Can + Like)
  secondary_keywords: string[]    // ì¼ë°˜ í‚¤ì›Œë“œ
  exclude_keywords: string[]      // ì œì™¸ í‚¤ì›Œë“œ (Risk)
  boost_weights: Map<string, number>
}

/**
 * Can ê²€ì¦ ê²°ê³¼ë¥¼ ë°˜ì˜í•œ ê°€ì¤‘ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
 * - ê²€ì¦ëœ ê°•ì ì€ primary_keywordsë¡œ ìš°ì„  ì²˜ë¦¬
 * - ë¯¸ê²€ì¦ ê°•ì ì€ secondary_keywordsë¡œ ì²˜ë¦¬
 */
export function buildWeightedSearchQuery(
  miniModule: MiniModuleResult,
  canValidationResults?: Record<string, { canBoost: number }>
): WeightedSearchQuery {
  const primary: string[] = []
  const secondary: string[] = []
  const exclude: string[] = []
  const weights = new Map<string, number>()

  // 1. Like í‚¤ì›Œë“œ (interest + value)
  for (const token of miniModule.interest_top || []) {
    const keyword = TOKEN_TO_ENGLISH[token]
    if (keyword) {
      secondary.push(keyword)
      weights.set(keyword, 1.0)
    }
  }

  for (const token of miniModule.value_top || []) {
    const keyword = TOKEN_TO_ENGLISH[token]
    if (keyword) {
      secondary.push(keyword)
      weights.set(keyword, 0.8)  // ê°€ì¹˜ëŠ” ê´€ì‹¬ë³´ë‹¤ ì•½ê°„ ë‚®ì€ ê°€ì¤‘ì¹˜
    }
  }

  // 2. Can í‚¤ì›Œë“œ (ê²€ì¦ëœ ê°•ì  ìš°ì„ )
  for (const token of miniModule.strength_top || []) {
    const keyword = TOKEN_TO_ENGLISH[token]
    if (!keyword) continue

    // Can ê²€ì¦ ê²°ê³¼ í™•ì¸
    const validationKey = `can_verified_${token}`
    const validation = canValidationResults?.[validationKey]

    if (validation && validation.canBoost >= 15) {
      // ê²€ì¦ëœ ê°•ì  â†’ primary (ë†’ì€ ê°€ì¤‘ì¹˜)
      primary.push(keyword)
      weights.set(keyword, 1.5)
    } else if (validation && validation.canBoost >= 8) {
      // ë¶€ë¶„ ê²€ì¦ â†’ secondary (ì¤‘ê°„ ê°€ì¤‘ì¹˜)
      secondary.push(keyword)
      weights.set(keyword, 1.2)
    } else {
      // ë¯¸ê²€ì¦ â†’ secondary (ê¸°ë³¸ ê°€ì¤‘ì¹˜)
      secondary.push(keyword)
      weights.set(keyword, 1.0)
    }
  }

  // 3. Risk í‚¤ì›Œë“œ (ì œì™¸ ëŒ€ìƒ)
  for (const token of miniModule.constraint_flags || []) {
    const keyword = TOKEN_TO_ENGLISH[token]
    if (keyword) {
      exclude.push(keyword)
    }
  }

  // ì—ë„ˆì§€ ì†Œëª¨ í”Œë˜ê·¸ë„ ì œì™¸ í‚¤ì›Œë“œë¡œ
  for (const token of miniModule.energy_drain_flags || []) {
    const keyword = TOKEN_TO_ENGLISH[token]
    if (keyword) {
      exclude.push(keyword)
    }
  }

  return {
    primary_keywords: primary,
    secondary_keywords: secondary,
    exclude_keywords: exclude,
    boost_weights: weights,
  }
}

/**
 * ê°€ì¤‘ ì¿¼ë¦¬ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (ê²€ìƒ‰ìš©)
 */
export function weightedQueryToString(query: WeightedSearchQuery): string {
  const parts: string[] = []

  // Primary í‚¤ì›Œë“œë¥¼ 2ë²ˆ í¬í•¨ (ê°€ì¤‘ì¹˜ íš¨ê³¼)
  if (query.primary_keywords.length > 0) {
    parts.push(`key skills: ${query.primary_keywords.join(' ')}`)
    parts.push(`strengths: ${query.primary_keywords.join(' ')}`)  // ì¤‘ë³µìœ¼ë¡œ ê°•ì¡°
  }

  // Secondary í‚¤ì›Œë“œ
  if (query.secondary_keywords.length > 0) {
    parts.push(`interests: ${query.secondary_keywords.join(' ')}`)
  }

  // Exclude í‚¤ì›Œë“œ (NOT í‘œí˜„)
  if (query.exclude_keywords.length > 0) {
    parts.push(`avoid: ${query.exclude_keywords.join(' ')}`)
  }

  if (parts.length === 0) {
    return 'career recommendation job matching'
  }

  return parts.join(' ').substring(0, 500)
}

// ============================================
// ì‚¬ìš©ì ì¿¼ë¦¬ ìƒì„± (facts â†’ ê²€ìƒ‰ ì¿¼ë¦¬)
// ============================================
export function buildSearchQuery(
  facts: Array<{ fact_key: string; value_json: string }>,
  miniModule?: MiniModuleResult
): string {
  // ë¯¸ë‹ˆëª¨ë“ˆ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
  if (miniModule && (miniModule.interest_top.length > 0 || miniModule.value_top.length > 0)) {
    return buildSearchQueryFromMiniModule(miniModule)
  }
  
  const queryParts: string[] = []
  
  for (const fact of facts) {
    try {
      const parsed = JSON.parse(fact.value_json)
      const value = parsed.value || parsed
      
      // ê´€ì‹¬ì‚¬ ì¶”ì¶œ â†’ ì˜ì–´ í‚¤ì›Œë“œë¡œ ë³€í™˜
      if (fact.fact_key.includes('interest')) {
        if (Array.isArray(value)) {
          // í•œêµ­ì–´ ê´€ì‹¬ì‚¬ë¥¼ ì˜ì–´ë¡œ ë§¤í•‘
          const interestMap: Record<string, string> = {
            'ê¸°ìˆ ': 'technology engineering development',
            'ë””ìì¸': 'design creative artistic',
            'ë¹„ì¦ˆë‹ˆìŠ¤': 'business management leadership',
            'ë°ì´í„°': 'data analysis quantitative',
            'êµìœ¡': 'education teaching training',
            'ì˜ë£Œ': 'healthcare medical health',
            'ê¸ˆìœµ': 'finance banking investment',
            'ë§ˆì¼€íŒ…': 'marketing sales communication',
          }
          const mapped = value.map((v: string) => interestMap[v] || v).join(' ')
          queryParts.push(`interest: ${mapped}`)
        } else {
          queryParts.push(`interest: ${value}`)
        }
      }
      
      // ìš°ì„ ìˆœìœ„ ì¶”ì¶œ â†’ ì˜ì–´ë¡œ ë³€í™˜
      if (fact.fact_key.includes('priority')) {
        const priorityMapEn: Record<string, string> = {
          growth: 'career growth learning development',
          income: 'high salary compensation financial',
          wlb: 'work-life balance flexible hours',
          stability: 'job security stable employment',
          meaning: 'meaningful work purpose impact',
        }
        queryParts.push(`value: ${priorityMapEn[value] || value}`)
      }
      
      // ì‘ì—… ìŠ¤íƒ€ì¼ â†’ ì˜ì–´ë¡œ ë³€í™˜
      if (fact.fact_key.includes('workstyle')) {
        if (value === 'solo') {
          queryParts.push('work style: independent autonomous focused')
        } else if (value === 'team') {
          queryParts.push('work style: collaborative team cooperative')
        }
      }
      
      // Deep intake ë‚´ìš© (ì´ê±´ í•œêµ­ì–´ ê·¸ëŒ€ë¡œ - ë³´ì¡° ì—­í• )
      if (fact.fact_key.includes('deep_intake') || fact.fact_key.includes('discovery')) {
        if (typeof value === 'string' && value.length > 5) {
          queryParts.push(value.substring(0, 100))
        }
      }
      
    } catch {
      // íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
    }
  }
  
  // ê¸°ë³¸ ì¿¼ë¦¬ (ì˜ì–´)
  if (queryParts.length === 0) {
    return 'career recommendation job matching professional work'
  }
  
  return queryParts.join(' ').substring(0, 500)
}

// ============================================
// ë²¡í„° ê²€ìƒ‰ (Cloudflare Vectorize + OpenAI Embedding)
// ============================================
export async function searchCandidates(
  vectorize: VectorizeIndex,
  openaiApiKey: string,
  query: string,
  topK: number = 500
): Promise<VectorSearchResult[]> {
  // 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (OpenAI - í•œêµ­ì–´ ì§ì ‘ ì²˜ë¦¬)
  const { embeddings } = await generateOpenAIEmbedding(openaiApiKey, query)
  const queryEmbedding = embeddings[0]
  
  // 2. ë²¡í„° ê²€ìƒ‰
  // Cloudflare Vectorize ì ˆëŒ€ ìƒí•œ: topK = 100
  // metadataëŠ” í›„ì† D1 ì¡°íšŒì—ì„œ ê°€ì ¸ì˜¤ë¯€ë¡œ 'none'ìœ¼ë¡œ ì„¤ì •
  const clampedTopK = Math.min(topK, 100)
  const searchResult = await vectorize.query(queryEmbedding, {
    topK: clampedTopK,
    returnValues: false,
    returnMetadata: 'none',
  })

  // 3. ê²°ê³¼ ë³€í™˜ (metadata ì—†ì´ ID + scoreë§Œ ë°˜í™˜, job_nameì€ D1ì—ì„œ ì¡°íšŒ)
  // major:/howto: prefix ID ì œì™¸ (RAG ê²€ìƒ‰ìš© ì—”íŠ¸ë¦¬ê°€ AI Analyzerì— í˜¼ì…ë˜ì§€ ì•Šë„ë¡)
  return searchResult.matches
    .filter(match => !match.id.includes(':'))
    .map(match => ({
      job_id: match.id,
      job_name: match.id,
      score: match.score,
      metadata: {} as Record<string, any>,
    }))
}

// ============================================
// Multi-Query ë²¡í„° ê²€ìƒ‰ (topK=100 ì œí•œ ìš°íšŒ)
// ì—¬ëŸ¬ ì¿¼ë¦¬ë¥¼ ë°°ì¹˜ ì„ë² ë”© + ë³‘ë ¬ ê²€ìƒ‰í•˜ì—¬ í›„ë³´ í’€ í™•ì¥
// ============================================
export async function searchCandidatesMultiQuery(
  vectorize: VectorizeIndex,
  openaiApiKey: string,
  queries: string[],
  topK: number = 100
): Promise<VectorSearchResult[]> {
  // 1. ë°°ì¹˜ ì„ë² ë”© (í•œ ë²ˆì˜ OpenAI í˜¸ì¶œë¡œ ëª¨ë“  ì¿¼ë¦¬ ì„ë² ë”©)
  const { embeddings } = await generateOpenAIEmbedding(openaiApiKey, queries)

  // 2. ë³‘ë ¬ Vectorize ê²€ìƒ‰ (ê° topK=100)
  const clampedTopK = Math.min(topK, 100)
  const searchPromises = embeddings.map(emb =>
    vectorize.query(emb, { topK: clampedTopK, returnValues: false, returnMetadata: 'none' })
  )
  const searchResults = await Promise.all(searchPromises)

  // 3. ì¤‘ë³µ ì œê±° (ê°™ì€ job_id â†’ ìµœê³  score ìœ ì§€ + íˆíŠ¸ì¹´ìš´íŠ¸ ì¶”ì )
  // v3.9.5: ì—¬ëŸ¬ ì¿¼ë¦¬ì— ë“±ì¥í•˜ëŠ” ì£¼ë¥˜ ì§ì—…ì— íˆíŠ¸ì¹´ìš´íŠ¸ ë³´ë„ˆìŠ¤
  // major:/howto: prefix ID ì œì™¸ (RAG ê²€ìƒ‰ìš© ì—”íŠ¸ë¦¬ê°€ AI Analyzerì— í˜¼ì…ë˜ì§€ ì•Šë„ë¡)
  const bestScoreMap = new Map<string, number>()
  const hitCountMap = new Map<string, number>()
  let totalMatches = 0
  for (const result of searchResults) {
    for (const match of result.matches) {
      if (match.id.includes(':')) continue  // major:/howto: prefix ì œì™¸
      totalMatches++
      const existing = bestScoreMap.get(match.id)
      if (existing === undefined || match.score > existing) {
        bestScoreMap.set(match.id, match.score)
      }
      hitCountMap.set(match.id, (hitCountMap.get(match.id) || 0) + 1)
    }
  }


  // 4. ê²°ê³¼ ë³€í™˜ (score ë‚´ë¦¼ì°¨ìˆœ)
  // íˆíŠ¸ì¹´ìš´íŠ¸ ë³´ë„ˆìŠ¤: 3+ê°œ ì¿¼ë¦¬ì— ë“±ì¥ â†’ ì ìˆ˜ ë³´ì • (ì£¼ë¥˜ ì§ì—… ìš°ì„ )
  return Array.from(bestScoreMap.entries())
    .map(([id, score]) => {
      const hits = hitCountMap.get(id) || 1
      // 3+ê°œ ì¿¼ë¦¬ íˆíŠ¸ ì‹œ scoreì— ë³´ë„ˆìŠ¤ (ìµœëŒ€ +0.05)
      const hitBonus = hits >= 3 ? Math.min(0.05, (hits - 2) * 0.015) : 0
      return { id, score: Math.min(1.0, score + hitBonus), hits }
    })
    .sort((a, b) => b.score - a.score)
    .map(({ id, score }) => ({
      job_id: id,
      job_name: id,
      score,
      metadata: {} as Record<string, any>,
    }))
}

// ============================================
// í›„ë³´êµ° í™•ì¥ (ë©”ì¸ í•¨ìˆ˜) - ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜
// ============================================
// 2026-01-26: íƒœê¹… ì˜ì¡´ë„ ì™„ì „ ì œê±°
// - ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ë§Œ ì‚¬ìš©
// - ëª¨ë“  ì§ì—… ê²€ìƒ‰ ê°€ëŠ¥ (íƒœê¹… ì—¬ë¶€ ë¬´ê´€)
// ============================================
export async function expandCandidates(
  db: D1Database,
  vectorize: VectorizeIndex | undefined,
  openaiApiKey: string | undefined,
  facts: Array<{ fact_key: string; value_json: string }>,
  options: {
    targetSize?: number
  } = {}
): Promise<CandidateExpansionResult> {
  const { targetSize = 500 } = options
  const startTime = Date.now()
  
  // Vectorize ë˜ëŠ” OpenAI API í‚¤ê°€ ì—†ìœ¼ë©´ fallback
  if (!vectorize || !openaiApiKey) {
    const fallbackResult = await getFallbackCandidates(db, targetSize)
    return {
      candidates: fallbackResult,
      total_searched: fallbackResult.length,
      search_duration_ms: Date.now() - startTime,
      fallback_used: true,
    }
  }
  
  try {
    // 1. ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (í•œêµ­ì–´ ì§ì ‘ ì‚¬ìš© ê°€ëŠ¥)
    const query = buildSearchQuery(facts)
    
    // 2. ë²¡í„° ê²€ìƒ‰ (OpenAI Embedding ì‚¬ìš©)
    const vectorResults = await searchCandidates(vectorize, openaiApiKey, query, targetSize)
    
    
    return {
      candidates: vectorResults,
      total_searched: vectorResults.length,
      search_duration_ms: Date.now() - startTime,
      fallback_used: false,
    }
    
  } catch (error) {
    const fallbackResult = await getFallbackCandidates(db, targetSize)
    return {
      candidates: fallbackResult,
      total_searched: fallbackResult.length,
      search_duration_ms: Date.now() - startTime,
      fallback_used: true,
    }
  }
}

// ============================================
// Fallback: DBì—ì„œ ì§ì ‘ ì¡°íšŒ (íƒœê¹… ë¬´ê´€)
// ============================================
// 2026-01-26: íƒœê¹… ì˜ì¡´ë„ ì œê±°
// - ëª¨ë“  ì§ì—…ì„ ì¡°íšŒ (tagger_version ì¡°ê±´ ì œê±°)
// - ëœë¤ ìƒ˜í”Œë§ìœ¼ë¡œ ë‹¤ì–‘í•œ ì§ì—… ì œê³µ
// ============================================
async function getFallbackCandidates(
  db: D1Database,
  limit: number
): Promise<VectorSearchResult[]> {
  // job_attributes í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì¡°íšŒ (íƒœê¹… ì—¬ë¶€ ë¬´ê´€)
  const result = await db.prepare(`
    SELECT job_id, job_name
    FROM job_attributes
    ORDER BY RANDOM()
    LIMIT ?
  `).bind(limit).all<{ job_id: string; job_name: string }>()
  
  return (result.results || []).map((row, idx) => ({
    job_id: row.job_id,
    job_name: row.job_name,
    score: 0.5 - (idx * 0.0005), // ìˆœì„œì— ë”°ë¼ ë¯¸ì„¸í•˜ê²Œ ì ìˆ˜ ê°ì†Œ
    metadata: { source: 'fallback_random' },
  }))
}

// ============================================
// Job Profile Compact: Freeze v1.1 ì¸ë±ì‹± í…ìŠ¤íŠ¸ ìƒì„±
// ============================================
// ë²„ì „: JOB_PROFILE_COMPACT_V1
// ë³€ê²½ ì‹œ ë°˜ë“œì‹œ JOB_PROFILE_COMPACT_VERSION ì¦ê°€ í•„ìš”!
// ============================================
export interface JobProfileData {
  name: string
  heroIntro?: string | null
  summary?: string | null
  description?: string | null
  duties?: string | null
  skills?: string[] | null
  workEnvironment?: string | null
  certifications?: string[] | null
  category?: string | null
  // V2: Contextual Embeddingìš© ì†ì„± ë°ì´í„°
  attributes?: {
    income?: number | null
    stability?: number | null
    wlb?: number | null
    growth?: number | null
    analytical?: number | null
    creative?: number | null
    people_facing?: number | null
    solo_deep?: number | null
    teamwork?: number | null
    execution?: number | null
  } | null
  relatedMajors?: string[] | null  // ê´€ë ¨ ì „ê³µëª…
}

/**
 * buildJobProfileCompact: ì§ì—… ë°ì´í„°ë¥¼ ì¸ë±ì‹±ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
 * 
 * Fallback ê·œì¹™:
 * 1. heroIntro â†’ summary â†’ description â†’ category ìš°ì„ ìˆœìœ„
 * 2. ëª¨ë“  ì§ì—…ì´ "ì§ì—…ëª… + í•µì‹¬ 2~3ë¬¸ì¥"ì€ ë°˜ë“œì‹œ í¬í•¨
 * 3. ìµœëŒ€ ê¸¸ì´ 1000ì
 * 4. ë¹ˆ ë°ì´í„°ê°€ ë§ì•„ë„ ìµœì†Œ ì •ë³´ëŸ‰ ë³´ì¥
 */
export function buildJobProfileCompact(job: JobProfileData): string {
  // ì§ì—…ëª…ì€ í•­ìƒ í•„ìˆ˜
  const name = job.name || 'ë¯¸ìƒ'

  // V2: ë§¥ë½ í”„ë¦¬ì•°ë¸” ìƒì„± (ì¹´í…Œê³ ë¦¬ + í•µì‹¬ ì†ì„± + ê´€ë ¨ ì „ê³µ)
  const preamble = buildContextPreamble(job)

  // ì„¤ëª… í…ìŠ¤íŠ¸ fallback ìš°ì„ ìˆœìœ„ (ë¹„ë¬¸ìì—´ ë°©ì–´)
  const rawDesc = job.heroIntro || job.summary || job.description || ''
  const mainDesc = (typeof rawDesc === 'string' ? rawDesc : '').trim()

  // ì„ íƒì  í•„ë“œë“¤ (ìˆìœ¼ë©´ ì¶”ê°€)
  const parts: string[] = []

  // í”„ë¦¬ì•°ë¸”ì´ ìˆìœ¼ë©´ ë§¨ ì•ì— ì¶”ê°€
  if (preamble) {
    parts.push(preamble)
    parts.push('---')
  }

  parts.push(name)

  // ë©”ì¸ ì„¤ëª… (ìµœëŒ€ 300ì)
  if (mainDesc) {
    parts.push(mainDesc.slice(0, 300))
  }

  // í•µì‹¬ì—…ë¬´ (ìˆìœ¼ë©´)
  const dutiesStr = typeof job.duties === 'string' ? job.duties.trim() : ''
  if (dutiesStr) {
    parts.push(`í•µì‹¬ì—…ë¬´: ${dutiesStr.slice(0, 100)}`)
  }

  // í•„ìš”ì—­ëŸ‰ (ìˆìœ¼ë©´, ìµœëŒ€ 5ê°œ)
  if (Array.isArray(job.skills) && job.skills.length > 0) {
    const validSkills = job.skills.filter(s => typeof s === 'string' && s.trim())
    if (validSkills.length > 0) {
      parts.push(`í•„ìš”ì—­ëŸ‰: ${validSkills.slice(0, 5).join(', ')}`)
    }
  }

  // ê·¼ë¬´í™˜ê²½ (ìˆìœ¼ë©´)
  const envStr = typeof job.workEnvironment === 'string' ? job.workEnvironment.trim() : ''
  if (envStr) {
    parts.push(`í™˜ê²½: ${envStr.slice(0, 50)}`)
  }

  // ìê²©ì¦ (ìˆìœ¼ë©´, ìµœëŒ€ 3ê°œ)
  if (Array.isArray(job.certifications) && job.certifications.length > 0) {
    const validCerts = job.certifications.filter(c => typeof c === 'string' && c.trim())
    if (validCerts.length > 0) {
      parts.push(`ìê²©: ${validCerts.slice(0, 3).join(', ')}`)
    }
  }

  // ì¹´í…Œê³ ë¦¬ (ìˆìœ¼ë©´, í”„ë¦¬ì•°ë¸”ì— ì—†ëŠ” ê²½ìš°ë§Œ)
  const catStr = typeof job.category === 'string' ? job.category.trim() : ''
  if (!preamble && catStr) {
    parts.push(catStr)
  }

  // ìµœì†Œ ë³´ì¥: name + categoryëŠ” ë°˜ë“œì‹œ í¬í•¨
  if (parts.length < 2) {
    parts.push(catStr || 'ë¯¸ë¶„ë¥˜')
  }

  // V2: ìµœëŒ€ ê¸¸ì´ 1200ì (í”„ë¦¬ì•°ë¸” í¬í•¨)
  return parts.join(' ').substring(0, 1200)
}

/**
 * V2 ë§¥ë½ í”„ë¦¬ì•°ë¸” ìƒì„±: ì¹´í…Œê³ ë¦¬ + í•µì‹¬ ì†ì„± + ê´€ë ¨ ì „ê³µ
 * 50-150ì ì´ë‚´ë¡œ ì••ì¶•
 */
function buildContextPreamble(job: JobProfileData): string {
  const fragments: string[] = []

  // 1. ì¹´í…Œê³ ë¦¬ ì»¨í…ìŠ¤íŠ¸
  const catText = typeof job.category === 'string' ? job.category.trim() : ''
  if (catText) {
    fragments.push(`[${catText}]`)
  }

  // 2. í•µì‹¬ ì†ì„± (70+ ê°’ë§Œ í•˜ì´ë¼ì´íŠ¸)
  if (job.attributes) {
    const attrLabels: { key: string; label: string }[] = [
      { key: 'analytical', label: 'ë¶„ì„' },
      { key: 'creative', label: 'ì°½ì˜' },
      { key: 'execution', label: 'ì‹¤í–‰' },
      { key: 'people_facing', label: 'ëŒ€ì¸' },
      { key: 'solo_deep', label: 'ë…ë¦½' },
      { key: 'teamwork', label: 'í˜‘ì—…' },
      { key: 'income', label: 'ê³ ì†Œë“' },
      { key: 'stability', label: 'ì•ˆì •' },
      { key: 'growth', label: 'ì„±ì¥' },
      { key: 'wlb', label: 'WLB' },
    ]
    const highlights: string[] = []
    for (const { key, label } of attrLabels) {
      const val = (job.attributes as any)[key] as number | null | undefined
      if (val !== null && val !== undefined && val >= 70) {
        highlights.push(label)
      }
    }
    if (highlights.length > 0) {
      fragments.push(`íŠ¹ì„±: ${highlights.slice(0, 4).join(', ')}`)
    }
  }

  // 3. ê´€ë ¨ ì „ê³µ
  if (job.relatedMajors && job.relatedMajors.length > 0) {
    fragments.push(`ê´€ë ¨ì „ê³µ: ${job.relatedMajors.slice(0, 3).join(', ')}`)
  }

  return fragments.join(' ')
}

/**
 * parseJobProfileFromMergedJson: merged_profile_jsonì—ì„œ JobProfileData ì¶”ì¶œ
 */
export function parseJobProfileFromMergedJson(
  jobId: string,
  jobName: string,
  mergedProfileJson: string | null,
  category?: string | null
): JobProfileData {
  let heroIntro: string | undefined
  let summary: string | undefined
  let description: string | undefined
  let duties: string | undefined
  let skills: string[] | undefined
  let workEnvironment: string | undefined
  let certifications: string[] | undefined

  if (mergedProfileJson) {
    try {
      const profile = JSON.parse(mergedProfileJson)
      
      // ë‹¤ì–‘í•œ í•„ë“œëª… ì§€ì› (ë°ì´í„° ì†ŒìŠ¤ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
      heroIntro = profile.heroIntro || profile.hero_intro || profile.intro
      summary = profile.summary || profile.brief
      description = profile.description || profile.overview || profile.what || profile.ì—…ë¬´ë‚´ìš©
      duties = profile.duties || profile.responsibilities || profile.tasks || 
               (profile.what && typeof profile.what === 'string' ? profile.what : undefined)
      
      // skills ë°°ì—´ ì²˜ë¦¬
      if (profile.skills) {
        skills = Array.isArray(profile.skills) ? profile.skills : [profile.skills]
      } else if (profile.required_skills) {
        skills = Array.isArray(profile.required_skills) ? profile.required_skills : [profile.required_skills]
      }
      
      workEnvironment = profile.workEnvironment || profile.work_environment || profile.environment
      
      // certifications ë°°ì—´ ì²˜ë¦¬
      if (profile.certifications) {
        certifications = Array.isArray(profile.certifications) ? profile.certifications : [profile.certifications]
      } else if (profile.licenses) {
        certifications = Array.isArray(profile.licenses) ? profile.licenses : [profile.licenses]
      }
      
    } catch (e) {
    }
  }

  return {
    name: jobName,
    heroIntro,
    summary,
    description,
    duties,
    skills,
    workEnvironment,
    certifications,
    category,
  }
}

// ============================================
// ì§ì—… ë°ì´í„° ì¸ë±ì‹± (ë°°ì¹˜ ì²˜ë¦¬ìš© - OpenAI Embedding)
// ============================================
// Version: JOB_PROFILE_COMPACT_V1
// ============================================
export async function indexJobsToVectorize(
  db: D1Database,
  vectorize: VectorizeIndex,
  openaiApiKey: string,
  batchSize: number = 50  // OpenAI API rate limit ê³ ë ¤í•˜ì—¬ ì¤„ì„
): Promise<{ indexed: number; errors: number; version: string }> {
  let indexed = 0
  let errors = 0
  let offset = 0
  const version = getFullEmbeddingVersion()
  
  
  while (true) {
    // jobs + job_attributes LEFT JOIN ì¡°íšŒ (V2: ë§¥ë½ í”„ë¦¬ì•°ë¸”ìš©)
    const jobs = await db.prepare(`
      SELECT
        j.id as job_id,
        j.name as job_name,
        j.merged_profile_json,
        ja.income, ja.stability, ja.wlb, ja.growth,
        ja.analytical, ja.creative, ja.people_facing, ja.solo_deep,
        ja.teamwork, ja.execution
      FROM jobs j
      LEFT JOIN job_attributes ja ON j.id = ja.job_id
      WHERE j.is_active = 1
      LIMIT ? OFFSET ?
    `).bind(batchSize, offset).all<{
      job_id: string
      job_name: string
      merged_profile_json: string | null
      income: number | null
      stability: number | null
      wlb: number | null
      growth: number | null
      analytical: number | null
      creative: number | null
      people_facing: number | null
      solo_deep: number | null
      teamwork: number | null
      execution: number | null
    }>()

    if (!jobs.results || jobs.results.length === 0) break

    // buildJobProfileCompactë¡œ ì¸ë±ì‹± í…ìŠ¤íŠ¸ ìƒì„± (V2: ì†ì„± ë°ì´í„° í¬í•¨)
    const textsForEmbedding = jobs.results.map(job => {
      // categoryëŠ” merged_profile_jsonì—ì„œ ì¶”ì¶œ
      let category: string | null = null
      if (job.merged_profile_json) {
        try {
          const p = JSON.parse(job.merged_profile_json)
          category = p.category || p.heroCategory || p.ë¶„ë¥˜ || null
        } catch {}
      }
      const profileData = parseJobProfileFromMergedJson(
        job.job_id,
        job.job_name,
        job.merged_profile_json,
        category
      )
      // V2: ì†ì„± ë°ì´í„° + ê´€ë ¨ ì „ê³µ ì¶”ê°€
      profileData.attributes = {
        income: job.income,
        stability: job.stability,
        wlb: job.wlb,
        growth: job.growth,
        analytical: job.analytical,
        creative: job.creative,
        people_facing: job.people_facing,
        solo_deep: job.solo_deep,
        teamwork: job.teamwork,
        execution: job.execution,
      }
      // ê´€ë ¨ ì „ê³µì€ merged_profile_jsonì—ì„œ ì¶”ì¶œ
      if (job.merged_profile_json) {
        try {
          const profile = JSON.parse(job.merged_profile_json)
          const majors = profile.relatedMajors || profile.related_majors || profile.ê´€ë ¨í•™ê³¼ || []
          if (Array.isArray(majors)) {
            profileData.relatedMajors = majors
              .slice(0, 3)
              .map((m: any) => typeof m === 'string' ? m : m.name || '')
              .filter(Boolean)
          }
        } catch {}
      }
      return buildJobProfileCompact(profileData)
    })

    try {
      // ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„±
      const { embeddings } = await generateOpenAIEmbedding(openaiApiKey, textsForEmbedding)

      // Vectorizeì— ë°°ì¹˜ ì €ì¥ (í™•ì¥ëœ metadata í¬í•¨)
      const vectors = jobs.results.map((job, idx) => {
        // merged_profile_jsonì—ì„œ ì¶”ê°€ metadata ì¶”ì¶œ
        let category = ''
        let kscoMajor: string | undefined
        let kscoMid: string | undefined
        let educationLevel: string | undefined

        if (job.merged_profile_json) {
          try {
            const profile = JSON.parse(job.merged_profile_json)
            category = profile.category || profile.heroCategory || profile.ë¶„ë¥˜ || ''
            kscoMajor = profile.ksco_major || profile.kscoMajor
            kscoMid = profile.ksco_mid || profile.kscoMid
            educationLevel = profile.education_level || profile.educationLevel || profile.í•™ë ¥
          } catch {}
        }

        return {
          id: job.job_id,
          values: embeddings[idx],
          metadata: {
            job_name: job.job_name,
            category,
            // QSP í’ˆì§ˆ ê°•í™”ìš© metadata
            ksco_major: kscoMajor || '',
            ksco_mid: kscoMid || '',
            education_level: educationLevel || '',
            // ë²„ì „ ì¶”ì 
            embedding_version: JOB_PROFILE_COMPACT_VERSION,
          },
        }
      })
      
      await vectorize.upsert(vectors)
      indexed += jobs.results.length
      
    } catch (error) {
      errors += jobs.results.length
    }
    
    offset += batchSize
    
    // OpenAI rate limit ë°©ì§€ (1ì´ˆ ëŒ€ê¸°)
    await new Promise(resolve => setTimeout(resolve, 1000))
  }
  
  
  return { indexed, errors, version }
}

// ============================================
// ì „ê³µ ë°ì´í„° ì¸ë±ì‹± (ë°°ì¹˜ ì²˜ë¦¬ìš© - OpenAI Embedding)
// ============================================
// Vectorize ID: major:{id}
// ============================================

/**
 * buildMajorProfileCompact: ì „ê³µ ë°ì´í„°ë¥¼ ì¸ë±ì‹±ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
 * ìµœëŒ€ 1000ì
 */
export function buildMajorProfileCompact(major: {
  name: string
  merged_profile_json: string | null
}): string {
  const name = major.name || 'ë¯¸ìƒ'
  const parts: string[] = [name]

  if (major.merged_profile_json) {
    try {
      const profile = JSON.parse(major.merged_profile_json)
      const summary = profile.heroIntro || profile.summary || profile.description || profile.overview || ''
      if (summary) parts.push(summary.trim().slice(0, 300))

      // ê´€ë ¨ ì§ì—… (ê²€ìƒ‰ ì—°ê´€ì„± í–¥ìƒ)
      const relatedJobs = profile.relatedJobs || profile.related_jobs || profile.ê´€ë ¨ì§ì—… || []
      if (Array.isArray(relatedJobs) && relatedJobs.length > 0) {
        const jobNames = relatedJobs.slice(0, 8).map((j: any) => typeof j === 'string' ? j : j.name || j.job_name || '').filter(Boolean)
        if (jobNames.length > 0) parts.push(`ê´€ë ¨ì§ì—…: ${jobNames.join(', ')}`)
      }

      // í•™ê³¼ ë¶„ë¥˜
      const category = profile.category || profile.ë¶„ë¥˜ || profile.field || ''
      if (category) parts.push(category)

      // í•µì‹¬ êµê³¼ëª©
      const courses = profile.courses || profile.ì£¼ìš”êµê³¼ëª© || profile.curriculum || []
      if (Array.isArray(courses) && courses.length > 0) {
        parts.push(`êµê³¼ëª©: ${courses.slice(0, 5).join(', ')}`)
      }
    } catch {}
  }

  return parts.join(' ').substring(0, 1000)
}

export async function indexMajorsToVectorize(
  db: D1Database,
  vectorize: VectorizeIndex,
  openaiApiKey: string,
  batchSize: number = 50
): Promise<{ indexed: number; errors: number }> {
  let indexed = 0
  let errors = 0
  let offset = 0


  while (true) {
    const majors = await db.prepare(`
      SELECT id, name, merged_profile_json
      FROM majors
      WHERE is_active = 1
      LIMIT ? OFFSET ?
    `).bind(batchSize, offset).all<{
      id: string
      name: string
      merged_profile_json: string | null
    }>()

    if (!majors.results || majors.results.length === 0) break

    const textsForEmbedding = majors.results.map(m =>
      buildMajorProfileCompact({ name: m.name, merged_profile_json: m.merged_profile_json })
    )

    try {
      const { embeddings } = await generateOpenAIEmbedding(openaiApiKey, textsForEmbedding)

      const vectors = majors.results.map((m, idx) => ({
        id: toVectorizeId('major', m.id),
        values: embeddings[idx],
        metadata: {
          type: 'major',
          name: m.name,
          original_id: m.id,
        },
      }))

      await vectorize.upsert(vectors)
      indexed += majors.results.length

      // indexed_at ì—…ë°ì´íŠ¸
      const ids = majors.results.map(m => m.id)
      const placeholders = ids.map(() => '?').join(',')
      await db.prepare(`UPDATE majors SET indexed_at = datetime('now'), embedding_version = 'MPC_V1' WHERE id IN (${placeholders})`).bind(...ids).run()
    } catch (error) {
      errors += majors.results.length
    }

    offset += batchSize
    await new Promise(resolve => setTimeout(resolve, 1000))
  }

  return { indexed, errors }
}

// ============================================
// ì „ê³µ ì¦ë¶„ ì¸ë±ì‹± (ì‹ ê·œ ë˜ëŠ” ë²„ì „ ë¶ˆì¼ì¹˜ë§Œ)
// ============================================
export async function incrementalUpsertMajorsToVectorize(
  db: D1Database,
  vectorize: VectorizeIndex,
  openaiApiKey: string,
  options: { batchSize?: number; maxItems?: number } = {}
): Promise<{ upserted: number; errors: number; lastError?: string }> {
  const { batchSize = 50, maxItems = 200 } = options
  const CURRENT_VERSION = 'MPC_V1'
  let upserted = 0
  let errors = 0
  let lastError: string | undefined
  let offset = 0

  while (upserted < maxItems) {
    const majors = await db.prepare(`
      SELECT id, name, merged_profile_json
      FROM majors
      WHERE is_active = 1
        AND (indexed_at IS NULL OR embedding_version != ?)
      ORDER BY id
      LIMIT ? OFFSET ?
    `).bind(CURRENT_VERSION, batchSize, offset).all<{
      id: string
      name: string
      merged_profile_json: string | null
    }>()

    if (!majors.results || majors.results.length === 0) break

    const textsForEmbedding = majors.results.map(m =>
      buildMajorProfileCompact({ name: m.name, merged_profile_json: m.merged_profile_json })
    )

    try {
      const { embeddings } = await generateOpenAIEmbedding(openaiApiKey, textsForEmbedding)

      const vectors = majors.results.map((m, idx) => ({
        id: toVectorizeId('major', m.id),
        values: embeddings[idx],
        metadata: { type: 'major', name: m.name, original_id: m.id },
      }))

      await vectorize.upsert(vectors)

      for (const m of majors.results) {
        await db.prepare(`
          UPDATE majors SET indexed_at = datetime('now'), embedding_version = ?
          WHERE id = ?
        `).bind(CURRENT_VERSION, m.id).run()
      }

      upserted += majors.results.length
    } catch (e) {
      lastError = e instanceof Error ? e.message : String(e)
      errors += majors.results.length
    }

    offset += batchSize
    await new Promise(resolve => setTimeout(resolve, 1000))
  }

  return { upserted, errors, lastError }
}

// ============================================
// HowTo(ê°€ì´ë“œ) ë°ì´í„° ì¸ë±ì‹± (ë°°ì¹˜ ì²˜ë¦¬ìš© - OpenAI Embedding)
// ============================================
// Vectorize ID: howto:{id}
// pages í…Œì´ë¸”ì˜ page_type='guide' ëŒ€ìƒ
// ============================================

/**
 * buildHowtoProfileCompact: ê°€ì´ë“œ ë°ì´í„°ë¥¼ ì¸ë±ì‹±ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
 * ìµœëŒ€ 1000ì
 */
export function buildHowtoProfileCompact(page: {
  title: string
  summary: string | null
  content: string | null
}): string {
  const parts: string[] = [page.title || 'ë¯¸ìƒ']

  if (page.summary) {
    parts.push(page.summary.trim().slice(0, 200))
  }

  if (page.content) {
    // HTML íƒœê·¸ ì œê±° í›„ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©
    const plainText = page.content.replace(/<[^>]+>/g, ' ').replace(/\s+/g, ' ').trim()
    if (plainText.length > 0) {
      parts.push(plainText.slice(0, 500))
    }
  }

  return parts.join(' ').substring(0, 1000)
}

export async function indexHowtosToVectorize(
  db: D1Database,
  vectorize: VectorizeIndex,
  openaiApiKey: string,
  batchSize: number = 50
): Promise<{ indexed: number; errors: number }> {
  let indexed = 0
  let errors = 0
  let offset = 0


  while (true) {
    const pages = await db.prepare(`
      SELECT id, slug, title, summary, content
      FROM pages
      WHERE page_type IN ('guide', 'howto')
        AND status = 'published'
      LIMIT ? OFFSET ?
    `).bind(batchSize, offset).all<{
      id: number
      slug: string
      title: string
      summary: string | null
      content: string | null
    }>()

    if (!pages.results || pages.results.length === 0) break

    const textsForEmbedding = pages.results.map(p =>
      buildHowtoProfileCompact({ title: p.title, summary: p.summary, content: p.content })
    )

    try {
      const { embeddings } = await generateOpenAIEmbedding(openaiApiKey, textsForEmbedding)

      const vectors = pages.results.map((p, idx) => ({
        id: `howto:${p.id}`,
        values: embeddings[idx],
        metadata: {
          type: 'howto',
          title: p.title,
          slug: p.slug,
        },
      }))

      await vectorize.upsert(vectors)
      indexed += pages.results.length

      // indexed_at ì—…ë°ì´íŠ¸
      const ids = pages.results.map(p => p.id)
      const placeholders = ids.map(() => '?').join(',')
      await db.prepare(`UPDATE pages SET indexed_at = datetime('now'), embedding_version = 'HPC_V1' WHERE id IN (${placeholders})`).bind(...ids).run()
    } catch (error) {
      errors += pages.results.length
    }

    offset += batchSize
    await new Promise(resolve => setTimeout(resolve, 1000))
  }

  return { indexed, errors }
}

// ============================================
// HowTo ì¦ë¶„ ì¸ë±ì‹± (ì‹ ê·œ ë˜ëŠ” ë²„ì „ ë¶ˆì¼ì¹˜ë§Œ)
// ============================================
export async function incrementalUpsertHowtosToVectorize(
  db: D1Database,
  vectorize: VectorizeIndex,
  openaiApiKey: string,
  options: { batchSize?: number; maxItems?: number } = {}
): Promise<{ upserted: number; errors: number }> {
  const { batchSize = 50, maxItems = 200 } = options
  const CURRENT_VERSION = 'HPC_V1'
  let upserted = 0
  let errors = 0
  let offset = 0

  while (upserted < maxItems) {
    const pages = await db.prepare(`
      SELECT id, slug, title, summary, content
      FROM pages
      WHERE page_type IN ('guide', 'howto')
        AND status = 'published'
        AND (indexed_at IS NULL OR embedding_version != ?)
      ORDER BY id
      LIMIT ? OFFSET ?
    `).bind(CURRENT_VERSION, batchSize, offset).all<{
      id: number
      slug: string
      title: string
      summary: string | null
      content: string | null
    }>()

    if (!pages.results || pages.results.length === 0) break

    const textsForEmbedding = pages.results.map(p =>
      buildHowtoProfileCompact({ title: p.title, summary: p.summary, content: p.content })
    )

    try {
      const { embeddings } = await generateOpenAIEmbedding(openaiApiKey, textsForEmbedding)

      const vectors = pages.results.map((p, idx) => ({
        id: `howto:${p.id}`,
        values: embeddings[idx],
        metadata: { type: 'howto', title: p.title, slug: p.slug },
      }))

      await vectorize.upsert(vectors)

      for (const p of pages.results) {
        await db.prepare(`
          UPDATE pages SET indexed_at = datetime('now'), embedding_version = ?
          WHERE id = ?
        `).bind(CURRENT_VERSION, p.id).run()
      }

      upserted += pages.results.length
    } catch {
      errors += pages.results.length
    }

    offset += batchSize
    await new Promise(resolve => setTimeout(resolve, 1000))
  }

  return { upserted, errors }
}

// ============================================
// ë‹¨ì¼ í•­ëª© ì¸ë±ì‹± (ìƒì„±/ë°œí–‰ ì‹œ ë°±ê·¸ë¼ìš´ë“œ í˜¸ì¶œìš©)
// ============================================

export async function indexSingleJob(
  db: D1Database,
  vectorize: VectorizeIndex,
  openaiApiKey: string,
  jobId: string
): Promise<boolean> {
  try {
    const job = await db.prepare(`
      SELECT
        j.id as job_id, j.name as job_name, j.merged_profile_json,
        ja.income, ja.stability, ja.wlb, ja.growth,
        ja.analytical, ja.creative, ja.people_facing, ja.solo_deep,
        ja.teamwork, ja.execution
      FROM jobs j
      LEFT JOIN job_attributes ja ON j.id = ja.job_id
      WHERE j.id = ? AND j.is_active = 1
    `).bind(jobId).first<{
      job_id: string; job_name: string; merged_profile_json: string | null
      income: number | null; stability: number | null; wlb: number | null; growth: number | null
      analytical: number | null; creative: number | null; people_facing: number | null
      solo_deep: number | null; teamwork: number | null; execution: number | null
    }>()

    if (!job) return false

    // categoryëŠ” merged_profile_jsonì—ì„œ ì¶”ì¶œ
    let category: string | null = null
    let kscoMajor = '', kscoMid = '', educationLevel = ''
    if (job.merged_profile_json) {
      try {
        const p = JSON.parse(job.merged_profile_json)
        category = p.category || p.heroCategory || p.ë¶„ë¥˜ || null
        kscoMajor = p.ksco_major || p.kscoMajor || ''
        kscoMid = p.ksco_mid || p.kscoMid || ''
        educationLevel = p.education_level || p.educationLevel || p.í•™ë ¥ || ''
      } catch {}
    }

    const profileData = parseJobProfileFromMergedJson(job.job_id, job.job_name, job.merged_profile_json, category)
    profileData.attributes = {
      income: job.income, stability: job.stability, wlb: job.wlb, growth: job.growth,
      analytical: job.analytical, creative: job.creative, people_facing: job.people_facing,
      solo_deep: job.solo_deep, teamwork: job.teamwork, execution: job.execution,
    }
    if (job.merged_profile_json) {
      try {
        const profile = JSON.parse(job.merged_profile_json)
        const majors = profile.relatedMajors || profile.related_majors || profile.ê´€ë ¨í•™ê³¼ || []
        if (Array.isArray(majors)) {
          profileData.relatedMajors = majors.slice(0, 3).map((m: any) => typeof m === 'string' ? m : m.name || '').filter(Boolean)
        }
      } catch {}
    }

    const text = buildJobProfileCompact(profileData)
    const { embeddings } = await generateOpenAIEmbedding(openaiApiKey, text)

    await vectorize.upsert([{
      id: job.job_id,
      values: embeddings[0],
      metadata: {
        job_name: job.job_name,
        category: category || '',
        ksco_major: kscoMajor,
        ksco_mid: kscoMid,
        education_level: educationLevel,
        embedding_version: JOB_PROFILE_COMPACT_VERSION,
      },
    }])

    const version = getFullEmbeddingVersion()
    await db.prepare(`UPDATE jobs SET indexed_at = datetime('now'), embedding_version = ? WHERE id = ?`).bind(version, jobId).run()
    return true
  } catch {
    return false
  }
}

export async function indexSingleMajor(
  db: D1Database,
  vectorize: VectorizeIndex,
  openaiApiKey: string,
  majorId: string
): Promise<boolean> {
  try {
    const major = await db.prepare(`
      SELECT id, name, merged_profile_json
      FROM majors WHERE id = ? AND is_active = 1
    `).bind(majorId).first<{ id: string; name: string; merged_profile_json: string | null }>()

    if (!major) return false

    const text = buildMajorProfileCompact({ name: major.name, merged_profile_json: major.merged_profile_json })
    const { embeddings } = await generateOpenAIEmbedding(openaiApiKey, text)

    await vectorize.upsert([{
      id: toVectorizeId('major', major.id),
      values: embeddings[0],
      metadata: { type: 'major', name: major.name, original_id: major.id },
    }])

    await db.prepare(`UPDATE majors SET indexed_at = datetime('now'), embedding_version = 'MPC_V1' WHERE id = ?`).bind(majorId).run()
    return true
  } catch {
    return false
  }
}

export async function indexSingleHowto(
  db: D1Database,
  vectorize: VectorizeIndex,
  openaiApiKey: string,
  pageId: number
): Promise<boolean> {
  try {
    const page = await db.prepare(`
      SELECT id, slug, title, summary, content
      FROM pages WHERE id = ? AND page_type IN ('guide', 'howto') AND status = 'published'
    `).bind(pageId).first<{ id: number; slug: string; title: string; summary: string | null; content: string | null }>()

    if (!page) return false

    const text = buildHowtoProfileCompact({ title: page.title, summary: page.summary, content: page.content })
    const { embeddings } = await generateOpenAIEmbedding(openaiApiKey, text)

    await vectorize.upsert([{
      id: `howto:${page.id}`,
      values: embeddings[0],
      metadata: { type: 'howto', title: page.title, slug: page.slug },
    }])

    await db.prepare(`UPDATE pages SET indexed_at = datetime('now'), embedding_version = 'HPC_V1' WHERE id = ?`).bind(pageId).run()
    return true
  } catch {
    return false
  }
}

// ============================================
// ì§ì—… ì„¤ëª… ì¶”ì¶œ í—¬í¼ í•¨ìˆ˜
// ============================================
export function extractJobDescription(apiDataJson: string | null, mergedProfileJson?: string | null, jobName?: string, aiDataJson?: string | null): string | undefined {
  // 1. merged_profile_jsonì—ì„œ ë¨¼ì € ì‹œë„ (heroIntro ë“± ì‹¤ì œ í•„ë“œëª…)
  if (mergedProfileJson) {
    try {
      const data = JSON.parse(mergedProfileJson)
      const description =
        data.heroIntro ||                     // ë©”ì¸ ì„¤ëª… í•„ë“œ
        data.overviewWork?.main ||            // ì—…ë¬´ ê°œìš”
        data.description ||
        data.job_overview ||
        data.summary ||
        data.job_summary ||
        data.overview ||
        data.ì§ë¬´ê°œìš” ||
        data.ì§ì—…ê°œìš” ||
        undefined
      if (description) {
        // ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
        const text = typeof description === 'string' ? description : JSON.stringify(description)
        return text.substring(0, 200)
      }
    } catch {
      // continue to api_data_json
    }
  }

  // 2. api_data_jsonì—ì„œ ì‹œë„
  if (apiDataJson) {
    try {
      const data = JSON.parse(apiDataJson)
      // merged â†’ careernet â†’ goyong24 ìˆœìœ¼ë¡œ ì‹œë„
      const description =
        data.merged?.heroIntro ||
        data.merged?.description ||
        data.merged?.job_overview ||
        data.careernet?.summary ||
        data.careernet?.job_overview ||
        data.careernet?.description ||
        data.goyong24?.summary?.jobSum ||
        data.goyong24?.duty?.jobSum ||
        data.goyong24?.description ||
        data.goyong24?.job_overview ||
        undefined
      if (description) {
        const text = typeof description === 'string' ? description : JSON.stringify(description)
        return text.substring(0, 200)
      }
    } catch {
      // continue to ai_data_json
    }
  }

  // 3. ai_data_jsonì—ì„œ ì‹œë„
  if (aiDataJson) {
    try {
      const data = JSON.parse(aiDataJson)
      const description =
        data.description ||
        data.summary ||
        data.heroIntro ||
        data.job_description ||
        undefined
      if (description) {
        const text = typeof description === 'string' ? description : JSON.stringify(description)
        return text.substring(0, 200)
      }
    } catch {
      // continue to fallback
    }
  }

  // 4. ì„¤ëª…ì´ ì—†ìœ¼ë©´ ì§ì—…ëª… ê¸°ë°˜ ê¸°ë³¸ ì„¤ëª… ìƒì„±
  if (jobName) {
    return `${jobName}ì€(ëŠ”) ì „ë¬¸ì ì¸ ì§€ì‹ê³¼ ê¸°ìˆ ì´ í•„ìš”í•œ ì§ì—…ì…ë‹ˆë‹¤.`
  }
  return undefined
}

// ============================================
// ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ë¥¼ ScoredJob í˜•íƒœë¡œ ë³€í™˜
// ============================================
export async function vectorResultsToScoredJobs(
  db: D1Database,
  vectorResults: VectorSearchResult[],
  miniModule?: any
): Promise<Array<{
  job_id: string
  job_name: string
  slug?: string
  image_url?: string
  job_description?: string
  base_like: number
  base_can: number
  base_risk: number
  like_score?: number
  can_score?: number
  risk_penalty?: number
  final_score?: number
  attributes: Record<string, number | string>
}>> {
  if (vectorResults.length === 0) return []

  // ë²¡í„° ê²°ê³¼ì˜ job_idë¡œ job_attributes + jobs ì¡°ì¸ ì¡°íšŒ
  // D1/SQLiteëŠ” ìµœëŒ€ 999ê°œ ë³€ìˆ˜ë§Œ í—ˆìš©í•˜ë¯€ë¡œ batch ì²˜ë¦¬
  const BATCH_SIZE = 100  // D1 ì•ˆì •ì„±ì„ ìœ„í•´ 100ê°œì”©
  const jobIds = vectorResults.map(v => v.job_id)

  // v3.10.6: batch ë³‘ë ¬ ì¡°íšŒ (ìˆœì°¨ â†’ Promise.allë¡œ ìµœì í™”)
  const batches: string[][] = []
  for (let i = 0; i < jobIds.length; i += BATCH_SIZE) {
    batches.push(jobIds.slice(i, i + BATCH_SIZE))
  }

  const batchPromises = batches.map(batchIds => {
    const placeholders = batchIds.map(() => '?').join(',')
    return db.prepare(`
      SELECT
        ja.job_id, ja.job_name,
        j.slug, j.image_url, j.api_data_json, j.merged_profile_json,
        ja.wlb, ja.growth, ja.stability, ja.income,
        ja.teamwork, ja.solo_deep, ja.analytical, ja.creative, ja.execution, ja.people_facing,
        ja.work_hours, ja.shift_work, ja.travel, ja.remote_possible,
        ja.degree_required, ja.license_required
      FROM job_attributes ja
      LEFT JOIN jobs j ON ja.job_id = j.id
      WHERE ja.job_id IN (${placeholders})
    `).bind(...batchIds).all<{
    job_id: string
    job_name: string
    slug: string | null
    image_url: string | null
    api_data_json: string | null
    merged_profile_json: string | null
    wlb: number
    growth: number
    stability: number
    income: number
    teamwork: number
    solo_deep: number
    analytical: number
    creative: number
    execution: number
    people_facing: number
    work_hours: string
    shift_work: string
    travel: string
    remote_possible: string
    degree_required: string
    license_required: string
  }>()
  })

  const batchResults = await Promise.all(batchPromises)
  const allAttributeResults: any[] = []
  for (const batchResult of batchResults) {
    if (batchResult.results) {
      allAttributeResults.push(...batchResult.results)
    }
  }

  const attributesMap = new Map(
    allAttributeResults.map(row => [row.job_id, row])
  )

  // job_attributesì— ì—†ëŠ” job_idë“¤ì„ ì°¾ì•„ì„œ jobs í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì¡°íšŒ
  const missingJobIds = jobIds.filter(id => !attributesMap.has(id))
  if (missingJobIds.length > 0) {

    // v3.10.6: fallbackë„ ë³‘ë ¬ ì¡°íšŒ
    const missingBatches: string[][] = []
    for (let i = 0; i < missingJobIds.length; i += BATCH_SIZE) {
      missingBatches.push(missingJobIds.slice(i, i + BATCH_SIZE))
    }

    const fallbackPromises = missingBatches.map(batchIds => {
      const placeholders = batchIds.map(() => '?').join(',')
      return db.prepare(`
        SELECT id as job_id, name as job_name, slug, image_url, api_data_json, merged_profile_json
        FROM jobs
        WHERE id IN (${placeholders})
      `).bind(...batchIds).all<{
        job_id: string
        job_name: string
        slug: string | null
        image_url: string | null
        api_data_json: string | null
        merged_profile_json: string | null
      }>()
    })

    const fallbackResults = await Promise.all(fallbackPromises)
    for (const fallbackResult of fallbackResults) {
      if (fallbackResult.results) {
        for (const row of fallbackResult.results) {
          attributesMap.set(row.job_id, {
            ...row,
            wlb: 50, growth: 50, stability: 50, income: 50,
            teamwork: 50, solo_deep: 50, analytical: 50, creative: 50, execution: 50, people_facing: 50,
            work_hours: 'regular', shift_work: 'none', travel: 'some', remote_possible: 'partial',
            degree_required: 'none', license_required: 'none', experience_required: 'none',
            _from_jobs_fallback: true,
          })
        }
      }
    }
  }

  // ë²¡í„° ì ìˆ˜ ë§µ (scoreë¡œ ì •ë ¬ ìœ ì§€)
  const vectorScoreMap = new Map(
    vectorResults.map(vr => [vr.job_id, vr.score])
  )
  
  // ë²¡í„° ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ScoredJob ìƒì„±
  return vectorResults.map(vr => {
    const attrs = attributesMap.get(vr.job_id) as any
    const vectorScore = vectorScoreMap.get(vr.job_id) || 0
    
    if (attrs) {
      const personalized = calculatePersonalizedBaseScores(attrs, miniModule)
      // v3.9.5: ë²¡í„° ìœ ì‚¬ë„ ë³´ë„ˆìŠ¤ ì¶•ì†Œ (ì´ì¤‘ ì ìš© ë²„ê·¸ ìˆ˜ì •)
      // ê¸°ì¡´: vectorScore*15 + finalì— vectorScore*20 = ìµœëŒ€ 35ì  ì´ì¤‘ ì ìš©
      // ìˆ˜ì •: vectorScore*10ë§Œ baseì— ë°˜ì˜, finalì—ëŠ” ì¶”ê°€ ë³´ë„ˆìŠ¤ ì—†ìŒ
      const vectorBonus = Math.round(vectorScore * 10)
      const baseLike = Math.min(100, personalized.like + vectorBonus)
      const baseCan = Math.min(100, personalized.can + Math.round(vectorBonus * 0.5))
      const baseRisk = 10

      // ë¯¸íƒœê¹… ì§ì—… í˜ë„í‹°: job_attributes ì—†ì´ ê¸°ë³¸ê°’ 50ìœ¼ë¡œ ì±„ì›Œì§„ ì§ì—…ì€ ìˆœìœ„ í•˜ë½
      const isUntagged = !!(attrs as any)?._from_jobs_fallback
      const untaggedPenalty = isUntagged ? -25 : 0

      // ksco_major ì¶”ì¶œ (ì¹´í…Œê³ ë¦¬ ë‹¤ì–‘ì„± ë³´ì¥ìš©)
      let kscoMajor = ''
      if (attrs.merged_profile_json) {
        try {
          const profile = JSON.parse(attrs.merged_profile_json)
          kscoMajor = profile.ksco_major || profile.kscoMajor || ''
        } catch {}
      }

      return {
        job_id: attrs.job_id,
        job_name: attrs.job_name,
        slug: attrs.slug || undefined,
        image_url: attrs.image_url || undefined,
        job_description: extractJobDescription(attrs.api_data_json, attrs.merged_profile_json, attrs.job_name),
        base_like: baseLike,
        base_can: baseCan,
        base_risk: baseRisk,
        like_score: baseLike,
        can_score: baseCan,
        risk_penalty: baseRisk,
        // v3.9.5: vectorScore*20 ì´ì¤‘ ì ìš© ì œê±° â€” ë²¡í„° ë³´ë„ˆìŠ¤ëŠ” baseLike/baseCanì—ë§Œ ë°˜ì˜
        final_score: Math.round(0.55 * baseLike + 0.45 * baseCan - baseRisk) + untaggedPenalty,
        ksco_major: kscoMajor,
        attributes: {
          wlb: attrs.wlb,
          growth: attrs.growth,
          stability: attrs.stability,
          income: attrs.income,
          remote: attrs.remote_possible === 'full' ? 100 : attrs.remote_possible === 'partial' ? 50 : 0,
          solo_work: attrs.solo_deep,
          solo_deep: attrs.solo_deep,
          people_facing: attrs.people_facing,
          analytical: attrs.analytical,
          creative: attrs.creative,
          execution: attrs.execution,
          teamwork: attrs.teamwork,
          work_hours: attrs.work_hours,
          shift_work: attrs.shift_work,
          degree_required: attrs.degree_required,
          license_required: attrs.license_required,
          ksco_major: kscoMajor,
        },
      }
    }
    
    // ì†ì„± ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’
    const baseLike = Math.round(50 + vr.score * 20)
    return {
      job_id: vr.job_id,
      job_name: vr.job_name,
      slug: undefined,
      image_url: undefined,
      base_like: baseLike,
      base_can: 50,
      base_risk: 15,
      like_score: baseLike,
      can_score: 50,
      risk_penalty: 15,
      final_score: Math.round(baseLike + 50 - 15),
      attributes: {
        wlb: 50,
        growth: 50,
        stability: 50,
        income: 50,
        remote: 50,
        solo_work: 50,
        solo_deep: 50,
        people_facing: 50,
        analytical: 50,
        creative: 50,
        execution: 50,
        teamwork: 50,
        work_hours: 'regular',
        shift_work: 'none',
        degree_required: 'none',
        license_required: 'none',
        ksco_major: '',
      },
    }
  })
}

// ============================================
// V3: SearchProfile ê¸°ë°˜ ê²€ìƒ‰ (2026-01 ë¦¬íŒ©í† ë§)
// ============================================
import type { SearchProfile, NarrativeFacts, RoundAnswer } from './types'

export interface SearchProfileInput {
  narrativeFacts?: NarrativeFacts
  roundAnswers?: RoundAnswer[]
  universalAnswers?: Record<string, string | string[]>
  careerState?: {
    role_identity: string
    career_stage_years: string
    transition_status: string
  }
}

// V3: SearchProfile ìƒì„± (rule-based, LLM ì—†ì´)
export function buildSearchProfile(input: SearchProfileInput): SearchProfile {
  const { narrativeFacts, roundAnswers, universalAnswers, careerState } = input
  
  const desiredThemes: string[] = []
  const dislikedThemes: string[] = []
  const strengthsHypothesis: string[] = []
  const environmentPreferences: string[] = []
  const hardConstraints: string[] = []
  const riskSignals: string[] = []
  const keywords: string[] = []
  
  // 1. Universal Answersì—ì„œ ì¶”ì¶œ
  if (universalAnswers) {
    // ê´€ì‹¬ì‚¬
    const interest = universalAnswers['univ_interest']
    if (interest) {
      const arr = Array.isArray(interest) ? interest : [interest]
      desiredThemes.push(...arr)
      keywords.push(...arr)
    }
    
    // ì‹«ì–´í•˜ëŠ” ê²ƒ
    const dislike = universalAnswers['univ_dislike']
    if (dislike) {
      const arr = Array.isArray(dislike) ? dislike : [dislike]
      dislikedThemes.push(...arr)
    }
    
    // ê°•ì 
    const strength = universalAnswers['univ_strength']
    if (strength) {
      const arr = Array.isArray(strength) ? strength : [strength]
      strengthsHypothesis.push(...arr)
      keywords.push(...arr)
    }
    
    // í™˜ê²½ ì„ í˜¸
    const environment = universalAnswers['univ_environment']
    if (environment) {
      environmentPreferences.push(environment as string)
    }
    
    // ì œì•½ì¡°ê±´
    const constraintTime = universalAnswers['univ_constraint_time']
    if (constraintTime) {
      const arr = Array.isArray(constraintTime) ? constraintTime : [constraintTime]
      hardConstraints.push(...arr)
    }
    
    const constraintLocation = universalAnswers['univ_constraint_location']
    if (constraintLocation) {
      const arr = Array.isArray(constraintLocation) ? constraintLocation : [constraintLocation]
      hardConstraints.push(...arr)
    }
    
    // ìš°ì„ ìˆœìœ„
    const priority = universalAnswers['univ_priority']
    if (priority) {
      desiredThemes.push(priority as string)
    }
  }
  
  // 2. ì„œìˆ í˜• ë‹µë³€ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ rule-based)
  if (narrativeFacts) {
    const extractKeywords = (text: string): string[] => {
      // ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (í•œêµ­ì–´ ëª…ì‚¬ íŒ¨í„´)
      const patterns = [
        'ì„±ì¥', 'ë°°ì›€', 'ììœ¨', 'ì•ˆì •', 'ë„ì „', 'ì°½ì˜', 'ë¶„ì„', 'í˜‘ì—…', 'ì†Œí†µ',
        'ê¸°ìˆ ', 'IT', 'ê°œë°œ', 'ë””ìì¸', 'ë§ˆì¼€íŒ…', 'ì˜ì—…', 'ê´€ë¦¬', 'ì—°êµ¬',
        'ì‚¬ëŒ', 'í˜¼ì', 'íŒ€', 'ììœ ', 'ê·œì¹™', 'ë£¨í‹´', 'ë³€í™”',
        'ì¸ì •', 'ì„±ì·¨', 'ì˜ë¯¸', 'ë³´ëŒ', 'ëˆ', 'ì—¬ìœ ', 'ê±´ê°•'
      ]
      return patterns.filter(p => text.includes(p))
    }
    
    if (narrativeFacts.highAliveMoment) {
      const kw = extractKeywords(narrativeFacts.highAliveMoment)
      desiredThemes.push(...kw)
      keywords.push(...kw)
    }
    
    if (narrativeFacts.lostMoment) {
      const kw = extractKeywords(narrativeFacts.lostMoment)
      dislikedThemes.push(...kw)
      riskSignals.push(...kw)
    }
  }
  
  // 3. ë¼ìš´ë“œ ë‹µë³€ì—ì„œ ì¶”ì¶œ
  if (roundAnswers && roundAnswers.length > 0) {
    for (const ans of roundAnswers) {
      const text = ans.answer || ''
      
      // Round 1 (ENGINE) - ì›í•˜ëŠ” ê²ƒ
      if (ans.roundNumber === 1) {
        const kw = text.split(/[,\s]+/).filter(w => w.length > 1).slice(0, 5)
        keywords.push(...kw)
      }
      
      // Round 2 (AVOIDANCE) - í”¼í•˜ê³  ì‹¶ì€ ê²ƒ
      if (ans.roundNumber === 2) {
        const kw = text.split(/[,\s]+/).filter(w => w.length > 1).slice(0, 3)
        riskSignals.push(...kw)
      }
    }
  }
  
  // 4. ì»¤ë¦¬ì–´ ìƒíƒœì—ì„œ í‚¤ì›Œë“œ ì¶”ê°€
  if (careerState) {
    if (careerState.transition_status === 'changer' || careerState.transition_status === 'returner') {
      keywords.push('ì „í™˜', 'ìƒˆë¡œìš´')
    }
    if (careerState.career_stage_years === 'student') {
      keywords.push('ì‹ ì…', 'ì´ˆë³´', 'ì…ë¬¸')
    }
  }
  
  // ì¤‘ë³µ ì œê±°
  return {
    desiredThemes: [...new Set(desiredThemes)],
    dislikedThemes: [...new Set(dislikedThemes)],
    strengthsHypothesis: [...new Set(strengthsHypothesis)],
    environmentPreferences: [...new Set(environmentPreferences)],
    hardConstraints: [...new Set(hardConstraints)],
    riskSignals: [...new Set(riskSignals)],
    keywords: [...new Set(keywords)],
  }
}

// ============================================
// LLM ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰ ì¿¼ë¦¬ ë™ì  ìƒì„±
// ============================================
// ì •ì  í† í°â†’í‚¤ì›Œë“œ ë§¤í•‘ ëŒ€ì‹  GPT-4o-miniê°€ ìœ ì € í”„ë¡œíŒŒì¼ì„ ë³´ê³ 
// ì í•©í•œ ì§ì—… ì¹´í…Œê³ ë¦¬/ì§ì—…ëª…ì„ ìë™ ì¶”ë¡ í•©ë‹ˆë‹¤.
// ë¹„ìš©: ~$0.001/call, ì‹œê°„: ~1-2ì´ˆ
// ============================================

const LLM_SEARCH_QUERY_PROMPT = `ë‹¹ì‹ ì€ í•œêµ­ ì§ì—… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ í”„ë¡œíŒŒì¼ì„ ë³´ê³ , ì´ ì‚¬ëŒì—ê²Œ ì í•©í•  ìˆ˜ ìˆëŠ” í•œêµ­ ì§ì—… ì¹´í…Œê³ ë¦¬ì™€ êµ¬ì²´ì  ì§ì—…ëª…ì„ ë‚˜ì—´í•´ì£¼ì„¸ìš”.

ê·œì¹™:
1. ì§ì—… ì¹´í…Œê³ ë¦¬ 5~8ê°œ, êµ¬ì²´ì  ì§ì—…ëª… 25~30ê°œë¥¼ ë‚˜ì—´
2. í•œêµ­ì–´ë¡œ ì‘ì„± (ì˜ˆ: ê³µë¬´ì›, í–‰ì •ì‚¬ë¬´ì›, ë°ì´í„°ë¶„ì„ê°€)
3. ì‚¬ìš©ìì˜ í¥ë¯¸, ê°€ì¹˜ê´€, ê°•ì , ì œì•½ì¡°ê±´ì„ ëª¨ë‘ ê³ ë ¤
4. â˜…â˜…â˜… ë°˜ë“œì‹œ ëˆ„êµ¬ë‚˜ ì•„ëŠ” ì£¼ë¥˜ ì§ì—… ìœ„ì£¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”!
   - ì£¼ë¥˜ ì§ì—… = ì·¨ì—…í¬í„¸ì—ì„œ ì‰½ê²Œ ê²€ìƒ‰ë˜ëŠ” ì§ì—… (ì˜ˆ: UXë””ìì´ë„ˆ, ì„œë¹„ìŠ¤ê¸°íšì, ì†Œí”„íŠ¸ì›¨ì–´ê°œë°œì, ê²½ì˜ì»¨ì„¤í„´íŠ¸, ì—°êµ¬ì›, ë§ˆì¼€í„°, êµì‚¬, ê°„í˜¸ì‚¬ ë“±)
   - ìµœì†Œ 20ê°œëŠ” ì£¼ë¥˜ ì§ì—…ì´ì–´ì•¼ í•©ë‹ˆë‹¤
   - ìˆ¨ê²¨ì§„ í‹ˆìƒˆ ì§ì—…ì€ 5ê°œ ì´í•˜ë¡œ ì œí•œ
5. âŒ ê¸ˆì§€: íŠ¹ì • ì†Œì¬/ì¬ë£Œ ê¸°ë°˜ ì„¸ë¶€ ì§ì¢… (ì˜ˆ: ê³ ë¬´ì œí’ˆê°œë°œì, ë°”ì´ì˜¤í™”í•™ì œí’ˆâ—‹â—‹ì, ì„ìœ í™”í•™â—‹â—‹ì, ë‹¨ì²­ê¸°ìˆ ì ë“±)
   â†’ ì‚¬ìš©ìê°€ í•´ë‹¹ ë¶„ì•¼ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì§€ ì•Šì•˜ë‹¤ë©´ ì ˆëŒ€ í¬í•¨ ê¸ˆì§€
6. ì œì•½ì¡°ê±´ì´ ìˆìœ¼ë©´ ê·¸ì— ë§ëŠ” í˜„ì‹¤ì ì¸ ì§ì—… ìœ„ì£¼ë¡œ
7. ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ í•œ ì¤„ë¡œ ì¶œë ¥
8. ì„¤ëª…ì´ë‚˜ ë²ˆí˜¸ ì—†ì´ ì§ì—…ëª…/ì¹´í…Œê³ ë¦¬ë§Œ ë‚˜ì—´`

export async function buildLLMSearchQuery(
  miniModule: MiniModuleResult,
  openaiApiKey: string
): Promise<string> {
  // ìœ ì € í”„ë¡œíŒŒì¼ì„ ìì—°ì–´ë¡œ ë³€í™˜
  const profileParts: string[] = []

  if (miniModule.interest_top?.length) {
    profileParts.push(`í¥ë¯¸: ${miniModule.interest_top.join(', ')}`)
  }
  if (miniModule.value_top?.length) {
    profileParts.push(`ê°€ì¹˜ê´€: ${miniModule.value_top.join(', ')}`)
  }
  if (miniModule.strength_top?.length) {
    profileParts.push(`ê°•ì : ${miniModule.strength_top.join(', ')}`)
  }
  if (miniModule.workstyle_top?.length) {
    profileParts.push(`ì—…ë¬´ìŠ¤íƒ€ì¼: ${miniModule.workstyle_top.join(', ')}`)
  }
  if (miniModule.constraint_flags?.length) {
    profileParts.push(`ì œì•½ì¡°ê±´: ${miniModule.constraint_flags.join(', ')}`)
  }
  if (miniModule.energy_drain_flags?.length) {
    profileParts.push(`ì—ë„ˆì§€ì†Œëª¨: ${miniModule.energy_drain_flags.join(', ')}`)
  }
  if (miniModule.sacrifice_flags?.length) {
    profileParts.push(`ê°ìˆ˜ê°€ëŠ¥: ${miniModule.sacrifice_flags.join(', ')}`)
  }
  if (miniModule.background_flags?.length) {
    profileParts.push(`ë°°ê²½: ${miniModule.background_flags.join(', ')}`)
  }
  if (miniModule.persistence_anchor) {
    profileParts.push(`ì§€ì†ë™ê¸°: ${miniModule.persistence_anchor}`)
  }
  if (miniModule.failure_response) {
    profileParts.push(`ì‹¤íŒ¨ë°˜ì‘: ${miniModule.failure_response}`)
  }

  if (profileParts.length === 0) {
    throw new Error('[LLM Search Query] miniModuleì— í”„ë¡œíŒŒì¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤')
  }

  const userMessage = `ì‚¬ìš©ì í”„ë¡œíŒŒì¼:\n${profileParts.join('\n')}`

  const response = await fetch('https://gateway.ai.cloudflare.com/v1/3587865378649966bfb0a814fce73c77/careerwiki/openai/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${openaiApiKey}`,
    },
    body: JSON.stringify({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: LLM_SEARCH_QUERY_PROMPT },
        { role: 'user', content: userMessage },
      ],
      temperature: 0.3,
      max_tokens: 300,
    }),
  })

  if (!response.ok) {
    const body = await response.text().catch(() => '')
    throw new Error(`[LLM Search Query] API error ${response.status}: ${body.substring(0, 200)}`)
  }

  const data = await response.json() as any
  const content = data.choices?.[0]?.message?.content?.trim()

  if (!content) {
    throw new Error('[LLM Search Query] LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤')
  }

  const llmQuery = `ì í•© ì§ì—…: ${content}`.substring(0, 500)


  return llmQuery
}

// ============================================
// v3.9.5: ì»¤ë¦¬ì–´ ì•„í‚¤íƒ€ì… ì¿¼ë¦¬ ë¹Œë”
// í¥ë¯¸+ê°€ì¹˜ ì¡°í•©ì—ì„œ ì£¼ë¥˜ ì§ì—…êµ° ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì—¬
// ë²¡í„° ê²€ìƒ‰ì—ì„œ ëˆ„êµ¬ë‚˜ ì•„ëŠ” ì§ì—…ì´ í›„ë³´ì— í¬í•¨ë˜ë„ë¡ ë³´ì¥
// ============================================
function buildArchetypeQueries(miniModule: MiniModuleResult): string[] {
  const interests = miniModule.interest_top || []
  const values = miniModule.value_top || []

  // í¥ë¯¸Ã—ê°€ì¹˜ ì¡°í•© â†’ ì£¼ë¥˜ ì§ì—… ì¿¼ë¦¬ ë§µ
  // ê° ì¡°í•©ì€ í•œêµ­ ì·¨ì—…ì‹œì¥ì—ì„œ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ëŒ€í‘œ ì§ì—… 4-6ê°œ
  const ARCHETYPE_MAP: Record<string, Record<string, string>> = {
    creating: {
      autonomy: 'UXë””ìì´ë„ˆ ì„œë¹„ìŠ¤ê¸°íšì ì½˜í…ì¸ ê¸°íšì ë¸Œëœë“œë””ìì´ë„ˆ ì˜ìƒí¸ì§‘ì',
      growth: 'UXë””ìì´ë„ˆ í”„ë¡œë•íŠ¸ë””ìì´ë„ˆ ê²Œì„ê¸°íšì ê´‘ê³ ê¸°íšì ì½˜í…ì¸ ì „ëµê°€',
      stability: 'UXë””ìì´ë„ˆ ì¸í…Œë¦¬ì–´ë””ìì´ë„ˆ í¸ì§‘ë””ìì´ë„ˆ ê³µê°„ë””ìì´ë„ˆ ì›¹ë””ìì´ë„ˆ',
      wlb: 'UXë””ìì´ë„ˆ ì›¹ë””ìì´ë„ˆ í¸ì§‘ë””ìì´ë„ˆ ì½˜í…ì¸ ê¸°íšì ê·¸ë˜í”½ë””ìì´ë„ˆ',
      income: 'ê´‘ê³ ê°ë… í¬ë¦¬ì—ì´í‹°ë¸Œë””ë ‰í„° ë¸Œëœë“œë§¤ë‹ˆì € UXë””ë ‰í„° ì•„íŠ¸ë””ë ‰í„°',
      meaning: 'êµìœ¡ì½˜í…ì¸ ê¸°íšì ë¬¸í™”ê¸°íšì ê³µê³µë””ìì´ë„ˆ ì‚¬íšŒí˜ì‹ ë””ìì´ë„ˆ',
      recognition: 'UXë””ë ‰í„° í¬ë¦¬ì—ì´í‹°ë¸Œë””ë ‰í„° ì•„íŠ¸ë””ë ‰í„° í”„ë¡œë•íŠ¸ë””ìì´ë„ˆ',
    },
    problem_solving: {
      autonomy: 'ê²½ì˜ì»¨ì„¤í„´íŠ¸ UXë¦¬ì„œì²˜ ë°ì´í„°ë¶„ì„ê°€ ì „ëµê¸°íšì í”„ë¦¬ëœì„œì»¨ì„¤í„´íŠ¸',
      growth: 'ê²½ì˜ì»¨ì„¤í„´íŠ¸ ì „ëµê¸°íšì ë°ì´í„°ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ ì‚¬ì—…ê°œë°œë§¤ë‹ˆì € íˆ¬ìë¶„ì„ê°€',
      stability: 'ê³µê³µì •ì±…ë¶„ì„ê°€ ì—°êµ¬ì› í’ˆì§ˆê´€ë¦¬ì „ë¬¸ê°€ ì‹œìŠ¤í…œë¶„ì„ê°€ ê°ì‚¬ê´€',
      wlb: 'ì—°êµ¬ì› í’ˆì§ˆê´€ë¦¬ì „ë¬¸ê°€ ê³µê³µì •ì±…ë¶„ì„ê°€ ë°ì´í„°ë¶„ì„ê°€ ì‹œìŠ¤í…œë¶„ì„ê°€',
      income: 'ê²½ì˜ì»¨ì„¤í„´íŠ¸ íˆ¬ìë¶„ì„ê°€ ì „ëµê¸°íšì„ì› ë°ì´í„°ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ ê¸°ìˆ ì»¨ì„¤í„´íŠ¸',
      meaning: 'ì •ì±…ì—°êµ¬ì› ì‚¬íšŒë¬¸ì œí•´ê²°ì „ë¬¸ê°€ ë¹„ì˜ë¦¬ì»¨ì„¤í„´íŠ¸ êµìœ¡í˜ì‹ ê°€',
      recognition: 'ê²½ì˜ì»¨ì„¤í„´íŠ¸ ì „ëµê¸°íšì ì—°êµ¬ì› ê¸°ìˆ ìë¬¸ìœ„ì›',
    },
    data_numbers: {
      autonomy: 'ë°ì´í„°ë¶„ì„ê°€ í†µê³„ì»¨ì„¤í„´íŠ¸ í€€íŠ¸ë¶„ì„ê°€ BIë¶„ì„ê°€ ë¦¬ì„œì¹˜ì• ë„ë¦¬ìŠ¤íŠ¸',
      growth: 'ë°ì´í„°ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ AIì—”ì§€ë‹ˆì–´ ë¨¸ì‹ ëŸ¬ë‹ì—”ì§€ë‹ˆì–´ ë°ì´í„°ì—”ì§€ë‹ˆì–´',
      stability: 'í†µê³„ë¶„ì„ì „ë¬¸ê°€ ë³´í—˜ê³„ë¦¬ì‚¬ ì¬ë¬´ë¶„ì„ê°€ ê³µê³µë°ì´í„°ë¶„ì„ê°€',
      wlb: 'í†µê³„ë¶„ì„ì „ë¬¸ê°€ ì¬ë¬´ë¶„ì„ê°€ ê³µê³µë°ì´í„°ë¶„ì„ê°€ ê²½ë¦¬ì‚¬ë¬´ì› íšŒê³„ì‚¬ë¬´ì›',
      income: 'í€€íŠ¸ë¶„ì„ê°€ ë°ì´í„°ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ AIì—”ì§€ë‹ˆì–´ ê¸ˆìœµê³µí•™ì „ë¬¸ê°€',
      meaning: 'ë³´ê±´í†µê³„ë¶„ì„ê°€ ì‚¬íšŒì¡°ì‚¬ë¶„ì„ì‚¬ ê³µê³µë°ì´í„°ë¶„ì„ê°€ êµìœ¡í‰ê°€ì—°êµ¬ì›',
      recognition: 'ë°ì´í„°ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ AIì—°êµ¬ì› í†µê³„í•™ì ë°ì´í„°ì•„í‚¤í…íŠ¸',
    },
    helping_teaching: {
      autonomy: 'ìƒë‹´ì‹¬ë¦¬ì‚¬ ì½”ì¹˜ êµìœ¡ì»¨ì„¤í„´íŠ¸ ì‚¬íšŒë³µì§€ì‚¬ ì§„ë¡œìƒë‹´ì‚¬',
      growth: 'êµìœ¡ê¸°íšì HRDì „ë¬¸ê°€ ì¡°ì§ê°œë°œì»¨ì„¤í„´íŠ¸ ìƒë‹´ì‹¬ë¦¬ì‚¬',
      stability: 'êµì‚¬ ê³µë¬´ì› ì‚¬íšŒë³µì§€ì‚¬ ê°„í˜¸ì‚¬ ìƒë‹´êµì‚¬',
      wlb: 'êµì‚¬ ì‚¬íšŒë³µì§€ì‚¬ ìƒë‹´êµì‚¬ ë³´ê±´êµì‚¬ ì‚¬ì„œ í•™êµìƒë‹´ì‚¬',
      income: 'ì„ìƒì‹¬ë¦¬ì „ë¬¸ê°€ ì¡°ì§ê°œë°œì»¨ì„¤í„´íŠ¸ HRDë§¤ë‹ˆì € ì˜ì‚¬',
      meaning: 'ì‚¬íšŒë³µì§€ì‚¬ ìƒë‹´ì‹¬ë¦¬ì‚¬ NGOí™œë™ê°€ êµìœ¡í˜ì‹ ê°€ ì²­ì†Œë…„ì§€ë„ì‚¬',
      recognition: 'ì„ìƒì‹¬ë¦¬ì „ë¬¸ê°€ êµìˆ˜ êµìœ¡ì „ë¬¸ê°€ ìƒë‹´ì‹¬ë¦¬ì‚¬',
    },
    organizing: {
      autonomy: 'í”„ë¡œì íŠ¸ë§¤ë‹ˆì € ê²½ì˜ê¸°íšì ì „ëµê¸°íšì ì‚¬ì—…ê°œë°œë§¤ë‹ˆì €',
      growth: 'ê²½ì˜ê¸°íšì ì‚¬ì—…ê°œë°œë§¤ë‹ˆì € í”„ë¡œë•íŠ¸ë§¤ë‹ˆì € ì „ëµê¸°íšì',
      stability: 'í–‰ì •ê´€ë¦¬ì ê³µë¬´ì› ì´ë¬´ê´€ë¦¬ì ì¸ì‚¬ë‹´ë‹¹ì ê²½ì˜ì§€ì›',
      wlb: 'í–‰ì •ì‚¬ë¬´ì› ì´ë¬´ê´€ë¦¬ì ì¸ì‚¬ë‹´ë‹¹ì ê²½ë¦¬ì‚¬ë¬´ì› ê³µë¬´ì› ì‚¬ë¬´ê´€ë¦¬ì',
      income: 'ê²½ì˜ê¸°íšì„ì› ì‚¬ì—…ê°œë°œì´ì‚¬ í”„ë¡œê·¸ë¨ë””ë ‰í„° ê²½ì˜ê´€ë¦¬ì',
      meaning: 'ë¹„ì˜ë¦¬ê²½ì˜ì ê³µê³µê¸°ê´€ê´€ë¦¬ì ì‚¬íšŒì ê¸°ì—…ë§¤ë‹ˆì € í˜‘ë™ì¡°í•©ìš´ì˜ì',
      recognition: 'ê²½ì˜ê¸°íšì í”„ë¡œì íŠ¸ë””ë ‰í„° ì „ëµê¸°íšì„ì›',
    },
    influencing: {
      autonomy: 'ë§ˆì¼€í„° ë¸Œëœë“œë§¤ë‹ˆì € í™ë³´ì „ë¬¸ê°€ ì½˜í…ì¸ ë§ˆì¼€í„° í¼í¬ë¨¼ìŠ¤ë§ˆì¼€í„°',
      growth: 'ë§ˆì¼€íŒ…ì „ëµê°€ ë¸Œëœë“œë§¤ë‹ˆì € ë””ì§€í„¸ë§ˆì¼€í„° ê·¸ë¡œìŠ¤í•´ì»¤',
      stability: 'í™ë³´ë‹´ë‹¹ì ë§ˆì¼€íŒ…ê´€ë¦¬ì ê´‘ê³ ëŒ€í–‰ì‚¬ê¸°íšì ì‚¬ë‚´ì»¤ë®¤ë‹ˆì¼€ì´ì…˜',
      wlb: 'í™ë³´ë‹´ë‹¹ì ë§ˆì¼€íŒ…ê´€ë¦¬ì ì‚¬ë‚´ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì½˜í…ì¸ ë§ˆì¼€í„°',
      income: 'CMO ë§ˆì¼€íŒ…ì´ì‚¬ ë¸Œëœë“œë””ë ‰í„° ì„¸ì¼ì¦ˆë””ë ‰í„°',
      meaning: 'ì‚¬íšŒë§ˆì¼€íŒ…ì „ë¬¸ê°€ ê³µìµìº í˜ì¸ê¸°íšì ë¹„ì˜ë¦¬í™ë³´ì „ë¬¸ê°€',
      recognition: 'ë¸Œëœë“œë””ë ‰í„° ë§ˆì¼€íŒ…ì „ëµê°€ PRì „ë¬¸ê°€ ê´‘ê³ í¬ë¦¬ì—ì´í„°',
    },
    tech: {
      autonomy: 'ì†Œí”„íŠ¸ì›¨ì–´ê°œë°œì í’€ìŠ¤íƒê°œë°œì í”„ë¦¬ëœì„œê°œë°œì DevOpsì—”ì§€ë‹ˆì–´',
      growth: 'ì†Œí”„íŠ¸ì›¨ì–´ì—”ì§€ë‹ˆì–´ ë°±ì—”ë“œê°œë°œì AIì—”ì§€ë‹ˆì–´ í´ë¼ìš°ë“œì•„í‚¤í…íŠ¸',
      stability: 'ì‹œìŠ¤í…œì—”ì§€ë‹ˆì–´ ITì¸í”„ë¼ê´€ë¦¬ì ì •ë³´ë³´ì•ˆì „ë¬¸ê°€ DBA',
      wlb: 'ì‹œìŠ¤í…œì—”ì§€ë‹ˆì–´ ITì¸í”„ë¼ê´€ë¦¬ì DBA ì •ë³´ë³´ì•ˆì „ë¬¸ê°€ ì›¹ê°œë°œì',
      income: 'CTO ì‹œë‹ˆì–´ê°œë°œì AIì—”ì§€ë‹ˆì–´ í´ë¼ìš°ë“œì•„í‚¤í…íŠ¸ ë³´ì•ˆì»¨ì„¤í„´íŠ¸',
      meaning: 'ì—ë“€í…Œí¬ê°œë°œì í—¬ìŠ¤í…Œí¬ê°œë°œì ì˜¤í”ˆì†ŒìŠ¤ê°œë°œì ì ‘ê·¼ì„±ì „ë¬¸ê°€',
      recognition: 'CTO í…Œí¬ë¦¬ë“œ ì†Œí”„íŠ¸ì›¨ì–´ì•„í‚¤í…íŠ¸ AIì—°êµ¬ì›',
    },
    routine: {
      autonomy: 'ì‚¬ë¬´ê´€ë¦¬ì ì¬ë¬´íšŒê³„ì‚¬ ì„¸ë¬´ì‚¬ í–‰ì •ì‚¬',
      growth: 'íšŒê³„ì‚¬ ì„¸ë¬´ì‚¬ ë²•ë¬´ì‚¬ ë…¸ë¬´ì‚¬ ê°ì •í‰ê°€ì‚¬',
      stability: 'ê³µë¬´ì› ì€í–‰ì› íšŒê³„ì‚¬ í–‰ì •ì§ ì‚¬ë¬´ê´€ë¦¬ì',
      wlb: 'ê³µë¬´ì› ì€í–‰ì› í–‰ì •ì‚¬ë¬´ì› ê²½ë¦¬ì‚¬ë¬´ì› ì‚¬ë¬´ê´€ë¦¬ì ì´ë¬´',
      income: 'íšŒê³„ì‚¬ ì„¸ë¬´ì‚¬ ë³€ë¦¬ì‚¬ ê°ì •í‰ê°€ì‚¬ ë²•ë¬´ì‚¬',
      meaning: 'ê³µê³µí–‰ì •ê°€ ì‹œë¯¼ì„œë¹„ìŠ¤ì „ë¬¸ê°€ ë²•ë¥ êµ¬ì¡°ì‚¬',
      recognition: 'ê³µì¸íšŒê³„ì‚¬ ì„¸ë¬´ì‚¬ í–‰ì •ì „ë¬¸ê°€',
    },
  }

  const queries: string[] = []
  const seen = new Set<string>()

  // v3.9.9: ìƒìœ„ í¥ë¯¸ 3ê°œ Ã— ìƒìœ„ ê°€ì¹˜ 3ê°œ ì¡°í•© (2Ã—2â†’3Ã—3 í™•ì¥)
  for (const interest of interests.slice(0, 3)) {
    for (const value of values.slice(0, 3)) {
      const query = ARCHETYPE_MAP[interest]?.[value]
      if (query && !seen.has(query)) {
        seen.add(query)
        queries.push(query)
      }
    }
  }

  // v3.9.9: ìµœëŒ€ 5ê°œë¡œ í™•ì¥ (3â†’5, ì£¼ë¥˜ ì§ì—… ì»¤ë²„ë¦¬ì§€ í–¥ìƒ)
  return queries.slice(0, 5)
}

// ============================================
// Multi-Search ì¿¼ë¦¬ ìƒì„± (LLM ì¿¼ë¦¬ ë¶„í•  + ì°¨ì›ë³„ í‚¤ì›Œë“œ)
// 10-12ê°œ ì¿¼ë¦¬ë¡œ ë²¡í„° ê³µê°„ì˜ ë‹¤ì–‘í•œ ì˜ì—­ íƒìƒ‰
// ============================================
export async function buildMultiSearchQueries(
  miniModule: MiniModuleResult,
  openaiApiKey: string
): Promise<string[]> {
  // 1. ê¸°ì¡´ LLM ì¿¼ë¦¬ (ì¢…í•© ì§ì—…ëª… ë¦¬ìŠ¤íŠ¸)
  const llmQuery = await buildLLMSearchQuery(miniModule, openaiApiKey)

  // 2. LLM ì¶œë ¥ì„ 3-5ê°œì”© ë¶„í• í•˜ì—¬ ì„œë¸Œì¿¼ë¦¬ ìƒì„±
  // "ì í•© ì§ì—…: A, B, C, D, E, ..." â†’ ["A, B, C", "D, E, F", ...]
  const rawContent = llmQuery.replace(/^ì í•© ì§ì—…:\s*/, '')
  const jobNames = rawContent.split(/[,ï¼Œã€]/).map(s => s.trim()).filter(Boolean)
  const chunkSize = Math.max(3, Math.ceil(jobNames.length / 5))
  const subQueries: string[] = []
  for (let i = 0; i < jobNames.length; i += chunkSize) {
    subQueries.push(jobNames.slice(i, i + chunkSize).join(', '))
  }

  // 3. ì°¨ì›ë³„ í‚¤ì›Œë“œ ì¿¼ë¦¬ ì¶”ê°€ (í•œêµ­ì–´ ë³€í™˜ + ê·œì¹™ ê¸°ë°˜)
  // v3.9.5: ì˜ì–´ í† í° â†’ í•œêµ­ì–´ ë¼ë²¨ ë³€í™˜ (ë²¡í„° ë§¤ì¹­ ì •í™•ë„ í–¥ìƒ)
  const INTEREST_KR: Record<string, string> = {
    creating: 'ì°½ì‘ ì˜ˆìˆ  ë””ìì¸ ê¸°íš', problem_solving: 'ë¬¸ì œí•´ê²° ë¶„ì„ ì»¨ì„¤íŒ…',
    data_numbers: 'ë°ì´í„°ë¶„ì„ í†µê³„', helping_teaching: 'êµìœ¡ ìƒë‹´ ë³µì§€',
    organizing: 'ê¸°íš ê´€ë¦¬ í–‰ì •', influencing: 'ë§ˆì¼€íŒ… ì˜ì—… í™ë³´',
    tech: 'ê¸°ìˆ  IT í”„ë¡œê·¸ë˜ë° ê°œë°œ', routine: 'ì‚¬ë¬´ í–‰ì • ì •ê·œì—…ë¬´',
  }
  const STRENGTH_KR: Record<string, string> = {
    analytical: 'ë¶„ì„ë ¥ ë…¼ë¦¬ì ì‚¬ê³ ', creative: 'ì°½ì˜ì„± ì•„ì´ë””ì–´',
    communication: 'ì†Œí†µ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜', structured_execution: 'ì‹¤í–‰ë ¥ ì²´ê³„ì ',
    persistence: 'ëˆê¸° ì§€ì†ë ¥', fast_learning: 'í•™ìŠµëŠ¥ë ¥ ë¹ ë¥¸ìŠµë“',
  }
  const VALUE_KR: Record<string, string> = {
    growth: 'ì„±ì¥ ë°œì „ ì»¤ë¦¬ì–´ì„±ì¥', stability: 'ì•ˆì • ì •ê·œì§ ì •ì‹œí‡´ê·¼',
    income: 'ë†’ì€ì—°ë´‰ ìˆ˜ì…', autonomy: 'ììœ¨ ë…ë¦½ ì¬ëŸ‰',
    meaning: 'ë³´ëŒ ì‚¬íšŒê¸°ì—¬', recognition: 'ì¸ì • ì „ë¬¸ì„±',
  }

  const dimensionQueries: string[] = []
  if (miniModule.interest_top?.length) {
    const krInterests = miniModule.interest_top.map((t: string) => INTEREST_KR[t] || t).join(' ')
    dimensionQueries.push(`${krInterests} ê´€ë ¨ ì§ì—…`)
  }
  if (miniModule.strength_top?.length) {
    const krStrengths = miniModule.strength_top.map((t: string) => STRENGTH_KR[t] || t).join(' ')
    dimensionQueries.push(`${krStrengths} ì—­ëŸ‰ì´ í•„ìš”í•œ ì§ì—…`)
  }
  if (miniModule.value_top?.length) {
    const krValues = miniModule.value_top.map((t: string) => VALUE_KR[t] || t).join(' ')
    dimensionQueries.push(`${krValues} í™˜ê²½ì˜ ì§ì—…`)
  }

  // 4. ì»¤ë¦¬ì–´ ì•„í‚¤íƒ€ì… ì¿¼ë¦¬ (í¥ë¯¸+ê°€ì¹˜ ì¡°í•© â†’ ì£¼ë¥˜ ì§ì—…êµ° ë³´ì¥)
  const archetypeQueries = buildArchetypeQueries(miniModule)

  // 5. ëª¨ë“  ì¿¼ë¦¬ ê²°í•© (ì¢…í•© + ì„œë¸Œì¿¼ë¦¬ + ì°¨ì›ë³„ + ì•„í‚¤íƒ€ì…)
  const allQueries = [
    llmQuery,            // ì¢…í•© (ê°€ì¥ ì¤‘ìš”)
    ...subQueries,       // LLM ì¶œë ¥ ë¶„í•  (5-8ê°œ)
    ...dimensionQueries, // í¥ë¯¸/ê°•ì /ê°€ì¹˜ í•œêµ­ì–´ ì°¨ì› (2-3ê°œ)
    ...archetypeQueries, // ì£¼ë¥˜ ì»¤ë¦¬ì–´ íŒ¨ìŠ¤ ë³´ì¥ (1-3ê°œ)
  ]


  return allQueries
}

// V3: SearchProfile â†’ ê²€ìƒ‰ ì¿¼ë¦¬ ë³€í™˜ (ì •ì  í‚¤ì›Œë“œ ê¸°ë°˜ - fallbackìš©)
export function searchProfileToQuery(profile: SearchProfile): string {
  const parts: string[] = []
  
  if (profile.desiredThemes.length > 0) {
    parts.push(`ì›í•˜ëŠ” ê²ƒ: ${profile.desiredThemes.join(', ')}`)
  }
  
  if (profile.strengthsHypothesis.length > 0) {
    parts.push(`ê°•ì : ${profile.strengthsHypothesis.join(', ')}`)
  }
  
  if (profile.keywords.length > 0) {
    parts.push(profile.keywords.join(' '))
  }
  
  if (profile.environmentPreferences.length > 0) {
    parts.push(`í™˜ê²½: ${profile.environmentPreferences.join(', ')}`)
  }
  
  if (parts.length === 0) {
    return 'ì§ì—… ì¶”ì²œ ì í•©í•œ ì¼ìë¦¬'
  }
  
  return parts.join(' ').substring(0, 500)
}

// ============================================
// V3: SearchProfile ê¸°ë°˜ í›„ë³´êµ° í™•ì¥ (OpenAI Embedding)
// ============================================
// 2026-01-26: íƒœê¹… ì˜ì¡´ë„ ì™„ì „ ì œê±°
// - ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ë§Œ ì‚¬ìš©
// - minTaggedJobs ì˜µì…˜ ì œê±°
// ============================================
export async function expandCandidatesV3(
  db: D1Database,
  vectorize: VectorizeIndex | undefined,
  openaiApiKey: string | undefined,
  searchProfile: SearchProfile,
  options: {
    targetSize?: number
    miniModule?: MiniModuleResult
  } = {}
): Promise<CandidateExpansionResult> {
  const { targetSize = 500, miniModule } = options
  const startTime = Date.now()

  // Vectorize ë˜ëŠ” OpenAI API í‚¤ê°€ ì—†ìœ¼ë©´ fallback
  if (!vectorize || !openaiApiKey) {
    const fallbackResult = await getFallbackCandidatesV3(db, targetSize)
    return {
      candidates: fallbackResult,
      total_searched: fallbackResult.length,
      search_duration_ms: Date.now() - startTime,
      fallback_used: true,
    }
  }

  // 1. LLM ê¸°ë°˜ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (í•„ìˆ˜ - ì‹¤íŒ¨ ì‹œ ì—ëŸ¬)
  if (!miniModule) {
    throw new Error('[V3 Vectorize] miniModuleì´ í•„ìˆ˜ì…ë‹ˆë‹¤ - LLM ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±ì— í•„ìš”')
  }

  const queries = await buildMultiSearchQueries(miniModule, openaiApiKey)

  // 2. ë²¡í„° ê²€ìƒ‰ (Multi-Query ë³‘ë ¬ ê²€ìƒ‰, OpenAI Embedding)
  // Vectorize ë¡œì»¬ ì‹¤í–‰ ë¶ˆê°€ ì‹œ DB fallback (wrangler pages dev í•œê³„)
  try {
    const vectorResults = await searchCandidatesMultiQuery(vectorize, openaiApiKey, queries)

    const candidates = vectorResults.map(vr => ({
      ...vr,
      metadata: { ...vr.metadata, source: 'vector_search', query_source: 'llm' },
    }))

    return {
      candidates,
      total_searched: vectorResults.length,
      search_duration_ms: Date.now() - startTime,
      fallback_used: false,
    }
  } catch (vecError: any) {
    // Vectorize ë¡œì»¬ ë°”ì¸ë”© ì—ëŸ¬ â†’ DB fallback (productionì—ì„œëŠ” ë°œìƒí•˜ì§€ ì•ŠìŒ)
    if (vecError?.message?.includes('remotely') || vecError?.message?.includes('Vectorize')) {
      const fallbackResult = await getFallbackCandidatesV3(db, targetSize)
      return {
        candidates: fallbackResult,
        total_searched: fallbackResult.length,
        search_duration_ms: Date.now() - startTime,
        fallback_used: true,
      }
    }
    throw vecError  // ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ê·¸ëŒ€ë¡œ ì „íŒŒ
  }
}

// V3: Fallback - jobs í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì¡°íšŒ (íƒœê¹… ë¬´ê´€)
async function getFallbackCandidatesV3(
  db: D1Database,
  limit: number
): Promise<VectorSearchResult[]> {
  const result = await db.prepare(`
    SELECT id, name
    FROM jobs
    WHERE is_active = 1 AND merged_profile_json IS NOT NULL
    ORDER BY RANDOM()
    LIMIT ?
  `).bind(limit).all<{ id: string; name: string }>()
  
  return (result.results || []).map((row, idx) => ({
    job_id: row.id,
    job_name: row.name,
    score: 0.5 - (idx * 0.0001), // ëœë¤ ìˆœì„œ ìœ ì§€
    metadata: { source: 'fallback_v3' },
  }))
}

// ============================================
// P1-2: SearchProfile ìºì‹œ ë²„ì „í™” (answers_hash)
// ============================================

/**
 * P1-2: ì‚¬ìš©ì ë‹µë³€ì„ ê¸°ë°˜ìœ¼ë¡œ í•´ì‹œ ìƒì„±
 * ë‹µë³€ì´ ë³€ê²½ë˜ë©´ ë‹¤ë¥¸ í•´ì‹œê°€ ìƒì„±ë˜ì–´ ìºì‹œê°€ ë¬´íš¨í™”ë¨
 */
export function computeAnswersHash(
  narrativeFacts?: NarrativeFacts,
  roundAnswers?: RoundAnswer[],
  universalAnswers?: Record<string, string | string[]>
): string {
  const content = JSON.stringify({
    n: narrativeFacts || null,
    r: (roundAnswers || []).map(a => ({ r: a.roundNumber, q: a.questionId, a: a.answer })),
    u: universalAnswers || {},
  })
  
  // ê°„ë‹¨í•œ í•´ì‹œ í•¨ìˆ˜ (DJB2 ì•Œê³ ë¦¬ì¦˜)
  let hash = 5381
  for (let i = 0; i < content.length; i++) {
    hash = ((hash << 5) + hash) + content.charCodeAt(i)
    hash = hash & hash // 32bit ì •ìˆ˜ë¡œ ë³€í™˜
  }
  
  return Math.abs(hash).toString(36)
}

/**
 * P1-2: SearchProfile ìºì‹œ ì¡°íšŒ (ë²„ì „í™”ëœ í‚¤ ì‚¬ìš©)
 */
export async function getCachedSearchProfile(
  db: D1Database,
  sessionId: string,
  answersHash: string
): Promise<SearchProfile | null> {
  try {
    const cached = await db.prepare(`
      SELECT profile_json FROM search_profile_cache 
      WHERE session_id = ? AND answers_hash = ?
    `).bind(sessionId, answersHash).first<{ profile_json: string }>()
    
    if (cached?.profile_json) {
      return JSON.parse(cached.profile_json)
    }
  } catch (error) {
  }
  
  return null
}

/**
 * P1-2: SearchProfile ìºì‹œ ì €ì¥ (ë²„ì „í™”ëœ í‚¤ ì‚¬ìš©)
 */
export async function cacheSearchProfile(
  db: D1Database,
  sessionId: string,
  answersHash: string,
  profile: SearchProfile
): Promise<void> {
  try {
    await db.prepare(`
      INSERT INTO search_profile_cache (session_id, answers_hash, profile_json)
      VALUES (?, ?, ?)
      ON CONFLICT(session_id, answers_hash) DO UPDATE SET 
        profile_json = excluded.profile_json,
        created_at = datetime('now')
    `).bind(sessionId, answersHash, JSON.stringify(profile)).run()
    
  } catch (error) {
    // ìºì‹œ ì €ì¥ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•ŠìŒ
  }
}

// ============================================
// Freeze v1.1: ì¦ë¶„ ì—…ì„œíŠ¸ ì‹œìŠ¤í…œ
// ============================================
// ì‹ ê·œ/ë³€ê²½ ì§ì—…ë§Œ Vectorizeì— ë°˜ì˜
// indexed_at/embedding_version ì»¬ëŸ¼ ê¸°ë°˜
// ============================================

/**
 * ì¦ë¶„ ì—…ì„œíŠ¸: ì‹ ê·œ ë˜ëŠ” ë²„ì „ ë¶ˆì¼ì¹˜ ì§ì—…ë§Œ ì¸ë±ì‹±
 */
export async function incrementalUpsertToVectorize(
  db: D1Database,
  vectorize: VectorizeIndex,
  openaiApiKey: string,
  options: {
    batchSize?: number
    maxJobs?: number
  } = {}
): Promise<{ upserted: number; errors: number; skipped: number }> {
  const { batchSize = 50, maxJobs = 500 } = options
  const CURRENT_VERSION = `JPC_${JOB_PROFILE_COMPACT_VERSION}`
  
  
  let upserted = 0
  let errors = 0
  let skipped = 0
  let offset = 0
  
  while (upserted + skipped < maxJobs) {
    // ì‹ ê·œ ë˜ëŠ” ë²„ì „ ë¶ˆì¼ì¹˜ ì§ì—… ì¡°íšŒ
    const jobs = await db.prepare(`
      SELECT id, name, merged_profile_json
      FROM jobs
      WHERE is_active = 1
        AND (indexed_at IS NULL OR embedding_version != ?)
      ORDER BY id
      LIMIT ? OFFSET ?
    `).bind(CURRENT_VERSION, batchSize, offset).all<{
      id: string
      name: string
      merged_profile_json: string | null
    }>()

    if (!jobs.results || jobs.results.length === 0) {
      break
    }

    // ì¸ë±ì‹± í…ìŠ¤íŠ¸ ìƒì„± (categoryëŠ” merged_profile_jsonì—ì„œ ì¶”ì¶œ)
    const textsForEmbedding = jobs.results.map(job => {
      let category: string | null = null
      if (job.merged_profile_json) {
        try {
          const p = JSON.parse(job.merged_profile_json)
          category = p.category || p.heroCategory || p.ë¶„ë¥˜ || null
        } catch {}
      }
      const profileData = parseJobProfileFromMergedJson(
        job.id,
        job.name,
        job.merged_profile_json,
        category
      )
      return buildJobProfileCompact(profileData)
    })

    try {
      // OpenAI Embedding ìƒì„±
      const { embeddings } = await generateOpenAIEmbedding(openaiApiKey, textsForEmbedding)

      // Vectorizeì— upsert
      const vectors = jobs.results.map((job, idx) => {
        let category = ''
        let kscoMajor: string | undefined
        let kscoMid: string | undefined
        let educationLevel: string | undefined

        if (job.merged_profile_json) {
          try {
            const profile = JSON.parse(job.merged_profile_json)
            category = profile.category || profile.heroCategory || profile.ë¶„ë¥˜ || ''
            kscoMajor = profile.ksco_major || profile.kscoMajor
            kscoMid = profile.ksco_mid || profile.kscoMid
            educationLevel = profile.education_level || profile.educationLevel
          } catch {}
        }

        return {
          id: job.id,
          values: embeddings[idx],
          metadata: {
            job_name: job.name,
            category,
            ksco_major: kscoMajor || '',
            ksco_mid: kscoMid || '',
            education_level: educationLevel || '',
            embedding_version: JOB_PROFILE_COMPACT_VERSION,
          },
        }
      })
      
      await vectorize.upsert(vectors)
      
      // D1ì— ì¸ë±ì‹± ìƒíƒœ ì—…ë°ì´íŠ¸
      for (const job of jobs.results) {
        await db.prepare(`
          UPDATE jobs 
          SET indexed_at = datetime('now'), embedding_version = ?
          WHERE id = ?
        `).bind(CURRENT_VERSION, job.id).run()
      }
      
      upserted += jobs.results.length
      
    } catch (error) {
      errors += jobs.results.length
    }
    
    offset += batchSize
    
    // Rate limit
    await new Promise(resolve => setTimeout(resolve, 1000))
  }
  
  
  return { upserted, errors, skipped }
}

/**
 * ì¸ë±ì‹±ì´ í•„ìš”í•œ ì§ì—… ìˆ˜ í™•ì¸
 */
export async function countJobsNeedingIndexing(
  db: D1Database
): Promise<{ total: number; needsIndexing: number; upToDate: number }> {
  const CURRENT_VERSION = `JPC_${JOB_PROFILE_COMPACT_VERSION}`
  
  const totalResult = await db.prepare(`
    SELECT COUNT(*) as count FROM jobs WHERE is_active = 1
  `).first<{ count: number }>()
  
  const needsResult = await db.prepare(`
    SELECT COUNT(*) as count FROM jobs 
    WHERE is_active = 1 
      AND (indexed_at IS NULL OR embedding_version != ?)
  `).bind(CURRENT_VERSION).first<{ count: number }>()
  
  const total = totalResult?.count || 0
  const needsIndexing = needsResult?.count || 0
  const upToDate = total - needsIndexing
  
  return { total, needsIndexing, upToDate }
}

/**
 * P1-2: SearchProfile ê¸°ë°˜ í›„ë³´êµ° í™•ì¥ (ìºì‹œ ì‚¬ìš©)
 * V3 Enhancement: TAG Pre-Filter ì§€ì› ì¶”ê°€
 * OpenAI Embedding ì‚¬ìš©
 * 
 * 2026-01-26: íƒœê¹… ì˜ì¡´ë„ ì™„ì „ ì œê±° (minTaggedJobs ì˜µì…˜ ì œê±°)
 */
export async function expandCandidatesV3WithCache(
  db: D1Database,
  vectorize: VectorizeIndex | undefined,
  openaiApiKey: string | undefined,
  profileInput: SearchProfileInput,
  options: {
    sessionId?: string
    targetSize?: number
    userConstraints?: UserConstraints  // Hard Constraint í•„í„°ìš©
    enableTagPreFilter?: boolean       // Pre-Filter í™œì„±í™” í”Œë˜ê·¸
    miniModule?: MiniModuleResult      // LLM ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±ìš©
  } = {}
): Promise<CandidateExpansionResult & {
  searchProfile: SearchProfile
  cacheHit: boolean
  preFilterResult?: PreFilterResult
}> {
  const { sessionId, targetSize = 500, userConstraints, enableTagPreFilter = false, miniModule } = options
  
  // P1-2: ë‹µë³€ í•´ì‹œ ê³„ì‚°
  const answersHash = computeAnswersHash(
    profileInput.narrativeFacts,
    profileInput.roundAnswers,
    profileInput.universalAnswers
  )
  
  // P1-2: ìºì‹œëœ SearchProfile í™•ì¸
  let searchProfile: SearchProfile | null = null
  let cacheHit = false
  
  if (sessionId) {
    searchProfile = await getCachedSearchProfile(db, sessionId, answersHash)
    if (searchProfile) {
      cacheHit = true
    }
  }
  
  // ìºì‹œ ë¯¸ìŠ¤ ì‹œ ìƒˆë¡œ ìƒì„±
  if (!searchProfile) {
    searchProfile = buildSearchProfile(profileInput)
    
    // P1-2: ìºì‹œ ì €ì¥
    if (sessionId) {
      await cacheSearchProfile(db, sessionId, answersHash, searchProfile)
    }
  }
  
  // ============================================
  // V3 Enhancement: TAG Pre-Filter (RAG ì „ ì ìš©)
  // ============================================
  let preFilterResult: PreFilterResult | undefined
  let excludedJobIds: Set<string> | undefined
  
  if (enableTagPreFilter && userConstraints) {
    preFilterResult = await preFilterByHardConstraints(db, userConstraints)
    excludedJobIds = preFilterResult.excludedJobIds
    
  }
  
  // í›„ë³´êµ° í™•ì¥ (Pre-Filter ê²°ê³¼ë¥¼ ì ìš©, OpenAI Embedding ì‚¬ìš©)
  const result = await expandCandidatesV3WithPreFilter(
    db,
    vectorize,
    openaiApiKey,
    searchProfile,
    { targetSize, excludedJobIds, miniModule }
  )
  
  return {
    ...result,
    searchProfile,
    cacheHit,
    preFilterResult,
  }
}

/**
 * V3 Enhancement: Pre-Filterê°€ ì ìš©ëœ í›„ë³´êµ° í™•ì¥
 * excludedJobIdsê°€ ìˆìœ¼ë©´ RAG ê²°ê³¼ì—ì„œ ì œì™¸
 * OpenAI Embedding ì‚¬ìš©
 * 
 * 2026-01-26: íƒœê¹… ì˜ì¡´ë„ ì™„ì „ ì œê±° (minTaggedJobs ì˜µì…˜ ì œê±°)
 */
async function expandCandidatesV3WithPreFilter(
  db: D1Database,
  vectorize: VectorizeIndex | undefined,
  openaiApiKey: string | undefined,
  searchProfile: SearchProfile,
  options: {
    targetSize?: number
    excludedJobIds?: Set<string>
    miniModule?: MiniModuleResult
  } = {}
): Promise<CandidateExpansionResult> {
  const { targetSize = 500, excludedJobIds, miniModule } = options
  const startTime = Date.now()

  // Vectorize ë˜ëŠ” OpenAI API í‚¤ê°€ ì—†ìœ¼ë©´ fallback
  if (!vectorize || !openaiApiKey) {
    let fallbackResult = await getFallbackCandidatesV3(db, targetSize)

    // Pre-Filter ì ìš©
    if (excludedJobIds && excludedJobIds.size > 0) {
      fallbackResult = fallbackResult.filter(c => !excludedJobIds.has(c.job_id))
    }

    return {
      candidates: fallbackResult,
      total_searched: fallbackResult.length,
      search_duration_ms: Date.now() - startTime,
      fallback_used: true,
    }
  }

  // 1. ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±: miniModule ìˆìœ¼ë©´ Multi-Query (LLM+ë¶„í• +ì°¨ì›ë³„), ì—†ìœ¼ë©´ ë‹¨ì¼ ì •ì  ì¿¼ë¦¬
  try {
    let vectorResults: VectorSearchResult[]

    if (miniModule) {
      const queries = await buildMultiSearchQueries(miniModule, openaiApiKey!)

      // 2. Multi-Query ë³‘ë ¬ ë²¡í„° ê²€ìƒ‰ (ê° topK=100, ì¤‘ë³µ ì œê±°)
      vectorResults = await searchCandidatesMultiQuery(vectorize, openaiApiKey!, queries)
    } else {
      const query = searchProfileToQuery(searchProfile)

      // 2. ë‹¨ì¼ ì¿¼ë¦¬ ë²¡í„° ê²€ìƒ‰ (ì¸í„°ë·° ëª¨ë“œ fallback)
      vectorResults = await searchCandidates(vectorize, openaiApiKey!, query, 100)
    }

    // 3. Pre-Filter ì ìš© (ì œì™¸ ëŒ€ìƒ ì œê±°)
    if (excludedJobIds && excludedJobIds.size > 0) {
      const beforeCount = vectorResults.length
      vectorResults = vectorResults.filter(r => !excludedJobIds.has(r.job_id))
    }

    // 4. targetSizeë¡œ ì œí•œ
    const candidates = vectorResults.slice(0, targetSize)

    return {
      candidates,
      total_searched: vectorResults.length,
      search_duration_ms: Date.now() - startTime,
      fallback_used: false,
    }
  } catch (vecError: any) {
    if (vecError?.message?.includes('remotely') || vecError?.message?.includes('Vectorize')) {
      let fallbackResult = await getFallbackCandidatesV3(db, targetSize)
      if (excludedJobIds && excludedJobIds.size > 0) {
        fallbackResult = fallbackResult.filter(c => !excludedJobIds.has(c.job_id))
      }
      return {
        candidates: fallbackResult,
        total_searched: fallbackResult.length,
        search_duration_ms: Date.now() - startTime,
        fallback_used: true,
      }
    }
    throw vecError
  }
}

// ============================================
// ì „ê³µ ì¶”ì²œ ì „ìš© ë²¡í„° íŒŒì´í”„ë¼ì¸
// ============================================
// ê¸°ì¡´ ì§ì—… ì¶”ì²œ í•¨ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šê³ , ì „ê³µ ì „ìš© í•¨ìˆ˜ë§Œ ì •ì˜
// major: prefix ë²¡í„°ë§Œ í•„í„°, major_attributes JOIN, ì „ê³µ ìŠ¤ì½”ì–´ë§
// ============================================

// ì „ê³µ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ íƒ€ì…
export interface MajorVectorSearchResult {
  major_id: string
  major_name: string
  score: number
  metadata?: Record<string, any>
}

export interface MajorCandidateExpansionResult {
  candidates: MajorVectorSearchResult[]
  total_searched: number
  search_duration_ms: number
  fallback_used: boolean
}

// ============================================
// ì „ê³µ ë²¡í„° ê²€ìƒ‰ (Multi-Query) â€” major: prefixë§Œ í¬í•¨
// ============================================
export async function searchMajorCandidatesMultiQuery(
  vectorize: VectorizeIndex,
  openaiApiKey: string,
  queries: string[],
  topK: number = 100
): Promise<MajorVectorSearchResult[]> {
  // 1. ë°°ì¹˜ ì„ë² ë”©
  const { embeddings } = await generateOpenAIEmbedding(openaiApiKey, queries)

  // 2. ë³‘ë ¬ Vectorize ê²€ìƒ‰
  const clampedTopK = Math.min(topK, 100)
  const searchPromises = embeddings.map(emb =>
    vectorize.query(emb, { topK: clampedTopK, returnValues: false, returnMetadata: 'none' })
  )
  const searchResults = await Promise.all(searchPromises)

  // 3. ì¤‘ë³µ ì œê±° â€” major: prefixë§Œ í¬í•¨ (ì§ì—… ê²€ìƒ‰ê³¼ ì •ë°˜ëŒ€)
  const bestScoreMap = new Map<string, number>()
  const hitCountMap = new Map<string, number>()
  for (const result of searchResults) {
    for (const match of result.matches) {
      if (!match.id.startsWith('major:')) continue  // major: prefixë§Œ í¬í•¨
      const majorId = match.id.replace('major:', '')  // prefix ì œê±°
      const existing = bestScoreMap.get(majorId)
      if (existing === undefined || match.score > existing) {
        bestScoreMap.set(majorId, match.score)
      }
      hitCountMap.set(majorId, (hitCountMap.get(majorId) || 0) + 1)
    }
  }

  // 4. ê²°ê³¼ ë³€í™˜ (íˆíŠ¸ì¹´ìš´íŠ¸ ë³´ë„ˆìŠ¤ í¬í•¨)
  return Array.from(bestScoreMap.entries())
    .map(([id, score]) => {
      const hits = hitCountMap.get(id) || 1
      const hitBonus = hits >= 3 ? Math.min(0.05, (hits - 2) * 0.015) : 0
      return { id, score: Math.min(1.0, score + hitBonus), hits }
    })
    .sort((a, b) => b.score - a.score)
    .map(({ id, score }) => ({
      major_id: id,
      major_name: id,  // ì‹¤ì œ ì´ë¦„ì€ DB ì¡°ì¸ì—ì„œ ì±„ì›€
      score,
      metadata: {} as Record<string, any>,
    }))
}

// ============================================
// ì „ê³µ LLM ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
// ============================================
const LLM_MAJOR_SEARCH_QUERY_PROMPT = `ë‹¹ì‹ ì€ í•œêµ­ ëŒ€í•™ ì „ê³µ/í•™ê³¼ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ í”„ë¡œíŒŒì¼ì„ ë³´ê³ , ì´ ì‚¬ëŒì—ê²Œ ì í•©í•  ìˆ˜ ìˆëŠ” í•œêµ­ ëŒ€í•™ ì „ê³µ(í•™ê³¼)ì„ ë‚˜ì—´í•´ì£¼ì„¸ìš”.

ê·œì¹™:
1. ì „ê³µ ì¹´í…Œê³ ë¦¬ 5~8ê°œ, êµ¬ì²´ì  ì „ê³µ/í•™ê³¼ëª… 25~30ê°œë¥¼ ë‚˜ì—´
2. í•œêµ­ì–´ë¡œ ì‘ì„± (ì˜ˆ: ì»´í“¨í„°ê³µí•™ê³¼, ê²½ì˜í•™ê³¼, ì‹¬ë¦¬í•™ê³¼)
3. ì‚¬ìš©ìì˜ í¥ë¯¸, ê°€ì¹˜ê´€, ê°•ì , ì œì•½ì¡°ê±´ì„ ëª¨ë‘ ê³ ë ¤
4. â˜…â˜…â˜… ë°˜ë“œì‹œ ì‹¤ì œ í•œêµ­ ëŒ€í•™ì— ê°œì„¤ëœ ì£¼ë¥˜ ì „ê³µ ìœ„ì£¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”!
   - ì£¼ë¥˜ ì „ê³µ = ëŒ€ë¶€ë¶„ ëŒ€í•™ì— ê°œì„¤ëœ ì¼ë°˜ì  í•™ê³¼ (ì˜ˆ: ì»´í“¨í„°ê³µí•™, ê²½ì˜í•™, ì‹¬ë¦¬í•™, ê°„í˜¸í•™, ë””ìì¸í•™, ì˜ë¬¸í•™, í™”í•™ê³µí•™ ë“±)
   - ìµœì†Œ 20ê°œëŠ” ì£¼ë¥˜ ì „ê³µì´ì–´ì•¼ í•©ë‹ˆë‹¤
   - íŠ¹ìˆ˜/í¬ì†Œ ì „ê³µì€ 5ê°œ ì´í•˜ë¡œ ì œí•œ
5. âŒ ê¸ˆì§€: ëŒ€í•™ì› ì „ìš© ì„¸ë¶€ ì „ê³µì´ë‚˜ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í•™ê³¼ëª…
6. ì œì•½ì¡°ê±´ì´ ìˆìœ¼ë©´ ê·¸ì— ë§ëŠ” í˜„ì‹¤ì ì¸ ì „ê³µ ìœ„ì£¼ë¡œ
7. ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ í•œ ì¤„ë¡œ ì¶œë ¥
8. ì„¤ëª…ì´ë‚˜ ë²ˆí˜¸ ì—†ì´ ì „ê³µëª…ë§Œ ë‚˜ì—´`

export async function buildLLMMajorSearchQuery(
  miniModule: MiniModuleResult,
  openaiApiKey: string
): Promise<string> {
  const profileParts: string[] = []

  if (miniModule.interest_top?.length) {
    profileParts.push(`í¥ë¯¸: ${miniModule.interest_top.join(', ')}`)
  }
  if (miniModule.value_top?.length) {
    profileParts.push(`ê°€ì¹˜ê´€: ${miniModule.value_top.join(', ')}`)
  }
  if (miniModule.strength_top?.length) {
    profileParts.push(`ê°•ì : ${miniModule.strength_top.join(', ')}`)
  }
  if (miniModule.workstyle_top?.length) {
    profileParts.push(`í•™ìŠµìŠ¤íƒ€ì¼: ${miniModule.workstyle_top.join(', ')}`)
  }
  if (miniModule.constraint_flags?.length) {
    profileParts.push(`ì œì•½ì¡°ê±´: ${miniModule.constraint_flags.join(', ')}`)
  }
  if (miniModule.energy_drain_flags?.length) {
    profileParts.push(`ì—ë„ˆì§€ì†Œëª¨: ${miniModule.energy_drain_flags.join(', ')}`)
  }
  if (miniModule.sacrifice_flags?.length) {
    profileParts.push(`ê°ìˆ˜ê°€ëŠ¥: ${miniModule.sacrifice_flags.join(', ')}`)
  }
  if (miniModule.persistence_anchor) {
    profileParts.push(`ì§€ì†ë™ê¸°: ${miniModule.persistence_anchor}`)
  }

  if (profileParts.length === 0) {
    throw new Error('[LLM Major Search Query] miniModuleì— í”„ë¡œíŒŒì¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤')
  }

  const userMessage = `ì‚¬ìš©ì í”„ë¡œíŒŒì¼:\n${profileParts.join('\n')}`

  let response: Response | null = null
  for (let attempt = 0; attempt < 3; attempt++) {
    try {
      response = await fetch('https://gateway.ai.cloudflare.com/v1/3587865378649966bfb0a814fce73c77/careerwiki/openai/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${openaiApiKey}`,
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',
          messages: [
            { role: 'system', content: LLM_MAJOR_SEARCH_QUERY_PROMPT },
            { role: 'user', content: userMessage },
          ],
          temperature: 0.3,
          max_tokens: 300,
        }),
      })
      if (response.ok) break
      if (response.status < 500) break // 4xxëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
    } catch (fetchError) {
      if (attempt === 2) throw fetchError
    }
    if (attempt < 2) await new Promise(r => setTimeout(r, 1000 * (attempt + 1)))
  }

  if (!response || !response.ok) {
    const body = response ? await response.text().catch(() => '') : 'no response'
    throw new Error(`[LLM Major Search Query] API error ${response?.status}: ${body.substring(0, 200)}`)
  }

  const data = await response.json() as any
  const content = data.choices?.[0]?.message?.content?.trim()

  if (!content) {
    throw new Error('[LLM Major Search Query] LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤')
  }

  return `ì í•© ì „ê³µ: ${content}`.substring(0, 500)
}

// ============================================
// ì „ê³µ ì•„í‚¤íƒ€ì… ì¿¼ë¦¬ ë¹Œë”
// í¥ë¯¸+ê°€ì¹˜ ì¡°í•©ì—ì„œ ì£¼ë¥˜ ì „ê³µ ì¿¼ë¦¬ë¥¼ ìƒì„±
// ============================================
function buildMajorArchetypeQueries(miniModule: MiniModuleResult): string[] {
  const interests = miniModule.interest_top || []
  const values = miniModule.value_top || []

  const MAJOR_ARCHETYPE_MAP: Record<string, Record<string, string>> = {
    creating: {
      autonomy: 'ì‹œê°ë””ìì¸í•™ê³¼ ì‚°ì—…ë””ìì¸í•™ê³¼ ê±´ì¶•í•™ê³¼ ë¯¸ë””ì–´í•™ê³¼ ì˜ìƒí•™ê³¼',
      growth: 'ì‚°ì—…ë””ìì¸í•™ê³¼ ë””ì§€í„¸ë¯¸ë””ì–´í•™ê³¼ ê²Œì„í•™ê³¼ ì½˜í…ì¸ í•™ê³¼',
      stability: 'ê±´ì¶•í•™ê³¼ ì‹¤ë‚´ë””ìì¸í•™ê³¼ íŒ¨ì…˜ë””ìì¸í•™ê³¼ ì‹œê°ë””ìì¸í•™ê³¼',
      income: 'ê±´ì¶•í•™ê³¼ ì‚°ì—…ë””ìì¸í•™ê³¼ ì˜ìƒí•™ê³¼',
      meaning: 'ë¬¸í™”ì½˜í…ì¸ í•™ê³¼ êµìœ¡ê³µí•™ê³¼ ë¯¸ë””ì–´ì»¤ë®¤ë‹ˆì¼€ì´ì…˜í•™ê³¼',
    },
    problem_solving: {
      autonomy: 'ì² í•™ê³¼ ê²½ì˜í•™ê³¼ ì»´í“¨í„°ê³µí•™ê³¼ ìˆ˜í•™ê³¼ ë¬¼ë¦¬í•™ê³¼',
      growth: 'ì»´í“¨í„°ê³µí•™ê³¼ ì‚°ì—…ê³µí•™ê³¼ ê²½ì˜í•™ê³¼ ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤í•™ê³¼',
      stability: 'ë²•í•™ê³¼ í–‰ì •í•™ê³¼ íšŒê³„í•™ê³¼ í†µê³„í•™ê³¼',
      income: 'ì˜í•™ê³¼ ë²•í•™ê³¼ ê²½ì˜í•™ê³¼ ì»´í“¨í„°ê³µí•™ê³¼ ê¸ˆìœµí•™ê³¼',
      meaning: 'ì‚¬íšŒí•™ê³¼ ì •ì¹˜í•™ê³¼ êµ­ì œí•™ê³¼ í™˜ê²½ê³µí•™ê³¼ êµìœ¡í•™ê³¼',
    },
    data_numbers: {
      autonomy: 'ìˆ˜í•™ê³¼ í†µê³„í•™ê³¼ ë¬¼ë¦¬í•™ê³¼ ê²½ì œí•™ê³¼ ì»´í“¨í„°ê³µí•™ê³¼',
      growth: 'ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤í•™ê³¼ ì»´í“¨í„°ê³µí•™ê³¼ ì‚°ì—…ê³µí•™ê³¼ í†µê³„í•™ê³¼',
      stability: 'íšŒê³„í•™ê³¼ í†µê³„í•™ê³¼ ì»´í“¨í„°ê³µí•™ê³¼ ê²½ì œí•™ê³¼',
      income: 'ì»´í“¨í„°ê³µí•™ê³¼ ê¸ˆìœµê³µí•™ê³¼ ê²½ì œí•™ê³¼ í†µê³„í•™ê³¼ ì˜í•™ê³¼',
      meaning: 'í™˜ê²½ê³µí•™ê³¼ ìˆ˜í•™êµìœ¡ê³¼ í†µê³„í•™ê³¼ ë³´ê±´í•™ê³¼',
    },
    helping_teaching: {
      autonomy: 'ì‹¬ë¦¬í•™ê³¼ ìƒë‹´í•™ê³¼ êµìœ¡í•™ê³¼ ì‚¬íšŒë³µì§€í•™ê³¼',
      growth: 'êµìœ¡í•™ê³¼ ì‹¬ë¦¬í•™ê³¼ ê°„í˜¸í•™ê³¼ ì–¸ì–´ì¹˜ë£Œí•™ê³¼',
      stability: 'ê°„í˜¸í•™ê³¼ ì‚¬íšŒë³µì§€í•™ê³¼ ìœ ì•„êµìœ¡ê³¼ ì´ˆë“±êµìœ¡ê³¼ íŠ¹ìˆ˜êµìœ¡ê³¼',
      income: 'ì˜í•™ê³¼ ì¹˜ì˜í•™ê³¼ ì•½í•™ê³¼ ê°„í˜¸í•™ê³¼ ë¬¼ë¦¬ì¹˜ë£Œí•™ê³¼',
      meaning: 'ì‚¬íšŒë³µì§€í•™ê³¼ êµìœ¡í•™ê³¼ ìƒë‹´í•™ê³¼ ì‹ í•™ê³¼ ê°„í˜¸í•™ê³¼',
    },
    tech: {
      autonomy: 'ì»´í“¨í„°ê³µí•™ê³¼ ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ì „ìê³µí•™ê³¼ ì •ë³´ë³´ì•ˆí•™ê³¼',
      growth: 'ì»´í“¨í„°ê³µí•™ê³¼ ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤í•™ê³¼ ë¡œë´‡ê³µí•™ê³¼',
      stability: 'ì „ê¸°ê³µí•™ê³¼ ì „ìê³µí•™ê³¼ ì»´í“¨í„°ê³µí•™ê³¼ ê¸°ê³„ê³µí•™ê³¼ í† ëª©ê³µí•™ê³¼',
      income: 'ì»´í“¨í„°ê³µí•™ê³¼ ì „ìê³µí•™ê³¼ í™”í•™ê³µí•™ê³¼ ì˜ê³µí•™ê³¼',
      meaning: 'í™˜ê²½ê³µí•™ê³¼ ë°”ì´ì˜¤ê³µí•™ê³¼ ì˜ê³µí•™ê³¼ ì—ë„ˆì§€ê³µí•™ê³¼',
    },
    research: {
      autonomy: 'ë¬¼ë¦¬í•™ê³¼ í™”í•™ê³¼ ìƒëª…ê³¼í•™ê³¼ ìˆ˜í•™ê³¼ ì²œë¬¸í•™ê³¼',
      growth: 'ìƒëª…ê³µí•™ê³¼ ì‹ ì†Œì¬ê³µí•™ê³¼ ë‡Œê³¼í•™ê³¼',
      stability: 'ì•½í•™ê³¼ í™”í•™ê³¼ ìƒëª…ê³¼í•™ê³¼ ìˆ˜í•™ê³¼',
      income: 'ì˜í•™ê³¼ ì•½í•™ê³¼ ì¹˜ì˜í•™ê³¼ í•œì˜í•™ê³¼',
      meaning: 'ìƒëª…ê³¼í•™ê³¼ í™˜ê²½ê³¼í•™ê³¼ í•´ì–‘í•™ê³¼ ì²œë¬¸í•™ê³¼',
    },
    organizing: {
      autonomy: 'ê²½ì˜í•™ê³¼ í–‰ì •í•™ê³¼ êµ­ì œí•™ê³¼ ì •ì¹˜ì™¸êµí•™ê³¼',
      growth: 'ê²½ì˜í•™ê³¼ êµ­ì œí†µìƒí•™ê³¼ ë¯¸ë””ì–´í•™ê³¼ ì‚°ì—…ê³µí•™ê³¼',
      stability: 'í–‰ì •í•™ê³¼ ê²½ì˜í•™ê³¼ íšŒê³„í•™ê³¼ ë²•í•™ê³¼ ì„¸ë¬´í•™ê³¼',
      income: 'ê²½ì˜í•™ê³¼ ê¸ˆìœµí•™ê³¼ ë²•í•™ê³¼ íšŒê³„í•™ê³¼',
      meaning: 'í–‰ì •í•™ê³¼ ì‚¬íšŒí•™ê³¼ êµ­ì œí•™ê³¼ ë„ì‹œê³„íší•™ê³¼',
    },
    influencing: {
      autonomy: 'ê´‘ê³ í™ë³´í•™ê³¼ ë¯¸ë””ì–´í•™ê³¼ ê²½ì˜í•™ê³¼ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜í•™ê³¼',
      growth: 'ê²½ì˜í•™ê³¼ ë¯¸ë””ì–´í•™ê³¼ ê´‘ê³ í™ë³´í•™ê³¼',
      stability: 'ê²½ì˜í•™ê³¼ í–‰ì •í•™ê³¼ ë²•í•™ê³¼ ë¬´ì—­í•™ê³¼',
      income: 'ê²½ì˜í•™ê³¼ ë²•í•™ê³¼ ê¸ˆìœµí•™ê³¼ ì˜í•™ê³¼',
      meaning: 'ì‚¬íšŒí•™ê³¼ êµ­ì œí•™ê³¼ ì •ì¹˜ì™¸êµí•™ê³¼ ì‹ ë¬¸ë°©ì†¡í•™ê³¼',
    },
  }

  const queries: string[] = []
  for (const interest of interests) {
    const valueMap = MAJOR_ARCHETYPE_MAP[interest]
    if (!valueMap) continue
    for (const value of values) {
      const query = valueMap[value]
      if (query && !queries.includes(query)) {
        queries.push(query)
      }
    }
  }

  return queries.slice(0, 3)
}

// ============================================
// Multi-Search ì¿¼ë¦¬ ìƒì„± (ì „ê³µìš©)
// ============================================
export async function buildMultiSearchQueriesForMajor(
  miniModule: MiniModuleResult,
  openaiApiKey: string
): Promise<string[]> {
  // 1. LLM ì¿¼ë¦¬ (ì¢…í•© ì „ê³µëª… ë¦¬ìŠ¤íŠ¸)
  const llmQuery = await buildLLMMajorSearchQuery(miniModule, openaiApiKey)

  // 2. LLM ì¶œë ¥ì„ 3-5ê°œì”© ë¶„í• 
  const rawContent = llmQuery.replace(/^ì í•© ì „ê³µ:\s*/, '')
  const majorNames = rawContent.split(/[,ï¼Œã€]/).map(s => s.trim()).filter(Boolean)
  const chunkSize = Math.max(3, Math.ceil(majorNames.length / 5))
  const subQueries: string[] = []
  for (let i = 0; i < majorNames.length; i += chunkSize) {
    subQueries.push(majorNames.slice(i, i + chunkSize).join(', '))
  }

  // 3. ì°¨ì›ë³„ í‚¤ì›Œë“œ ì¿¼ë¦¬ (ì „ê³µ ë„ë©”ì¸)
  const INTEREST_MAJOR_KR: Record<string, string> = {
    creating: 'ë””ìì¸ ë¯¸ìˆ  ê±´ì¶• ì˜ìƒ ì°½ì‘',
    problem_solving: 'ê³µí•™ ê³¼í•™ ë¶„ì„ ì—°êµ¬ ì»¨ì„¤íŒ…',
    data_numbers: 'ìˆ˜í•™ í†µê³„ ë°ì´í„° ê²½ì œ íšŒê³„',
    helping_teaching: 'êµìœ¡ ì‹¬ë¦¬ ë³µì§€ ìƒë‹´ ê°„í˜¸',
    organizing: 'ê²½ì˜ í–‰ì • ê¸°íš ê´€ë¦¬',
    influencing: 'ê´‘ê³  í™ë³´ ë§ˆì¼€íŒ… ë¯¸ë””ì–´ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜',
    tech: 'IT ì»´í“¨í„° ì „ì ê¸°ê³„ ì†Œí”„íŠ¸ì›¨ì–´',
    routine: 'í–‰ì • ì‚¬ë¬´ íšŒê³„ ì„¸ë¬´',
    research: 'ì—°êµ¬ ê³¼í•™ ë¬¼ë¦¬ í™”í•™ ìƒëª…',
    design: 'ë””ìì¸ ì‹œê° ì‚°ì—… ê±´ì¶• íŒ¨ì…˜',
    art: 'ë¯¸ìˆ  ìŒì•… ì˜í™” ì—°ê·¹ ë¬´ìš©',
  }
  const STRENGTH_MAJOR_KR: Record<string, string> = {
    analytical: 'ë¶„ì„ ë…¼ë¦¬ ìˆ˜í•™ ê³¼í•™ ì—°êµ¬',
    creative: 'ì°½ì˜ ë””ìì¸ ì˜ˆìˆ  ê¸°íš',
    communication: 'ì†Œí†µ ë°œí‘œ í† ë¡  ì–¸ì–´',
    structured_execution: 'ì‹¤í—˜ ì‹¤ìŠµ ì œì‘ êµ¬í˜„',
    persistence: 'ì—°êµ¬ ì‹¬í™” ì „ë¬¸',
    fast_learning: 'ë‹¤í•™ì œ ìœµí•© ë³µìˆ˜ì „ê³µ',
  }
  const VALUE_MAJOR_KR: Record<string, string> = {
    growth: 'ì„±ì¥ì‚°ì—… ì‹ ê¸°ìˆ  ë¯¸ë˜ìœ ë§',
    stability: 'ì•ˆì • ì·¨ì—…ë¥  ê³µë¬´ì› ì „ë¬¸ì§',
    income: 'ê³ ì†Œë“ ì „ë¬¸ì§ ê¸ˆìœµ ì˜í•™',
    autonomy: 'ììœ  ì—°êµ¬ ìê¸°ì£¼ë„',
    meaning: 'ì‚¬íšŒê³µí—Œ êµìœ¡ ë³µì§€ í™˜ê²½',
    recognition: 'ì „ë¬¸ì„± ëª…ì„± í•™ìˆ ',
  }

  const dimensionQueries: string[] = []
  if (miniModule.interest_top?.length) {
    const kr = miniModule.interest_top.map((t: string) => INTEREST_MAJOR_KR[t] || t).join(' ')
    dimensionQueries.push(`${kr} ê´€ë ¨ ì „ê³µ í•™ê³¼`)
  }
  if (miniModule.strength_top?.length) {
    const kr = miniModule.strength_top.map((t: string) => STRENGTH_MAJOR_KR[t] || t).join(' ')
    dimensionQueries.push(`${kr} ì—­ëŸ‰ì´ í•„ìš”í•œ ì „ê³µ í•™ê³¼`)
  }
  if (miniModule.value_top?.length) {
    const kr = miniModule.value_top.map((t: string) => VALUE_MAJOR_KR[t] || t).join(' ')
    dimensionQueries.push(`${kr} ì „ê³µ í•™ê³¼`)
  }

  // 4. ì•„í‚¤íƒ€ì… ì¿¼ë¦¬ (í¥ë¯¸+ê°€ì¹˜ ì¡°í•© â†’ ì£¼ë¥˜ ì „ê³µ)
  const archetypeQueries = buildMajorArchetypeQueries(miniModule)

  // 5. ê²°í•©
  return [
    llmQuery,
    ...subQueries,
    ...dimensionQueries,
    ...archetypeQueries,
  ]
}

// ============================================
// ì „ê³µ ë²¡í„° ê²°ê³¼ â†’ ScoredMajor ë³€í™˜
// major_attributes + majors í…Œì´ë¸” JOIN
// ============================================
export async function vectorResultsToScoredMajors(
  db: D1Database,
  vectorResults: MajorVectorSearchResult[],
  miniModule?: any
): Promise<ScoredMajor[]> {
  if (vectorResults.length === 0) return []

  const BATCH_SIZE = 100
  const majorIds = vectorResults.map(v => v.major_id)

  // 1. major_attributes + majors ì¡°ì¸ ì¡°íšŒ (ë°°ì¹˜ ë³‘ë ¬)
  const batches: string[][] = []
  for (let i = 0; i < majorIds.length; i += BATCH_SIZE) {
    batches.push(majorIds.slice(i, i + BATCH_SIZE))
  }

  const batchPromises = batches.map(batchIds => {
    const placeholders = batchIds.map(() => '?').join(',')
    return db.prepare(`
      SELECT
        ma.major_id, ma.major_name,
        m.slug, m.image_url, m.merged_profile_json,
        ma.academic_rigor, ma.math_intensity, ma.creativity, ma.social_interaction,
        ma.lab_practical, ma.reading_writing,
        ma.career_breadth, ma.career_income_potential, ma.employment_rate,
        ma.competition_level, ma.growth_outlook, ma.stability, ma.autonomy, ma.teamwork,
        ma.field_category, ma.degree_level,
        ma.prerequisite_subjects, ma.related_careers, ma.key_skills, ma.description
      FROM major_attributes ma
      LEFT JOIN majors m ON ma.major_id = m.id
      WHERE ma.major_id IN (${placeholders})
    `).bind(...batchIds).all<{
      major_id: number
      major_name: string
      slug: string | null
      image_url: string | null
      merged_profile_json: string | null
      academic_rigor: number
      math_intensity: number
      creativity: number
      social_interaction: number
      lab_practical: number
      reading_writing: number
      career_breadth: number
      career_income_potential: number
      employment_rate: number
      competition_level: number
      growth_outlook: number
      stability: number
      autonomy: number
      teamwork: number
      field_category: string
      degree_level: string
      prerequisite_subjects: string
      related_careers: string
      key_skills: string
      description: string | null
    }>()
  })

  const batchResults = await Promise.all(batchPromises)
  const allAttributeResults: any[] = []
  for (const batchResult of batchResults) {
    if (batchResult.results) {
      allAttributeResults.push(...batchResult.results)
    }
  }

  const attributesMap = new Map(
    allAttributeResults.map(row => [String(row.major_id), row])
  )

  // 2. major_attributesì— ì—†ëŠ” ì „ê³µ â†’ majors í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì¡°íšŒ (fallback)
  const missingMajorIds = majorIds.filter(id => !attributesMap.has(id))
  if (missingMajorIds.length > 0) {
    const missingBatches: string[][] = []
    for (let i = 0; i < missingMajorIds.length; i += BATCH_SIZE) {
      missingBatches.push(missingMajorIds.slice(i, i + BATCH_SIZE))
    }

    const fallbackPromises = missingBatches.map(batchIds => {
      const placeholders = batchIds.map(() => '?').join(',')
      return db.prepare(`
        SELECT id as major_id, name as major_name, slug, image_url, merged_profile_json
        FROM majors
        WHERE id IN (${placeholders})
      `).bind(...batchIds).all<{
        major_id: number
        major_name: string
        slug: string | null
        image_url: string | null
        merged_profile_json: string | null
      }>()
    })

    const fallbackResults = await Promise.all(fallbackPromises)
    for (const fallbackResult of fallbackResults) {
      if (fallbackResult.results) {
        for (const row of fallbackResult.results) {
          attributesMap.set(String(row.major_id), {
            ...row,
            academic_rigor: 50, math_intensity: 50, creativity: 50, social_interaction: 50,
            lab_practical: 50, reading_writing: 50,
            career_breadth: 50, career_income_potential: 50, employment_rate: 50,
            competition_level: 50, growth_outlook: 50, stability: 50, autonomy: 50, teamwork: 50,
            field_category: 'general', degree_level: 'bachelor',
            prerequisite_subjects: '[]', related_careers: '[]', key_skills: '[]',
            description: null,
            _from_majors_fallback: true,
          })
        }
      }
    }
  }

  // 3. ScoredMajor ìƒì„±
  const vectorScoreMap = new Map(
    vectorResults.map(vr => [vr.major_id, vr.score])
  )

  return vectorResults.map(vr => {
    const attrs = attributesMap.get(vr.major_id) as any
    const vectorScore = vectorScoreMap.get(vr.major_id) || 0

    if (attrs) {
      const personalized = calculateMajorPersonalizedBaseScores(attrs, miniModule)
      const vectorBonus = Math.round(vectorScore * 10)
      const baseLike = Math.min(100, personalized.like + vectorBonus)
      const baseCan = Math.min(100, personalized.can + Math.round(vectorBonus * 0.5))
      const baseRisk = 10

      // ë¯¸íƒœê¹… ì „ê³µ í˜ë„í‹°
      const isUntagged = !!(attrs as any)?._from_majors_fallback
      const untaggedPenalty = isUntagged ? -25 : 0

      // ì „ê³µ ì„¤ëª… ì¶”ì¶œ
      let majorDescription: string | undefined
      if (attrs.description) {
        majorDescription = attrs.description
      } else if (attrs.merged_profile_json) {
        try {
          const profile = JSON.parse(attrs.merged_profile_json)
          majorDescription = (
            profile.overview?.summary || profile.summary || profile.ìš”ì•½ || profile.description || ''
          ).substring(0, 200) || undefined
        } catch {}
      }

      return {
        entity_type: 'major' as const,
        major_id: String(attrs.major_id),
        major_name: attrs.major_name,
        slug: attrs.slug || undefined,
        image_url: attrs.image_url || undefined,
        major_description: majorDescription,
        base_like: baseLike,
        base_can: baseCan,
        base_risk: baseRisk,
        like_score: baseLike,
        can_score: baseCan,
        risk_penalty: baseRisk,
        final_score: Math.round(0.55 * baseLike + 0.45 * baseCan - baseRisk) + untaggedPenalty,
        field_category: attrs.field_category || 'general',
        tag_source: (isUntagged ? 'untagged' : 'tagged') as 'tagged' | 'untagged',
        attributes: {
          academic_rigor: attrs.academic_rigor,
          math_intensity: attrs.math_intensity,
          creativity: attrs.creativity,
          social_interaction: attrs.social_interaction,
          lab_practical: attrs.lab_practical,
          reading_writing: attrs.reading_writing,
          career_breadth: attrs.career_breadth,
          career_income_potential: attrs.career_income_potential,
          employment_rate: attrs.employment_rate,
          competition_level: attrs.competition_level,
          growth_outlook: attrs.growth_outlook,
          stability: attrs.stability,
          autonomy: attrs.autonomy,
          teamwork: attrs.teamwork,
          field_category: attrs.field_category,
          degree_level: attrs.degree_level,
        } as MajorAttributes,
      } satisfies ScoredMajor
    }

    // ì†ì„± ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’
    const baseLike = Math.round(50 + vr.score * 20)
    return {
      entity_type: 'major' as const,
      major_id: vr.major_id,
      major_name: vr.major_name,
      slug: undefined,
      image_url: undefined,
      major_description: undefined,
      base_like: baseLike,
      base_can: 50,
      base_risk: 15,
      like_score: baseLike,
      can_score: 50,
      risk_penalty: 15,
      final_score: Math.round(baseLike + 50 - 15),
      field_category: 'general',
      tag_source: 'untagged' as const,
      attributes: {
        academic_rigor: 50, math_intensity: 50, creativity: 50, social_interaction: 50,
        lab_practical: 50, reading_writing: 50,
        career_breadth: 50, career_income_potential: 50, employment_rate: 50,
        competition_level: 50, growth_outlook: 50, stability: 50, autonomy: 50, teamwork: 50,
        field_category: 'general', degree_level: 'bachelor',
      } as MajorAttributes,
    } satisfies ScoredMajor
  })
}

// ============================================
// V3: Fallback â€” majors í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì¡°íšŒ (íƒœê¹… ë¬´ê´€)
// ============================================
async function getFallbackMajorCandidatesV3(
  db: D1Database,
  limit: number
): Promise<MajorVectorSearchResult[]> {
  const result = await db.prepare(`
    SELECT id, name
    FROM majors
    WHERE name IS NOT NULL AND merged_profile_json IS NOT NULL
    ORDER BY RANDOM()
    LIMIT ?
  `).bind(limit).all<{ id: string; name: string }>()

  return (result.results || []).map((row, idx) => ({
    major_id: String(row.id),
    major_name: row.name,
    score: 0.5 - (idx * 0.0001),
    metadata: { source: 'fallback_v3' },
  }))
}

// ============================================
// V3: SearchProfile ê¸°ë°˜ ì „ê³µ í›„ë³´êµ° í™•ì¥
// ============================================
export async function expandCandidatesV3ForMajors(
  db: D1Database,
  vectorize: VectorizeIndex | undefined,
  openaiApiKey: string | undefined,
  searchProfile: SearchProfile,
  options: {
    targetSize?: number
    miniModule?: MiniModuleResult
  } = {}
): Promise<MajorCandidateExpansionResult> {
  const { targetSize = 500, miniModule } = options
  const startTime = Date.now()

  // Vectorize ë˜ëŠ” OpenAI API í‚¤ê°€ ì—†ìœ¼ë©´ fallback
  if (!vectorize || !openaiApiKey) {
    const fallbackResult = await getFallbackMajorCandidatesV3(db, targetSize)
    return {
      candidates: fallbackResult,
      total_searched: fallbackResult.length,
      search_duration_ms: Date.now() - startTime,
      fallback_used: true,
    }
  }

  // miniModule í•„ìˆ˜
  if (!miniModule) {
    throw new Error('[V3 Major Vectorize] miniModuleì´ í•„ìˆ˜ì…ë‹ˆë‹¤ - LLM ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±ì— í•„ìš”')
  }

  try {
    const queries = await buildMultiSearchQueriesForMajor(miniModule, openaiApiKey)
    const vectorResults = await searchMajorCandidatesMultiQuery(vectorize, openaiApiKey, queries)

    const candidates = vectorResults.map(vr => ({
      ...vr,
      metadata: { ...vr.metadata, source: 'vector_search', query_source: 'llm' },
    }))

    return {
      candidates,
      total_searched: vectorResults.length,
      search_duration_ms: Date.now() - startTime,
      fallback_used: false,
    }
  } catch (vecError: any) {
    // LLM/Vectorize ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ DB fallback
    console.error('[V3 Major Vectorize] ê²€ìƒ‰ ì‹¤íŒ¨, DB fallback ì‚¬ìš©:', vecError?.message)
    const fallbackResult = await getFallbackMajorCandidatesV3(db, targetSize)
    return {
      candidates: fallbackResult,
      total_searched: fallbackResult.length,
      search_duration_ms: Date.now() - startTime,
      fallback_used: true,
    }
  }
}
