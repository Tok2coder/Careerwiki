// CareerWiki AI Analyzer - Vectorize Pipeline
// Version: v1.1.0 (Freeze v1.1)
//
// ============================================
// ğŸš¨ [ë¶ˆë³€ ì›ì¹™] Vectorize ì—­í•  ê²½ê³„ (ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€)
// ============================================
// 1. Vectorize scoreëŠ” ì¶”ì²œ ì ìˆ˜ì— ì§ì ‘ ì‚¬ìš© ê¸ˆì§€
//    - ìœ ì‚¬ë„ ì ìˆ˜ëŠ” í›„ë³´ í’€ í•„í„°ìš©ì¼ ë¿, ë­í‚¹ì— ì˜í–¥ ì—†ìŒ
//
// 2. ìš©ë„ ì œí•œ: ì§ˆë¬¸ ì„¤ê³„ / í›„ë³´ í’€ ìƒì„± / ì„¤ëª… ë³´ì¡°
//    - Interview Mode: QSP ìƒì„± (ì§ì—…ëª… ë¹„ë…¸ì¶œ)
//    - Recommendation Mode: í›„ë³´ í’€ TopK=800
//
// 3. ë­í‚¹ ê²°ì •: LLM Judgeë§Œ ë‹´ë‹¹
//    - ìµœì¢… ì¶”ì²œ ìˆœìœ„ëŠ” Fit/Desire/Feasibility ì ìˆ˜ë¡œ ê²°ì •
//    - "500ê°œë§Œ ë³´ë©´ ì¶©ë¶„"ì´ë¼ëŠ” ìœ í˜¹ì— ë„˜ì–´ê°€ì§€ ë§ ê²ƒ
// ============================================
//
// âš ï¸ ì„¤ê³„ ì›ì¹™
// ============================================
// 1. í›„ë³´êµ° í™•ì¥: 80ê°œ â†’ 500-1000ê°œ
// 2. íƒœê¹… ëŒ€ì‹  ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ì»¤ë²„ë¦¬ì§€ í™•ë³´
// 3. Evidence Generatorì™€ í†µí•©
// ============================================

import type { D1Database, VectorizeIndex, Ai } from '@cloudflare/workers-types'
import { preFilterByHardConstraints, type PreFilterResult } from './tag-filter'
import type { UserConstraints } from './types'
import type { MiniModuleResult } from './mini-module-questions'
import { TOKEN_TO_ENGLISH } from './mini-module-questions'
import { generateOpenAIEmbedding, OPENAI_EMBEDDING_DIMENSIONS } from './openai-client'
import { calculatePersonalizedBaseScores } from './personalized-scoring'
import { 
  JOB_PROFILE_COMPACT_VERSION, 
  getFullEmbeddingVersion 
} from '../../constants/embedding-versions'

// ============================================
// íƒ€ì… ì •ì˜
// ============================================

export interface VectorizeJobData {
  job_id: string
  job_name: string
  description: string
  category?: string
  tags?: string[]
}

export interface VectorSearchResult {
  job_id: string
  job_name: string
  score: number
  metadata?: Record<string, any>
}

export interface CandidateExpansionResult {
  candidates: VectorSearchResult[]
  total_searched: number
  search_duration_ms: number
  fallback_used: boolean
}

// ============================================
// ì„ë² ë”© ëª¨ë¸ ì„¤ì • (OpenAI text-embedding-3-small)
// ============================================
// ê¸°ì¡´: '@cf/baai/bge-base-en-v1.5' (768ì°¨ì›, ì˜ì–´ ê¸°ë°˜)
// ë³€ê²½: OpenAI 'text-embedding-3-small' (1536ì°¨ì›, ë‹¤êµ­ì–´ ì§€ì›)
const VECTOR_DIMENSIONS = OPENAI_EMBEDDING_DIMENSIONS  // 1536

// ============================================
// ë¯¸ë‹ˆëª¨ë“ˆ ê¸°ë°˜ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (ì˜ì–´ í‚¤ì›Œë“œ ë§¤í•‘)
// ============================================
export function buildSearchQueryFromMiniModule(
  miniModule: MiniModuleResult
): string {
  const parts: string[] = []
  
  // í¥ë¯¸ í† í° â†’ ì˜ì–´ í‚¤ì›Œë“œ
  if (miniModule.interest_top.length > 0) {
    const interestKeywords = miniModule.interest_top
      .map(token => TOKEN_TO_ENGLISH[token] || token)
      .join(' ')
    parts.push(`interest: ${interestKeywords}`)
  }
  
  // ê°€ì¹˜ í† í° â†’ ì˜ì–´ í‚¤ì›Œë“œ
  if (miniModule.value_top.length > 0) {
    const valueKeywords = miniModule.value_top
      .map(token => TOKEN_TO_ENGLISH[token] || token)
      .join(' ')
    parts.push(`value: ${valueKeywords}`)
  }
  
  // ê°•ì  í† í° â†’ ì˜ì–´ í‚¤ì›Œë“œ
  if (miniModule.strength_top.length > 0) {
    const strengthKeywords = miniModule.strength_top
      .map(token => TOKEN_TO_ENGLISH[token] || token)
      .join(' ')
    parts.push(`strength: ${strengthKeywords}`)
  }
  
  // ì œì•½ í”Œë˜ê·¸ â†’ ì˜ì–´ í‚¤ì›Œë“œ (í”¼í•´ì•¼ í•  ê²ƒ)
  if (miniModule.constraint_flags.length > 0) {
    const constraintKeywords = miniModule.constraint_flags
      .map(token => TOKEN_TO_ENGLISH[token] || token)
      .join(' ')
    parts.push(`avoid: ${constraintKeywords}`)
  }
  
  // ì˜ì–´ ì¿¼ë¦¬ ìƒì„± (BGE ëª¨ë¸ì´ ì˜ì–´ ê¸°ë°˜)
  if (parts.length === 0) {
    return 'career recommendation job matching'
  }

  return parts.join(' ').substring(0, 500)
}

/**
 * MiniModuleResult â†’ SearchProfile ë³€í™˜
 * E2E í…ŒìŠ¤íŠ¸ ë° /v3/recommendì—ì„œ ë²¡í„° ê²€ìƒ‰ ì‹œ ì‚¬ìš©
 */
export function buildSearchProfileFromMiniModule(
  miniModule: MiniModuleResult
): SearchProfile {
  // í† í°ì„ í•œêµ­ì–´ë¡œ ë³€í™˜í•˜ëŠ” ë§µ (ë²¡í„° ê²€ìƒ‰ìš©)
  const interestKorean: Record<string, string> = {
    data_numbers: 'ë°ì´í„° ë¶„ì„ í†µê³„',
    problem_solving: 'ë¬¸ì œ í•´ê²° ë…¼ë¦¬',
    research: 'ì—°êµ¬ ì¡°ì‚¬ ë¶„ì„',
    tech: 'ê¸°ìˆ  ê°œë°œ IT',
    creative: 'ì°½ì‘ ë””ìì¸ ì˜ˆìˆ ',
    helping: 'ë„ì›€ ìƒë‹´ ë³µì§€ ì„œë¹„ìŠ¤ ëŒë´„',
    helping_teaching: 'ë„ì›€ ê°€ë¥´ì¹¨ ìƒë‹´ êµìœ¡ ë³µì§€',
    organizing: 'ì¡°ì§ ê´€ë¦¬ í–‰ì • ì‚¬ë¬´ ê²½ì˜ì§€ì›',
    routine: 'í–‰ì • ì‚¬ë¬´ ê³µë¬´ì› ì •í˜•í™”ëœ ì—…ë¬´',
    design: 'ë””ìì¸ ì‹œê° ê·¸ë˜í”½',
    art: 'ì˜ˆìˆ  ì°½ì‘ ë¬¸í™”',
  }

  const valueKorean: Record<string, string> = {
    autonomy: 'ììœ¨ì„± ììœ  ë…ë¦½',
    growth: 'ì„±ì¥ ë°œì „ ê²½ë ¥ê°œë°œ',
    expertise: 'ì „ë¬¸ì„± ìˆ™ë ¨ ì „ë¬¸ê°€',
    stability: 'ì•ˆì • ì •ê·œì§ ê³µë¬´ì› ê³µê³µê¸°ê´€',
    wlb: 'ì›Œë¼ë°¸ ê· í˜• ì •ì‹œí‡´ê·¼',
    income: 'ì†Œë“ ì—°ë´‰ ë³´ìˆ˜',
    creativity: 'ì°½ì˜ì„± ì°½ì‘',
    recognition: 'ì¸ì • ì„±ì·¨',
    meaning: 'ì˜ë¯¸ ë³´ëŒ ì‚¬íšŒê³µí—Œ',
  }

  const strengthKorean: Record<string, string> = {
    analytical: 'ë¶„ì„ë ¥ ë…¼ë¦¬ ë°ì´í„°',
    fast_learning: 'ë¹ ë¥¸ í•™ìŠµ ìŠµë“',
    persistence: 'ëˆê¸° ì¸ë‚´ ê¾¸ì¤€í•¨',
    communication: 'ì†Œí†µ ëŒ€ì¸ê´€ê³„ ìƒë‹´ ê³ ê°ì‘ëŒ€',
    creative: 'ì°½ì˜ì„± ë…ì°½',
    structured_execution: 'ì²´ê³„ì  ì‹¤í–‰ ì—…ë¬´ì²˜ë¦¬ ì‚¬ë¬´',
    leadership: 'ë¦¬ë”ì‹­ í†µì†” ê´€ë¦¬',
    empathy: 'ê³µê° ì´í•´ ëŒë´„',
    adaptability: 'ì ì‘ë ¥ ìœ ì—°',
    detail_oriented: 'ê¼¼ê¼¼í•¨ ì •ë°€ ê²€ìˆ˜',
  }

  // desiredThemes: í¥ë¯¸ + ê°€ì¹˜
  const desiredThemes: string[] = [
    ...miniModule.interest_top.map(t => interestKorean[t] || t),
    ...miniModule.value_top.map(t => valueKorean[t] || t),
  ]

  // strengthsHypothesis: ê°•ì 
  const strengthsHypothesis: string[] = miniModule.strength_top.map(t => strengthKorean[t] || t)

  // hardConstraints: ì œì•½ í”Œë˜ê·¸
  const hardConstraints: string[] = miniModule.constraint_flags || []

  // keywords: ê²€ìƒ‰ í‚¤ì›Œë“œ (ì˜ì–´ + í•œêµ­ì–´ í˜¼í•©, ê°€ì¹˜ í•œêµ­ì–´ í¬í•¨)
  const keywords: string[] = [
    ...miniModule.interest_top.map(t => TOKEN_TO_ENGLISH[t] || t),
    ...miniModule.strength_top.map(t => TOKEN_TO_ENGLISH[t] || t),
    ...miniModule.interest_top.map(t => interestKorean[t] || t),
    ...miniModule.value_top.map(t => valueKorean[t] || t),
  ]

  // dislikedThemes: ì—ë„ˆì§€ ì†Œëª¨ í”Œë˜ê·¸ì—ì„œ ì¶”ì¶œ
  const energyDrainKorean: Record<string, string> = {
    people_drain: 'ì‚¬ëŒ ìƒí˜¸ì‘ìš© ë§ì€ ì¼',
    routine_drain: 'ë°˜ë³µ ë‹¨ìˆœ ì‘ì—…',
    time_pressure_drain: 'ì‹œê°„ ì••ë°• ë§ˆê°',
    bureaucracy_drain: 'ê´€ë£Œì  ì ˆì°¨',
    conflict_drain: 'ê°ˆë“± ì¶©ëŒ',
    multitask_drain: 'ë©€í‹°íƒœìŠ¤í‚¹',
    uncertainty_drain: 'ë¶ˆí™•ì‹¤ì„±',
  }
  const dislikedThemes: string[] = (miniModule.energy_drain_flags || []).map(t => energyDrainKorean[t] || t)

  return {
    desiredThemes,
    dislikedThemes,
    strengthsHypothesis,
    environmentPreferences: miniModule.workstyle_top || [],
    hardConstraints,
    riskSignals: [],
    keywords: [...new Set(keywords)],  // ì¤‘ë³µ ì œê±°
  }
}

// ============================================
// P2: Can/Like ê°€ì¤‘ ê²€ìƒ‰ ì¿¼ë¦¬ ì‹œìŠ¤í…œ
// ê²€ì¦ëœ Canì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬
// ============================================
export interface WeightedSearchQuery {
  primary_keywords: string[]      // ê°€ì¤‘ì¹˜ ë†’ì€ í‚¤ì›Œë“œ (ê²€ì¦ëœ Can + Like)
  secondary_keywords: string[]    // ì¼ë°˜ í‚¤ì›Œë“œ
  exclude_keywords: string[]      // ì œì™¸ í‚¤ì›Œë“œ (Risk)
  boost_weights: Map<string, number>
}

/**
 * Can ê²€ì¦ ê²°ê³¼ë¥¼ ë°˜ì˜í•œ ê°€ì¤‘ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
 * - ê²€ì¦ëœ ê°•ì ì€ primary_keywordsë¡œ ìš°ì„  ì²˜ë¦¬
 * - ë¯¸ê²€ì¦ ê°•ì ì€ secondary_keywordsë¡œ ì²˜ë¦¬
 */
export function buildWeightedSearchQuery(
  miniModule: MiniModuleResult,
  canValidationResults?: Record<string, { canBoost: number }>
): WeightedSearchQuery {
  const primary: string[] = []
  const secondary: string[] = []
  const exclude: string[] = []
  const weights = new Map<string, number>()

  // 1. Like í‚¤ì›Œë“œ (interest + value)
  for (const token of miniModule.interest_top || []) {
    const keyword = TOKEN_TO_ENGLISH[token]
    if (keyword) {
      secondary.push(keyword)
      weights.set(keyword, 1.0)
    }
  }

  for (const token of miniModule.value_top || []) {
    const keyword = TOKEN_TO_ENGLISH[token]
    if (keyword) {
      secondary.push(keyword)
      weights.set(keyword, 0.8)  // ê°€ì¹˜ëŠ” ê´€ì‹¬ë³´ë‹¤ ì•½ê°„ ë‚®ì€ ê°€ì¤‘ì¹˜
    }
  }

  // 2. Can í‚¤ì›Œë“œ (ê²€ì¦ëœ ê°•ì  ìš°ì„ )
  for (const token of miniModule.strength_top || []) {
    const keyword = TOKEN_TO_ENGLISH[token]
    if (!keyword) continue

    // Can ê²€ì¦ ê²°ê³¼ í™•ì¸
    const validationKey = `can_verified_${token}`
    const validation = canValidationResults?.[validationKey]

    if (validation && validation.canBoost >= 15) {
      // ê²€ì¦ëœ ê°•ì  â†’ primary (ë†’ì€ ê°€ì¤‘ì¹˜)
      primary.push(keyword)
      weights.set(keyword, 1.5)
    } else if (validation && validation.canBoost >= 8) {
      // ë¶€ë¶„ ê²€ì¦ â†’ secondary (ì¤‘ê°„ ê°€ì¤‘ì¹˜)
      secondary.push(keyword)
      weights.set(keyword, 1.2)
    } else {
      // ë¯¸ê²€ì¦ â†’ secondary (ê¸°ë³¸ ê°€ì¤‘ì¹˜)
      secondary.push(keyword)
      weights.set(keyword, 1.0)
    }
  }

  // 3. Risk í‚¤ì›Œë“œ (ì œì™¸ ëŒ€ìƒ)
  for (const token of miniModule.constraint_flags || []) {
    const keyword = TOKEN_TO_ENGLISH[token]
    if (keyword) {
      exclude.push(keyword)
    }
  }

  // ì—ë„ˆì§€ ì†Œëª¨ í”Œë˜ê·¸ë„ ì œì™¸ í‚¤ì›Œë“œë¡œ
  for (const token of miniModule.energy_drain_flags || []) {
    const keyword = TOKEN_TO_ENGLISH[token]
    if (keyword) {
      exclude.push(keyword)
    }
  }

  return {
    primary_keywords: primary,
    secondary_keywords: secondary,
    exclude_keywords: exclude,
    boost_weights: weights,
  }
}

/**
 * ê°€ì¤‘ ì¿¼ë¦¬ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (ê²€ìƒ‰ìš©)
 */
export function weightedQueryToString(query: WeightedSearchQuery): string {
  const parts: string[] = []

  // Primary í‚¤ì›Œë“œë¥¼ 2ë²ˆ í¬í•¨ (ê°€ì¤‘ì¹˜ íš¨ê³¼)
  if (query.primary_keywords.length > 0) {
    parts.push(`key skills: ${query.primary_keywords.join(' ')}`)
    parts.push(`strengths: ${query.primary_keywords.join(' ')}`)  // ì¤‘ë³µìœ¼ë¡œ ê°•ì¡°
  }

  // Secondary í‚¤ì›Œë“œ
  if (query.secondary_keywords.length > 0) {
    parts.push(`interests: ${query.secondary_keywords.join(' ')}`)
  }

  // Exclude í‚¤ì›Œë“œ (NOT í‘œí˜„)
  if (query.exclude_keywords.length > 0) {
    parts.push(`avoid: ${query.exclude_keywords.join(' ')}`)
  }

  if (parts.length === 0) {
    return 'career recommendation job matching'
  }

  return parts.join(' ').substring(0, 500)
}

// ============================================
// ì‚¬ìš©ì ì¿¼ë¦¬ ìƒì„± (facts â†’ ê²€ìƒ‰ ì¿¼ë¦¬)
// ============================================
export function buildSearchQuery(
  facts: Array<{ fact_key: string; value_json: string }>,
  miniModule?: MiniModuleResult
): string {
  // ë¯¸ë‹ˆëª¨ë“ˆ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
  if (miniModule && (miniModule.interest_top.length > 0 || miniModule.value_top.length > 0)) {
    return buildSearchQueryFromMiniModule(miniModule)
  }
  
  const queryParts: string[] = []
  
  for (const fact of facts) {
    try {
      const parsed = JSON.parse(fact.value_json)
      const value = parsed.value || parsed
      
      // ê´€ì‹¬ì‚¬ ì¶”ì¶œ â†’ ì˜ì–´ í‚¤ì›Œë“œë¡œ ë³€í™˜
      if (fact.fact_key.includes('interest')) {
        if (Array.isArray(value)) {
          // í•œêµ­ì–´ ê´€ì‹¬ì‚¬ë¥¼ ì˜ì–´ë¡œ ë§¤í•‘
          const interestMap: Record<string, string> = {
            'ê¸°ìˆ ': 'technology engineering development',
            'ë””ìì¸': 'design creative artistic',
            'ë¹„ì¦ˆë‹ˆìŠ¤': 'business management leadership',
            'ë°ì´í„°': 'data analysis quantitative',
            'êµìœ¡': 'education teaching training',
            'ì˜ë£Œ': 'healthcare medical health',
            'ê¸ˆìœµ': 'finance banking investment',
            'ë§ˆì¼€íŒ…': 'marketing sales communication',
          }
          const mapped = value.map((v: string) => interestMap[v] || v).join(' ')
          queryParts.push(`interest: ${mapped}`)
        } else {
          queryParts.push(`interest: ${value}`)
        }
      }
      
      // ìš°ì„ ìˆœìœ„ ì¶”ì¶œ â†’ ì˜ì–´ë¡œ ë³€í™˜
      if (fact.fact_key.includes('priority')) {
        const priorityMapEn: Record<string, string> = {
          growth: 'career growth learning development',
          income: 'high salary compensation financial',
          wlb: 'work-life balance flexible hours',
          stability: 'job security stable employment',
          meaning: 'meaningful work purpose impact',
        }
        queryParts.push(`value: ${priorityMapEn[value] || value}`)
      }
      
      // ì‘ì—… ìŠ¤íƒ€ì¼ â†’ ì˜ì–´ë¡œ ë³€í™˜
      if (fact.fact_key.includes('workstyle')) {
        if (value === 'solo') {
          queryParts.push('work style: independent autonomous focused')
        } else if (value === 'team') {
          queryParts.push('work style: collaborative team cooperative')
        }
      }
      
      // Deep intake ë‚´ìš© (ì´ê±´ í•œêµ­ì–´ ê·¸ëŒ€ë¡œ - ë³´ì¡° ì—­í• )
      if (fact.fact_key.includes('deep_intake') || fact.fact_key.includes('discovery')) {
        if (typeof value === 'string' && value.length > 5) {
          queryParts.push(value.substring(0, 100))
        }
      }
      
    } catch {
      // íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
    }
  }
  
  // ê¸°ë³¸ ì¿¼ë¦¬ (ì˜ì–´)
  if (queryParts.length === 0) {
    return 'career recommendation job matching professional work'
  }
  
  return queryParts.join(' ').substring(0, 500)
}

// ============================================
// ë²¡í„° ê²€ìƒ‰ (Cloudflare Vectorize + OpenAI Embedding)
// ============================================
export async function searchCandidates(
  vectorize: VectorizeIndex,
  openaiApiKey: string,
  query: string,
  topK: number = 500
): Promise<VectorSearchResult[]> {
  // 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (OpenAI - í•œêµ­ì–´ ì§ì ‘ ì²˜ë¦¬)
  const { embeddings } = await generateOpenAIEmbedding(openaiApiKey, query)
  const queryEmbedding = embeddings[0]
  
  // 2. ë²¡í„° ê²€ìƒ‰
  // Cloudflare Vectorize ì ˆëŒ€ ìƒí•œ: topK = 100
  // metadataëŠ” í›„ì† D1 ì¡°íšŒì—ì„œ ê°€ì ¸ì˜¤ë¯€ë¡œ 'none'ìœ¼ë¡œ ì„¤ì •
  const clampedTopK = Math.min(topK, 100)
  const searchResult = await vectorize.query(queryEmbedding, {
    topK: clampedTopK,
    returnValues: false,
    returnMetadata: 'none',
  })

  // 3. ê²°ê³¼ ë³€í™˜ (metadata ì—†ì´ ID + scoreë§Œ ë°˜í™˜, job_nameì€ D1ì—ì„œ ì¡°íšŒ)
  return searchResult.matches.map(match => ({
    job_id: match.id,
    job_name: match.id,
    score: match.score,
    metadata: {} as Record<string, any>,
  }))
}

// ============================================
// Multi-Query ë²¡í„° ê²€ìƒ‰ (topK=100 ì œí•œ ìš°íšŒ)
// ì—¬ëŸ¬ ì¿¼ë¦¬ë¥¼ ë°°ì¹˜ ì„ë² ë”© + ë³‘ë ¬ ê²€ìƒ‰í•˜ì—¬ í›„ë³´ í’€ í™•ì¥
// ============================================
export async function searchCandidatesMultiQuery(
  vectorize: VectorizeIndex,
  openaiApiKey: string,
  queries: string[],
  topK: number = 100
): Promise<VectorSearchResult[]> {
  // 1. ë°°ì¹˜ ì„ë² ë”© (í•œ ë²ˆì˜ OpenAI í˜¸ì¶œë¡œ ëª¨ë“  ì¿¼ë¦¬ ì„ë² ë”©)
  const { embeddings } = await generateOpenAIEmbedding(openaiApiKey, queries)
  console.log(`[Multi-Query] Batch embedding done: ${queries.length} queries â†’ ${embeddings.length} embeddings`)

  // 2. ë³‘ë ¬ Vectorize ê²€ìƒ‰ (ê° topK=100)
  const clampedTopK = Math.min(topK, 100)
  const searchPromises = embeddings.map(emb =>
    vectorize.query(emb, { topK: clampedTopK, returnValues: false, returnMetadata: 'none' })
  )
  const searchResults = await Promise.all(searchPromises)

  // 3. ì¤‘ë³µ ì œê±° (ê°™ì€ job_id â†’ ìµœê³  score ìœ ì§€)
  const bestScoreMap = new Map<string, number>()
  let totalMatches = 0
  for (const result of searchResults) {
    for (const match of result.matches) {
      totalMatches++
      const existing = bestScoreMap.get(match.id)
      if (existing === undefined || match.score > existing) {
        bestScoreMap.set(match.id, match.score)
      }
    }
  }

  console.log(`[Multi-Query] Total matches: ${totalMatches}, Unique jobs: ${bestScoreMap.size}`)

  // 4. ê²°ê³¼ ë³€í™˜ (score ë‚´ë¦¼ì°¨ìˆœ)
  return Array.from(bestScoreMap.entries())
    .sort((a, b) => b[1] - a[1])
    .map(([id, score]) => ({
      job_id: id,
      job_name: id,
      score,
      metadata: {} as Record<string, any>,
    }))
}

// ============================================
// í›„ë³´êµ° í™•ì¥ (ë©”ì¸ í•¨ìˆ˜) - ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜
// ============================================
// 2026-01-26: íƒœê¹… ì˜ì¡´ë„ ì™„ì „ ì œê±°
// - ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ë§Œ ì‚¬ìš©
// - ëª¨ë“  ì§ì—… ê²€ìƒ‰ ê°€ëŠ¥ (íƒœê¹… ì—¬ë¶€ ë¬´ê´€)
// ============================================
export async function expandCandidates(
  db: D1Database,
  vectorize: VectorizeIndex | undefined,
  openaiApiKey: string | undefined,
  facts: Array<{ fact_key: string; value_json: string }>,
  options: {
    targetSize?: number
  } = {}
): Promise<CandidateExpansionResult> {
  const { targetSize = 500 } = options
  const startTime = Date.now()
  
  // Vectorize ë˜ëŠ” OpenAI API í‚¤ê°€ ì—†ìœ¼ë©´ fallback
  if (!vectorize || !openaiApiKey) {
    console.log('[Vectorize] Vectorize/OpenAI not available, using DB fallback')
    const fallbackResult = await getFallbackCandidates(db, targetSize)
    return {
      candidates: fallbackResult,
      total_searched: fallbackResult.length,
      search_duration_ms: Date.now() - startTime,
      fallback_used: true,
    }
  }
  
  try {
    // 1. ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (í•œêµ­ì–´ ì§ì ‘ ì‚¬ìš© ê°€ëŠ¥)
    const query = buildSearchQuery(facts)
    console.log(`[Vectorize] Search query: ${query.substring(0, 100)}...`)
    
    // 2. ë²¡í„° ê²€ìƒ‰ (OpenAI Embedding ì‚¬ìš©)
    const vectorResults = await searchCandidates(vectorize, openaiApiKey, query, targetSize)
    
    console.log(`[Vectorize] Found ${vectorResults.length} candidates via vector search`)
    
    return {
      candidates: vectorResults,
      total_searched: vectorResults.length,
      search_duration_ms: Date.now() - startTime,
      fallback_used: false,
    }
    
  } catch (error) {
    console.error('[Vectorize] Search failed, using fallback:', error)
    const fallbackResult = await getFallbackCandidates(db, targetSize)
    return {
      candidates: fallbackResult,
      total_searched: fallbackResult.length,
      search_duration_ms: Date.now() - startTime,
      fallback_used: true,
    }
  }
}

// ============================================
// Fallback: DBì—ì„œ ì§ì ‘ ì¡°íšŒ (íƒœê¹… ë¬´ê´€)
// ============================================
// 2026-01-26: íƒœê¹… ì˜ì¡´ë„ ì œê±°
// - ëª¨ë“  ì§ì—…ì„ ì¡°íšŒ (tagger_version ì¡°ê±´ ì œê±°)
// - ëœë¤ ìƒ˜í”Œë§ìœ¼ë¡œ ë‹¤ì–‘í•œ ì§ì—… ì œê³µ
// ============================================
async function getFallbackCandidates(
  db: D1Database,
  limit: number
): Promise<VectorSearchResult[]> {
  // job_attributes í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì¡°íšŒ (íƒœê¹… ì—¬ë¶€ ë¬´ê´€)
  const result = await db.prepare(`
    SELECT job_id, job_name
    FROM job_attributes
    ORDER BY RANDOM()
    LIMIT ?
  `).bind(limit).all<{ job_id: string; job_name: string }>()
  
  return (result.results || []).map((row, idx) => ({
    job_id: row.job_id,
    job_name: row.job_name,
    score: 0.5 - (idx * 0.0005), // ìˆœì„œì— ë”°ë¼ ë¯¸ì„¸í•˜ê²Œ ì ìˆ˜ ê°ì†Œ
    metadata: { source: 'fallback_random' },
  }))
}

// ============================================
// Job Profile Compact: Freeze v1.1 ì¸ë±ì‹± í…ìŠ¤íŠ¸ ìƒì„±
// ============================================
// ë²„ì „: JOB_PROFILE_COMPACT_V1
// ë³€ê²½ ì‹œ ë°˜ë“œì‹œ JOB_PROFILE_COMPACT_VERSION ì¦ê°€ í•„ìš”!
// ============================================
export interface JobProfileData {
  name: string
  heroIntro?: string | null
  summary?: string | null
  description?: string | null
  duties?: string | null
  skills?: string[] | null
  workEnvironment?: string | null
  certifications?: string[] | null
  category?: string | null
}

/**
 * buildJobProfileCompact: ì§ì—… ë°ì´í„°ë¥¼ ì¸ë±ì‹±ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
 * 
 * Fallback ê·œì¹™:
 * 1. heroIntro â†’ summary â†’ description â†’ category ìš°ì„ ìˆœìœ„
 * 2. ëª¨ë“  ì§ì—…ì´ "ì§ì—…ëª… + í•µì‹¬ 2~3ë¬¸ì¥"ì€ ë°˜ë“œì‹œ í¬í•¨
 * 3. ìµœëŒ€ ê¸¸ì´ 1000ì
 * 4. ë¹ˆ ë°ì´í„°ê°€ ë§ì•„ë„ ìµœì†Œ ì •ë³´ëŸ‰ ë³´ì¥
 */
export function buildJobProfileCompact(job: JobProfileData): string {
  // ì§ì—…ëª…ì€ í•­ìƒ í•„ìˆ˜
  const name = job.name || 'ë¯¸ìƒ'
  
  // ì„¤ëª… í…ìŠ¤íŠ¸ fallback ìš°ì„ ìˆœìœ„
  const mainDesc = (
    job.heroIntro || 
    job.summary || 
    job.description || 
    ''
  ).trim()
  
  // ì„ íƒì  í•„ë“œë“¤ (ìˆìœ¼ë©´ ì¶”ê°€)
  const parts: string[] = [name]
  
  // ë©”ì¸ ì„¤ëª… (ìµœëŒ€ 300ì)
  if (mainDesc) {
    parts.push(mainDesc.slice(0, 300))
  }
  
  // í•µì‹¬ì—…ë¬´ (ìˆìœ¼ë©´)
  if (job.duties && job.duties.trim()) {
    parts.push(`í•µì‹¬ì—…ë¬´: ${job.duties.slice(0, 100)}`)
  }
  
  // í•„ìš”ì—­ëŸ‰ (ìˆìœ¼ë©´, ìµœëŒ€ 5ê°œ)
  if (job.skills && job.skills.length > 0) {
    const validSkills = job.skills.filter(s => s && s.trim())
    if (validSkills.length > 0) {
      parts.push(`í•„ìš”ì—­ëŸ‰: ${validSkills.slice(0, 5).join(', ')}`)
    }
  }
  
  // ê·¼ë¬´í™˜ê²½ (ìˆìœ¼ë©´)
  if (job.workEnvironment && job.workEnvironment.trim()) {
    parts.push(`í™˜ê²½: ${job.workEnvironment.slice(0, 50)}`)
  }
  
  // ìê²©ì¦ (ìˆìœ¼ë©´, ìµœëŒ€ 3ê°œ)
  if (job.certifications && job.certifications.length > 0) {
    const validCerts = job.certifications.filter(c => c && c.trim())
    if (validCerts.length > 0) {
      parts.push(`ìê²©: ${validCerts.slice(0, 3).join(', ')}`)
    }
  }
  
  // ì¹´í…Œê³ ë¦¬ (ìˆìœ¼ë©´)
  if (job.category && job.category.trim()) {
    parts.push(job.category)
  }
  
  // ìµœì†Œ ë³´ì¥: name + categoryëŠ” ë°˜ë“œì‹œ í¬í•¨
  if (parts.length < 2) {
    parts.push(job.category || 'ë¯¸ë¶„ë¥˜')
  }
  
  return parts.join(' ').substring(0, 1000)
}

/**
 * parseJobProfileFromMergedJson: merged_profile_jsonì—ì„œ JobProfileData ì¶”ì¶œ
 */
export function parseJobProfileFromMergedJson(
  jobId: string,
  jobName: string,
  mergedProfileJson: string | null,
  category?: string | null
): JobProfileData {
  let heroIntro: string | undefined
  let summary: string | undefined
  let description: string | undefined
  let duties: string | undefined
  let skills: string[] | undefined
  let workEnvironment: string | undefined
  let certifications: string[] | undefined

  if (mergedProfileJson) {
    try {
      const profile = JSON.parse(mergedProfileJson)
      
      // ë‹¤ì–‘í•œ í•„ë“œëª… ì§€ì› (ë°ì´í„° ì†ŒìŠ¤ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
      heroIntro = profile.heroIntro || profile.hero_intro || profile.intro
      summary = profile.summary || profile.brief
      description = profile.description || profile.overview || profile.what || profile.ì—…ë¬´ë‚´ìš©
      duties = profile.duties || profile.responsibilities || profile.tasks || 
               (profile.what && typeof profile.what === 'string' ? profile.what : undefined)
      
      // skills ë°°ì—´ ì²˜ë¦¬
      if (profile.skills) {
        skills = Array.isArray(profile.skills) ? profile.skills : [profile.skills]
      } else if (profile.required_skills) {
        skills = Array.isArray(profile.required_skills) ? profile.required_skills : [profile.required_skills]
      }
      
      workEnvironment = profile.workEnvironment || profile.work_environment || profile.environment
      
      // certifications ë°°ì—´ ì²˜ë¦¬
      if (profile.certifications) {
        certifications = Array.isArray(profile.certifications) ? profile.certifications : [profile.certifications]
      } else if (profile.licenses) {
        certifications = Array.isArray(profile.licenses) ? profile.licenses : [profile.licenses]
      }
      
    } catch (e) {
      console.warn(`[parseJobProfile] Failed to parse merged_profile_json for ${jobId}:`, e)
    }
  }

  return {
    name: jobName,
    heroIntro,
    summary,
    description,
    duties,
    skills,
    workEnvironment,
    certifications,
    category,
  }
}

// ============================================
// ì§ì—… ë°ì´í„° ì¸ë±ì‹± (ë°°ì¹˜ ì²˜ë¦¬ìš© - OpenAI Embedding)
// ============================================
// Version: JOB_PROFILE_COMPACT_V1
// ============================================
export async function indexJobsToVectorize(
  db: D1Database,
  vectorize: VectorizeIndex,
  openaiApiKey: string,
  batchSize: number = 50  // OpenAI API rate limit ê³ ë ¤í•˜ì—¬ ì¤„ì„
): Promise<{ indexed: number; errors: number; version: string }> {
  let indexed = 0
  let errors = 0
  let offset = 0
  const version = getFullEmbeddingVersion()
  
  console.log(`[Vectorize] Starting indexing with version: ${version}`)
  
  while (true) {
    // jobs í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì¡°íšŒ (6,945ê°œ ì „ì²´)
    const jobs = await db.prepare(`
      SELECT 
        id as job_id,
        name as job_name,
        merged_profile_json,
        category
      FROM jobs
      WHERE is_active = 1
      LIMIT ? OFFSET ?
    `).bind(batchSize, offset).all<{
      job_id: string
      job_name: string
      merged_profile_json: string | null
      category: string | null
    }>()
    
    if (!jobs.results || jobs.results.length === 0) break
    
    // buildJobProfileCompactë¡œ ì¸ë±ì‹± í…ìŠ¤íŠ¸ ìƒì„±
    const textsForEmbedding = jobs.results.map(job => {
      const profileData = parseJobProfileFromMergedJson(
        job.job_id,
        job.job_name,
        job.merged_profile_json,
        job.category
      )
      return buildJobProfileCompact(profileData)
    })
    
    try {
      // ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„±
      const { embeddings } = await generateOpenAIEmbedding(openaiApiKey, textsForEmbedding)
      
      // Vectorizeì— ë°°ì¹˜ ì €ì¥ (í™•ì¥ëœ metadata í¬í•¨)
      const vectors = jobs.results.map((job, idx) => {
        // merged_profile_jsonì—ì„œ ì¶”ê°€ metadata ì¶”ì¶œ
        let kscoMajor: string | undefined
        let kscoMid: string | undefined
        let educationLevel: string | undefined
        
        if (job.merged_profile_json) {
          try {
            const profile = JSON.parse(job.merged_profile_json)
            kscoMajor = profile.ksco_major || profile.kscoMajor
            kscoMid = profile.ksco_mid || profile.kscoMid
            educationLevel = profile.education_level || profile.educationLevel || profile.í•™ë ¥
          } catch {}
        }
        
        return {
          id: job.job_id,
          values: embeddings[idx],
          metadata: {
            job_name: job.job_name,
            category: job.category || '',
            // QSP í’ˆì§ˆ ê°•í™”ìš© metadata
            ksco_major: kscoMajor || '',
            ksco_mid: kscoMid || '',
            education_level: educationLevel || '',
            // ë²„ì „ ì¶”ì 
            embedding_version: JOB_PROFILE_COMPACT_VERSION,
          },
        }
      })
      
      await vectorize.upsert(vectors)
      indexed += jobs.results.length
      
    } catch (error) {
      console.error(`[Vectorize] Batch indexing failed at offset ${offset}:`, error)
      errors += jobs.results.length
    }
    
    offset += batchSize
    console.log(`[Vectorize] Indexed ${indexed} jobs so far...`)
    
    // OpenAI rate limit ë°©ì§€ (1ì´ˆ ëŒ€ê¸°)
    await new Promise(resolve => setTimeout(resolve, 1000))
  }
  
  console.log(`[Vectorize] Indexing complete. Total: ${indexed}, Errors: ${errors}, Version: ${version}`)
  
  return { indexed, errors, version }
}

// ============================================
// ì§ì—… ì„¤ëª… ì¶”ì¶œ í—¬í¼ í•¨ìˆ˜
// ============================================
export function extractJobDescription(apiDataJson: string | null, mergedProfileJson?: string | null, jobName?: string, aiDataJson?: string | null): string | undefined {
  // 1. merged_profile_jsonì—ì„œ ë¨¼ì € ì‹œë„ (heroIntro ë“± ì‹¤ì œ í•„ë“œëª…)
  if (mergedProfileJson) {
    try {
      const data = JSON.parse(mergedProfileJson)
      const description =
        data.heroIntro ||                     // ë©”ì¸ ì„¤ëª… í•„ë“œ
        data.overviewWork?.main ||            // ì—…ë¬´ ê°œìš”
        data.description ||
        data.job_overview ||
        data.summary ||
        data.job_summary ||
        data.overview ||
        data.ì§ë¬´ê°œìš” ||
        data.ì§ì—…ê°œìš” ||
        undefined
      if (description) {
        // ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
        const text = typeof description === 'string' ? description : JSON.stringify(description)
        return text.substring(0, 200)
      }
    } catch {
      // continue to api_data_json
    }
  }

  // 2. api_data_jsonì—ì„œ ì‹œë„
  if (apiDataJson) {
    try {
      const data = JSON.parse(apiDataJson)
      // merged â†’ careernet â†’ goyong24 ìˆœìœ¼ë¡œ ì‹œë„
      const description =
        data.merged?.heroIntro ||
        data.merged?.description ||
        data.merged?.job_overview ||
        data.careernet?.summary ||
        data.careernet?.job_overview ||
        data.careernet?.description ||
        data.goyong24?.summary?.jobSum ||
        data.goyong24?.duty?.jobSum ||
        data.goyong24?.description ||
        data.goyong24?.job_overview ||
        undefined
      if (description) {
        const text = typeof description === 'string' ? description : JSON.stringify(description)
        return text.substring(0, 200)
      }
    } catch {
      // continue to ai_data_json
    }
  }

  // 3. ai_data_jsonì—ì„œ ì‹œë„
  if (aiDataJson) {
    try {
      const data = JSON.parse(aiDataJson)
      const description =
        data.description ||
        data.summary ||
        data.heroIntro ||
        data.job_description ||
        undefined
      if (description) {
        const text = typeof description === 'string' ? description : JSON.stringify(description)
        return text.substring(0, 200)
      }
    } catch {
      // continue to fallback
    }
  }

  // 4. ì„¤ëª…ì´ ì—†ìœ¼ë©´ ì§ì—…ëª… ê¸°ë°˜ ê¸°ë³¸ ì„¤ëª… ìƒì„±
  if (jobName) {
    return `${jobName}ì€(ëŠ”) ì „ë¬¸ì ì¸ ì§€ì‹ê³¼ ê¸°ìˆ ì´ í•„ìš”í•œ ì§ì—…ì…ë‹ˆë‹¤.`
  }
  return undefined
}

// ============================================
// ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ë¥¼ ScoredJob í˜•íƒœë¡œ ë³€í™˜
// ============================================
export async function vectorResultsToScoredJobs(
  db: D1Database,
  vectorResults: VectorSearchResult[],
  miniModule?: any
): Promise<Array<{
  job_id: string
  job_name: string
  slug?: string
  image_url?: string
  job_description?: string
  base_like: number
  base_can: number
  base_risk: number
  like_score?: number
  can_score?: number
  risk_penalty?: number
  final_score?: number
  attributes: Record<string, number | string>
}>> {
  if (vectorResults.length === 0) return []

  // ë²¡í„° ê²°ê³¼ì˜ job_idë¡œ job_attributes + jobs ì¡°ì¸ ì¡°íšŒ
  // D1/SQLiteëŠ” ìµœëŒ€ 999ê°œ ë³€ìˆ˜ë§Œ í—ˆìš©í•˜ë¯€ë¡œ batch ì²˜ë¦¬
  const BATCH_SIZE = 100  // D1 ì•ˆì •ì„±ì„ ìœ„í•´ 100ê°œì”©
  const jobIds = vectorResults.map(v => v.job_id)

  // batchë¡œ ë‚˜ëˆ ì„œ ì¡°íšŒ
  const allAttributeResults: any[] = []
  for (let i = 0; i < jobIds.length; i += BATCH_SIZE) {
    const batchIds = jobIds.slice(i, i + BATCH_SIZE)
    const placeholders = batchIds.map(() => '?').join(',')

    const batchResult = await db.prepare(`
      SELECT
        ja.job_id, ja.job_name,
        j.slug, j.image_url, j.api_data_json, j.merged_profile_json,
        ja.wlb, ja.growth, ja.stability, ja.income,
        ja.teamwork, ja.solo_deep, ja.analytical, ja.creative, ja.execution, ja.people_facing,
        ja.work_hours, ja.shift_work, ja.travel, ja.remote_possible,
        ja.degree_required, ja.license_required
      FROM job_attributes ja
      LEFT JOIN jobs j ON ja.job_id = j.id
      WHERE ja.job_id IN (${placeholders})
    `).bind(...batchIds).all<{
    job_id: string
    job_name: string
    slug: string | null
    image_url: string | null
    api_data_json: string | null
    merged_profile_json: string | null
    wlb: number
    growth: number
    stability: number
    income: number
    teamwork: number
    solo_deep: number
    analytical: number
    creative: number
    execution: number
    people_facing: number
    work_hours: string
    shift_work: string
    travel: string
    remote_possible: string
    degree_required: string
    license_required: string
  }>()

    if (batchResult.results) {
      allAttributeResults.push(...batchResult.results)
    }
  }

  const attributesMap = new Map(
    allAttributeResults.map(row => [row.job_id, row])
  )

  // job_attributesì— ì—†ëŠ” job_idë“¤ì„ ì°¾ì•„ì„œ jobs í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì¡°íšŒ
  const missingJobIds = jobIds.filter(id => !attributesMap.has(id))
  if (missingJobIds.length > 0) {
    console.log(`[vectorResultsToScoredJobs] ${missingJobIds.length}ê°œ ì§ì—…ì´ job_attributesì— ì—†ìŒ, jobs í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì¡°íšŒ`)

    for (let i = 0; i < missingJobIds.length; i += BATCH_SIZE) {
      const batchIds = missingJobIds.slice(i, i + BATCH_SIZE)
      const placeholders = batchIds.map(() => '?').join(',')

      const fallbackResult = await db.prepare(`
        SELECT id as job_id, name as job_name, slug, image_url, api_data_json, merged_profile_json
        FROM jobs
        WHERE id IN (${placeholders})
      `).bind(...batchIds).all<{
        job_id: string
        job_name: string
        slug: string | null
        image_url: string | null
        api_data_json: string | null
        merged_profile_json: string | null
      }>()

      if (fallbackResult.results) {
        for (const row of fallbackResult.results) {
          // job_attributes ë°ì´í„° ì—†ì´ jobs í…Œì´ë¸” ë°ì´í„°ë§Œìœ¼ë¡œ ê¸°ë³¸ê°’ ìƒì„±
          attributesMap.set(row.job_id, {
            ...row,
            wlb: 50, growth: 50, stability: 50, income: 50,
            teamwork: 50, solo_deep: 50, analytical: 50, creative: 50, execution: 50, people_facing: 50,
            work_hours: 'regular', shift_work: 'none', travel: 'some', remote_possible: 'partial',
            degree_required: 'none', license_required: 'none', experience_required: 'none',
            _from_jobs_fallback: true,
          })
        }
      }
    }
  }

  // ë²¡í„° ì ìˆ˜ ë§µ (scoreë¡œ ì •ë ¬ ìœ ì§€)
  const vectorScoreMap = new Map(
    vectorResults.map(vr => [vr.job_id, vr.score])
  )
  
  // ë²¡í„° ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ScoredJob ìƒì„±
  return vectorResults.map(vr => {
    const attrs = attributesMap.get(vr.job_id) as any
    const vectorScore = vectorScoreMap.get(vr.job_id) || 0
    
    if (attrs) {
      const personalized = calculatePersonalizedBaseScores(attrs, miniModule)
      // ë²¡í„° ìœ ì‚¬ë„ ë³´ë„ˆìŠ¤: ì˜ë¯¸ì ìœ¼ë¡œ ê°€ê¹Œìš´ ì§ì—…ì— Like/Can ë³´ë„ˆìŠ¤
      // vectorScore ë²”ìœ„ 0~1, ë³´ë„ˆìŠ¤ 0~15ì 
      const vectorBonus = Math.round(vectorScore * 15)
      const baseLike = Math.min(100, personalized.like + vectorBonus)
      const baseCan = Math.min(100, personalized.can + Math.round(vectorBonus * 0.5))
      const baseRisk = 10

      // ë¯¸íƒœê¹… ì§ì—… í˜ë„í‹°: job_attributes ì—†ì´ ê¸°ë³¸ê°’ 50ìœ¼ë¡œ ì±„ì›Œì§„ ì§ì—…ì€ ìˆœìœ„ í•˜ë½
      const isUntagged = !!(attrs as any)?._from_jobs_fallback
      const untaggedPenalty = isUntagged ? -25 : 0

      // ksco_major ì¶”ì¶œ (ì¹´í…Œê³ ë¦¬ ë‹¤ì–‘ì„± ë³´ì¥ìš©)
      let kscoMajor = ''
      if (attrs.merged_profile_json) {
        try {
          const profile = JSON.parse(attrs.merged_profile_json)
          kscoMajor = profile.ksco_major || profile.kscoMajor || ''
        } catch {}
      }

      return {
        job_id: attrs.job_id,
        job_name: attrs.job_name,
        slug: attrs.slug || undefined,
        image_url: attrs.image_url || undefined,
        job_description: extractJobDescription(attrs.api_data_json, attrs.merged_profile_json, attrs.job_name),
        base_like: baseLike,
        base_can: baseCan,
        base_risk: baseRisk,
        like_score: baseLike,
        can_score: baseCan,
        risk_penalty: baseRisk,
        final_score: Math.round(0.55 * baseLike + 0.45 * baseCan - baseRisk + (vectorScore * 20)) + untaggedPenalty,
        ksco_major: kscoMajor,
        attributes: {
          wlb: attrs.wlb,
          growth: attrs.growth,
          stability: attrs.stability,
          income: attrs.income,
          remote: attrs.remote_possible === 'full' ? 100 : attrs.remote_possible === 'partial' ? 50 : 0,
          solo_work: attrs.solo_deep,
          solo_deep: attrs.solo_deep,
          people_facing: attrs.people_facing,
          analytical: attrs.analytical,
          creative: attrs.creative,
          execution: attrs.execution,
          teamwork: attrs.teamwork,
          work_hours: attrs.work_hours,
          shift_work: attrs.shift_work,
          degree_required: attrs.degree_required,
          license_required: attrs.license_required,
          ksco_major: kscoMajor,
        },
      }
    }
    
    // ì†ì„± ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’
    const baseLike = Math.round(50 + vr.score * 20)
    return {
      job_id: vr.job_id,
      job_name: vr.job_name,
      slug: undefined,
      image_url: undefined,
      base_like: baseLike,
      base_can: 50,
      base_risk: 15,
      like_score: baseLike,
      can_score: 50,
      risk_penalty: 15,
      final_score: Math.round(baseLike + 50 - 15),
      attributes: {
        wlb: 50,
        growth: 50,
        stability: 50,
        income: 50,
        remote: 50,
        solo_work: 50,
        people_facing: 50,
        analytical: 50,
        creative: 50,
      },
    }
  })
}

// ============================================
// V3: SearchProfile ê¸°ë°˜ ê²€ìƒ‰ (2026-01 ë¦¬íŒ©í† ë§)
// ============================================
import type { SearchProfile, NarrativeFacts, RoundAnswer } from './types'

export interface SearchProfileInput {
  narrativeFacts?: NarrativeFacts
  roundAnswers?: RoundAnswer[]
  universalAnswers?: Record<string, string | string[]>
  careerState?: {
    role_identity: string
    career_stage_years: string
    transition_status: string
  }
}

// V3: SearchProfile ìƒì„± (rule-based, LLM ì—†ì´)
export function buildSearchProfile(input: SearchProfileInput): SearchProfile {
  const { narrativeFacts, roundAnswers, universalAnswers, careerState } = input
  
  const desiredThemes: string[] = []
  const dislikedThemes: string[] = []
  const strengthsHypothesis: string[] = []
  const environmentPreferences: string[] = []
  const hardConstraints: string[] = []
  const riskSignals: string[] = []
  const keywords: string[] = []
  
  // 1. Universal Answersì—ì„œ ì¶”ì¶œ
  if (universalAnswers) {
    // ê´€ì‹¬ì‚¬
    const interest = universalAnswers['univ_interest']
    if (interest) {
      const arr = Array.isArray(interest) ? interest : [interest]
      desiredThemes.push(...arr)
      keywords.push(...arr)
    }
    
    // ì‹«ì–´í•˜ëŠ” ê²ƒ
    const dislike = universalAnswers['univ_dislike']
    if (dislike) {
      const arr = Array.isArray(dislike) ? dislike : [dislike]
      dislikedThemes.push(...arr)
    }
    
    // ê°•ì 
    const strength = universalAnswers['univ_strength']
    if (strength) {
      const arr = Array.isArray(strength) ? strength : [strength]
      strengthsHypothesis.push(...arr)
      keywords.push(...arr)
    }
    
    // í™˜ê²½ ì„ í˜¸
    const environment = universalAnswers['univ_environment']
    if (environment) {
      environmentPreferences.push(environment as string)
    }
    
    // ì œì•½ì¡°ê±´
    const constraintTime = universalAnswers['univ_constraint_time']
    if (constraintTime) {
      const arr = Array.isArray(constraintTime) ? constraintTime : [constraintTime]
      hardConstraints.push(...arr)
    }
    
    const constraintLocation = universalAnswers['univ_constraint_location']
    if (constraintLocation) {
      const arr = Array.isArray(constraintLocation) ? constraintLocation : [constraintLocation]
      hardConstraints.push(...arr)
    }
    
    // ìš°ì„ ìˆœìœ„
    const priority = universalAnswers['univ_priority']
    if (priority) {
      desiredThemes.push(priority as string)
    }
  }
  
  // 2. ì„œìˆ í˜• ë‹µë³€ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ rule-based)
  if (narrativeFacts) {
    const extractKeywords = (text: string): string[] => {
      // ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (í•œêµ­ì–´ ëª…ì‚¬ íŒ¨í„´)
      const patterns = [
        'ì„±ì¥', 'ë°°ì›€', 'ììœ¨', 'ì•ˆì •', 'ë„ì „', 'ì°½ì˜', 'ë¶„ì„', 'í˜‘ì—…', 'ì†Œí†µ',
        'ê¸°ìˆ ', 'IT', 'ê°œë°œ', 'ë””ìì¸', 'ë§ˆì¼€íŒ…', 'ì˜ì—…', 'ê´€ë¦¬', 'ì—°êµ¬',
        'ì‚¬ëŒ', 'í˜¼ì', 'íŒ€', 'ììœ ', 'ê·œì¹™', 'ë£¨í‹´', 'ë³€í™”',
        'ì¸ì •', 'ì„±ì·¨', 'ì˜ë¯¸', 'ë³´ëŒ', 'ëˆ', 'ì—¬ìœ ', 'ê±´ê°•'
      ]
      return patterns.filter(p => text.includes(p))
    }
    
    if (narrativeFacts.highAliveMoment) {
      const kw = extractKeywords(narrativeFacts.highAliveMoment)
      desiredThemes.push(...kw)
      keywords.push(...kw)
    }
    
    if (narrativeFacts.lostMoment) {
      const kw = extractKeywords(narrativeFacts.lostMoment)
      dislikedThemes.push(...kw)
      riskSignals.push(...kw)
    }
  }
  
  // 3. ë¼ìš´ë“œ ë‹µë³€ì—ì„œ ì¶”ì¶œ
  if (roundAnswers && roundAnswers.length > 0) {
    for (const ans of roundAnswers) {
      const text = ans.answer || ''
      
      // Round 1 (ENGINE) - ì›í•˜ëŠ” ê²ƒ
      if (ans.roundNumber === 1) {
        const kw = text.split(/[,\s]+/).filter(w => w.length > 1).slice(0, 5)
        keywords.push(...kw)
      }
      
      // Round 2 (AVOIDANCE) - í”¼í•˜ê³  ì‹¶ì€ ê²ƒ
      if (ans.roundNumber === 2) {
        const kw = text.split(/[,\s]+/).filter(w => w.length > 1).slice(0, 3)
        riskSignals.push(...kw)
      }
    }
  }
  
  // 4. ì»¤ë¦¬ì–´ ìƒíƒœì—ì„œ í‚¤ì›Œë“œ ì¶”ê°€
  if (careerState) {
    if (careerState.transition_status === 'changer' || careerState.transition_status === 'returner') {
      keywords.push('ì „í™˜', 'ìƒˆë¡œìš´')
    }
    if (careerState.career_stage_years === 'student') {
      keywords.push('ì‹ ì…', 'ì´ˆë³´', 'ì…ë¬¸')
    }
  }
  
  // ì¤‘ë³µ ì œê±°
  return {
    desiredThemes: [...new Set(desiredThemes)],
    dislikedThemes: [...new Set(dislikedThemes)],
    strengthsHypothesis: [...new Set(strengthsHypothesis)],
    environmentPreferences: [...new Set(environmentPreferences)],
    hardConstraints: [...new Set(hardConstraints)],
    riskSignals: [...new Set(riskSignals)],
    keywords: [...new Set(keywords)],
  }
}

// ============================================
// LLM ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰ ì¿¼ë¦¬ ë™ì  ìƒì„±
// ============================================
// ì •ì  í† í°â†’í‚¤ì›Œë“œ ë§¤í•‘ ëŒ€ì‹  GPT-4o-miniê°€ ìœ ì € í”„ë¡œíŒŒì¼ì„ ë³´ê³ 
// ì í•©í•œ ì§ì—… ì¹´í…Œê³ ë¦¬/ì§ì—…ëª…ì„ ìë™ ì¶”ë¡ í•©ë‹ˆë‹¤.
// ë¹„ìš©: ~$0.001/call, ì‹œê°„: ~1-2ì´ˆ
// ============================================

const LLM_SEARCH_QUERY_PROMPT = `ë‹¹ì‹ ì€ í•œêµ­ ì§ì—… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ í”„ë¡œíŒŒì¼ì„ ë³´ê³ , ì´ ì‚¬ëŒì—ê²Œ ì í•©í•  ìˆ˜ ìˆëŠ” í•œêµ­ ì§ì—… ì¹´í…Œê³ ë¦¬ì™€ êµ¬ì²´ì  ì§ì—…ëª…ì„ ë‚˜ì—´í•´ì£¼ì„¸ìš”.

ê·œì¹™:
1. ì§ì—… ì¹´í…Œê³ ë¦¬ 5~8ê°œ, êµ¬ì²´ì  ì§ì—…ëª… 15~25ê°œë¥¼ ë‚˜ì—´
2. í•œêµ­ì–´ë¡œ ì‘ì„± (ì˜ˆ: ê³µë¬´ì›, í–‰ì •ì‚¬ë¬´ì›, ë°ì´í„°ë¶„ì„ê°€)
3. ì‚¬ìš©ìì˜ í¥ë¯¸, ê°€ì¹˜ê´€, ê°•ì , ì œì•½ì¡°ê±´ì„ ëª¨ë‘ ê³ ë ¤
4. ë„ˆë¬´ ë»”í•œ ê²ƒë§Œ ë‚˜ì—´í•˜ì§€ ë§ê³ , ìˆ¨ê²¨ì§„ ì í•© ì§ì—…ë„ í¬í•¨
5. ì œì•½ì¡°ê±´ì´ ìˆìœ¼ë©´ ê·¸ì— ë§ëŠ” í˜„ì‹¤ì ì¸ ì§ì—… ìœ„ì£¼ë¡œ
6. ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ í•œ ì¤„ë¡œ ì¶œë ¥
7. ì„¤ëª…ì´ë‚˜ ë²ˆí˜¸ ì—†ì´ ì§ì—…ëª…/ì¹´í…Œê³ ë¦¬ë§Œ ë‚˜ì—´`

export async function buildLLMSearchQuery(
  miniModule: MiniModuleResult,
  openaiApiKey: string
): Promise<string> {
  // ìœ ì € í”„ë¡œíŒŒì¼ì„ ìì—°ì–´ë¡œ ë³€í™˜
  const profileParts: string[] = []

  if (miniModule.interest_top?.length) {
    profileParts.push(`í¥ë¯¸: ${miniModule.interest_top.join(', ')}`)
  }
  if (miniModule.value_top?.length) {
    profileParts.push(`ê°€ì¹˜ê´€: ${miniModule.value_top.join(', ')}`)
  }
  if (miniModule.strength_top?.length) {
    profileParts.push(`ê°•ì : ${miniModule.strength_top.join(', ')}`)
  }
  if (miniModule.workstyle_top?.length) {
    profileParts.push(`ì—…ë¬´ìŠ¤íƒ€ì¼: ${miniModule.workstyle_top.join(', ')}`)
  }
  if (miniModule.constraint_flags?.length) {
    profileParts.push(`ì œì•½ì¡°ê±´: ${miniModule.constraint_flags.join(', ')}`)
  }
  if (miniModule.energy_drain_flags?.length) {
    profileParts.push(`ì—ë„ˆì§€ì†Œëª¨: ${miniModule.energy_drain_flags.join(', ')}`)
  }
  if (miniModule.sacrifice_flags?.length) {
    profileParts.push(`ê°ìˆ˜ê°€ëŠ¥: ${miniModule.sacrifice_flags.join(', ')}`)
  }
  if (miniModule.background_flags?.length) {
    profileParts.push(`ë°°ê²½: ${miniModule.background_flags.join(', ')}`)
  }
  if (miniModule.persistence_anchor) {
    profileParts.push(`ì§€ì†ë™ê¸°: ${miniModule.persistence_anchor}`)
  }
  if (miniModule.failure_response) {
    profileParts.push(`ì‹¤íŒ¨ë°˜ì‘: ${miniModule.failure_response}`)
  }

  if (profileParts.length === 0) {
    throw new Error('[LLM Search Query] miniModuleì— í”„ë¡œíŒŒì¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤')
  }

  const userMessage = `ì‚¬ìš©ì í”„ë¡œíŒŒì¼:\n${profileParts.join('\n')}`

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${openaiApiKey}`,
    },
    body: JSON.stringify({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: LLM_SEARCH_QUERY_PROMPT },
        { role: 'user', content: userMessage },
      ],
      temperature: 0.3,
      max_tokens: 300,
    }),
  })

  if (!response.ok) {
    const body = await response.text().catch(() => '')
    throw new Error(`[LLM Search Query] API error ${response.status}: ${body.substring(0, 200)}`)
  }

  const data = await response.json() as any
  const content = data.choices?.[0]?.message?.content?.trim()

  if (!content) {
    throw new Error('[LLM Search Query] LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤')
  }

  const llmQuery = `ì í•© ì§ì—…: ${content}`.substring(0, 500)

  console.log(`[LLM Search Query] Generated: ${llmQuery.substring(0, 150)}...`)
  console.log(`[LLM Search Query] Tokens: ${data.usage?.total_tokens || 'unknown'}`)

  return llmQuery
}

// ============================================
// Multi-Search ì¿¼ë¦¬ ìƒì„± (LLM ì¿¼ë¦¬ ë¶„í•  + ì°¨ì›ë³„ í‚¤ì›Œë“œ)
// 10-12ê°œ ì¿¼ë¦¬ë¡œ ë²¡í„° ê³µê°„ì˜ ë‹¤ì–‘í•œ ì˜ì—­ íƒìƒ‰
// ============================================
export async function buildMultiSearchQueries(
  miniModule: MiniModuleResult,
  openaiApiKey: string
): Promise<string[]> {
  // 1. ê¸°ì¡´ LLM ì¿¼ë¦¬ (ì¢…í•© ì§ì—…ëª… ë¦¬ìŠ¤íŠ¸)
  const llmQuery = await buildLLMSearchQuery(miniModule, openaiApiKey)

  // 2. LLM ì¶œë ¥ì„ 3-5ê°œì”© ë¶„í• í•˜ì—¬ ì„œë¸Œì¿¼ë¦¬ ìƒì„±
  // "ì í•© ì§ì—…: A, B, C, D, E, ..." â†’ ["A, B, C", "D, E, F", ...]
  const rawContent = llmQuery.replace(/^ì í•© ì§ì—…:\s*/, '')
  const jobNames = rawContent.split(/[,ï¼Œã€]/).map(s => s.trim()).filter(Boolean)
  const chunkSize = Math.max(3, Math.ceil(jobNames.length / 5))
  const subQueries: string[] = []
  for (let i = 0; i < jobNames.length; i += chunkSize) {
    subQueries.push(jobNames.slice(i, i + chunkSize).join(', '))
  }

  // 3. ì°¨ì›ë³„ í‚¤ì›Œë“œ ì¿¼ë¦¬ ì¶”ê°€ (LLM í˜¸ì¶œ ì—†ì´ ê·œì¹™ ê¸°ë°˜)
  const dimensionQueries: string[] = []
  if (miniModule.interest_top?.length) {
    dimensionQueries.push(`${miniModule.interest_top.join(' ')} ê´€ë ¨ ì§ì—…`)
  }
  if (miniModule.strength_top?.length) {
    dimensionQueries.push(`${miniModule.strength_top.join(' ')} ì—­ëŸ‰ì´ í•„ìš”í•œ ì§ì—…`)
  }
  if (miniModule.value_top?.length) {
    dimensionQueries.push(`${miniModule.value_top.join(' ')} ê°€ì¹˜ë¥¼ ì¶©ì¡±í•˜ëŠ” ì§ì—…`)
  }

  // 4. ëª¨ë“  ì¿¼ë¦¬ ê²°í•© (ì¢…í•© + ì„œë¸Œì¿¼ë¦¬ + ì°¨ì›ë³„)
  const allQueries = [
    llmQuery,          // ì¢…í•© (ê°€ì¥ ì¤‘ìš”)
    ...subQueries,     // LLM ì¶œë ¥ ë¶„í•  (5-8ê°œ)
    ...dimensionQueries, // í¥ë¯¸/ê°•ì /ê°€ì¹˜ ì°¨ì› (2-3ê°œ)
  ]

  console.log(`[Multi-Search] Generated ${allQueries.length} queries: 1 main + ${subQueries.length} sub + ${dimensionQueries.length} dimension`)

  return allQueries
}

// V3: SearchProfile â†’ ê²€ìƒ‰ ì¿¼ë¦¬ ë³€í™˜ (ì •ì  í‚¤ì›Œë“œ ê¸°ë°˜ - fallbackìš©)
export function searchProfileToQuery(profile: SearchProfile): string {
  const parts: string[] = []
  
  if (profile.desiredThemes.length > 0) {
    parts.push(`ì›í•˜ëŠ” ê²ƒ: ${profile.desiredThemes.join(', ')}`)
  }
  
  if (profile.strengthsHypothesis.length > 0) {
    parts.push(`ê°•ì : ${profile.strengthsHypothesis.join(', ')}`)
  }
  
  if (profile.keywords.length > 0) {
    parts.push(profile.keywords.join(' '))
  }
  
  if (profile.environmentPreferences.length > 0) {
    parts.push(`í™˜ê²½: ${profile.environmentPreferences.join(', ')}`)
  }
  
  if (parts.length === 0) {
    return 'ì§ì—… ì¶”ì²œ ì í•©í•œ ì¼ìë¦¬'
  }
  
  return parts.join(' ').substring(0, 500)
}

// ============================================
// V3: SearchProfile ê¸°ë°˜ í›„ë³´êµ° í™•ì¥ (OpenAI Embedding)
// ============================================
// 2026-01-26: íƒœê¹… ì˜ì¡´ë„ ì™„ì „ ì œê±°
// - ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ë§Œ ì‚¬ìš©
// - minTaggedJobs ì˜µì…˜ ì œê±°
// ============================================
export async function expandCandidatesV3(
  db: D1Database,
  vectorize: VectorizeIndex | undefined,
  openaiApiKey: string | undefined,
  searchProfile: SearchProfile,
  options: {
    targetSize?: number
    miniModule?: MiniModuleResult
  } = {}
): Promise<CandidateExpansionResult> {
  const { targetSize = 500, miniModule } = options
  const startTime = Date.now()

  // Vectorize ë˜ëŠ” OpenAI API í‚¤ê°€ ì—†ìœ¼ë©´ fallback
  if (!vectorize || !openaiApiKey) {
    console.log('[V3 Vectorize] Vectorize/OpenAI not available, using DB fallback')
    const fallbackResult = await getFallbackCandidatesV3(db, targetSize)
    return {
      candidates: fallbackResult,
      total_searched: fallbackResult.length,
      search_duration_ms: Date.now() - startTime,
      fallback_used: true,
    }
  }

  // 1. LLM ê¸°ë°˜ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (í•„ìˆ˜ - ì‹¤íŒ¨ ì‹œ ì—ëŸ¬)
  if (!miniModule) {
    throw new Error('[V3 Vectorize] miniModuleì´ í•„ìˆ˜ì…ë‹ˆë‹¤ - LLM ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±ì— í•„ìš”')
  }

  const queries = await buildMultiSearchQueries(miniModule, openaiApiKey)
  console.log(`[V3 Vectorize] Multi-query search: ${queries.length} queries`)

  // 2. ë²¡í„° ê²€ìƒ‰ (Multi-Query ë³‘ë ¬ ê²€ìƒ‰, OpenAI Embedding)
  // Vectorize ë¡œì»¬ ì‹¤í–‰ ë¶ˆê°€ ì‹œ DB fallback (wrangler pages dev í•œê³„)
  try {
    const vectorResults = await searchCandidatesMultiQuery(vectorize, openaiApiKey, queries)

    const candidates = vectorResults.map(vr => ({
      ...vr,
      metadata: { ...vr.metadata, source: 'vector_search', query_source: 'llm' },
    }))

    return {
      candidates,
      total_searched: vectorResults.length,
      search_duration_ms: Date.now() - startTime,
      fallback_used: false,
    }
  } catch (vecError: any) {
    // Vectorize ë¡œì»¬ ë°”ì¸ë”© ì—ëŸ¬ â†’ DB fallback (productionì—ì„œëŠ” ë°œìƒí•˜ì§€ ì•ŠìŒ)
    if (vecError?.message?.includes('remotely') || vecError?.message?.includes('Vectorize')) {
      console.warn(`[V3 Vectorize] Vectorize ë¡œì»¬ ì‹¤í–‰ ë¶ˆê°€ â†’ DB fallback: ${vecError.message}`)
      console.log(`[V3 Vectorize] LLM ì¿¼ë¦¬ëŠ” ì„±ê³µ: ${queries[0]?.substring(0, 80)}...`)
      const fallbackResult = await getFallbackCandidatesV3(db, targetSize)
      return {
        candidates: fallbackResult,
        total_searched: fallbackResult.length,
        search_duration_ms: Date.now() - startTime,
        fallback_used: true,
      }
    }
    throw vecError  // ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ê·¸ëŒ€ë¡œ ì „íŒŒ
  }
}

// V3: Fallback - jobs í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì¡°íšŒ (íƒœê¹… ë¬´ê´€)
async function getFallbackCandidatesV3(
  db: D1Database,
  limit: number
): Promise<VectorSearchResult[]> {
  const result = await db.prepare(`
    SELECT id, name
    FROM jobs
    WHERE is_active = 1 AND merged_profile_json IS NOT NULL
    ORDER BY RANDOM()
    LIMIT ?
  `).bind(limit).all<{ id: string; name: string }>()
  
  return (result.results || []).map((row, idx) => ({
    job_id: row.id,
    job_name: row.name,
    score: 0.5 - (idx * 0.0001), // ëœë¤ ìˆœì„œ ìœ ì§€
    metadata: { source: 'fallback_v3' },
  }))
}

// ============================================
// P1-2: SearchProfile ìºì‹œ ë²„ì „í™” (answers_hash)
// ============================================

/**
 * P1-2: ì‚¬ìš©ì ë‹µë³€ì„ ê¸°ë°˜ìœ¼ë¡œ í•´ì‹œ ìƒì„±
 * ë‹µë³€ì´ ë³€ê²½ë˜ë©´ ë‹¤ë¥¸ í•´ì‹œê°€ ìƒì„±ë˜ì–´ ìºì‹œê°€ ë¬´íš¨í™”ë¨
 */
export function computeAnswersHash(
  narrativeFacts?: NarrativeFacts,
  roundAnswers?: RoundAnswer[],
  universalAnswers?: Record<string, string | string[]>
): string {
  const content = JSON.stringify({
    n: narrativeFacts || null,
    r: (roundAnswers || []).map(a => ({ r: a.roundNumber, q: a.questionId, a: a.answer })),
    u: universalAnswers || {},
  })
  
  // ê°„ë‹¨í•œ í•´ì‹œ í•¨ìˆ˜ (DJB2 ì•Œê³ ë¦¬ì¦˜)
  let hash = 5381
  for (let i = 0; i < content.length; i++) {
    hash = ((hash << 5) + hash) + content.charCodeAt(i)
    hash = hash & hash // 32bit ì •ìˆ˜ë¡œ ë³€í™˜
  }
  
  return Math.abs(hash).toString(36)
}

/**
 * P1-2: SearchProfile ìºì‹œ ì¡°íšŒ (ë²„ì „í™”ëœ í‚¤ ì‚¬ìš©)
 */
export async function getCachedSearchProfile(
  db: D1Database,
  sessionId: string,
  answersHash: string
): Promise<SearchProfile | null> {
  try {
    const cached = await db.prepare(`
      SELECT profile_json FROM search_profile_cache 
      WHERE session_id = ? AND answers_hash = ?
    `).bind(sessionId, answersHash).first<{ profile_json: string }>()
    
    if (cached?.profile_json) {
      return JSON.parse(cached.profile_json)
    }
  } catch (error) {
    console.warn('[P1-2] SearchProfile cache read failed:', error)
  }
  
  return null
}

/**
 * P1-2: SearchProfile ìºì‹œ ì €ì¥ (ë²„ì „í™”ëœ í‚¤ ì‚¬ìš©)
 */
export async function cacheSearchProfile(
  db: D1Database,
  sessionId: string,
  answersHash: string,
  profile: SearchProfile
): Promise<void> {
  try {
    await db.prepare(`
      INSERT INTO search_profile_cache (session_id, answers_hash, profile_json)
      VALUES (?, ?, ?)
      ON CONFLICT(session_id, answers_hash) DO UPDATE SET 
        profile_json = excluded.profile_json,
        created_at = datetime('now')
    `).bind(sessionId, answersHash, JSON.stringify(profile)).run()
    
    console.log('[P1-2] SearchProfile cached:', { sessionId, answersHash: answersHash.substring(0, 8) })
  } catch (error) {
    // ìºì‹œ ì €ì¥ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•ŠìŒ
    console.warn('[P1-2] SearchProfile cache write failed:', error)
  }
}

// ============================================
// Freeze v1.1: ì¦ë¶„ ì—…ì„œíŠ¸ ì‹œìŠ¤í…œ
// ============================================
// ì‹ ê·œ/ë³€ê²½ ì§ì—…ë§Œ Vectorizeì— ë°˜ì˜
// indexed_at/embedding_version ì»¬ëŸ¼ ê¸°ë°˜
// ============================================

/**
 * ì¦ë¶„ ì—…ì„œíŠ¸: ì‹ ê·œ ë˜ëŠ” ë²„ì „ ë¶ˆì¼ì¹˜ ì§ì—…ë§Œ ì¸ë±ì‹±
 */
export async function incrementalUpsertToVectorize(
  db: D1Database,
  vectorize: VectorizeIndex,
  openaiApiKey: string,
  options: {
    batchSize?: number
    maxJobs?: number
  } = {}
): Promise<{ upserted: number; errors: number; skipped: number }> {
  const { batchSize = 50, maxJobs = 500 } = options
  const CURRENT_VERSION = `JPC_${JOB_PROFILE_COMPACT_VERSION}`
  
  console.log(`[Vectorize Incremental] Starting upsert, target version: ${CURRENT_VERSION}`)
  
  let upserted = 0
  let errors = 0
  let skipped = 0
  let offset = 0
  
  while (upserted + skipped < maxJobs) {
    // ì‹ ê·œ ë˜ëŠ” ë²„ì „ ë¶ˆì¼ì¹˜ ì§ì—… ì¡°íšŒ
    const jobs = await db.prepare(`
      SELECT id, name, merged_profile_json, category
      FROM jobs
      WHERE is_active = 1 
        AND (indexed_at IS NULL OR embedding_version != ?)
      ORDER BY id
      LIMIT ? OFFSET ?
    `).bind(CURRENT_VERSION, batchSize, offset).all<{
      id: string
      name: string
      merged_profile_json: string | null
      category: string | null
    }>()
    
    if (!jobs.results || jobs.results.length === 0) {
      console.log('[Vectorize Incremental] No more jobs to upsert')
      break
    }
    
    // ì¸ë±ì‹± í…ìŠ¤íŠ¸ ìƒì„±
    const textsForEmbedding = jobs.results.map(job => {
      const profileData = parseJobProfileFromMergedJson(
        job.id,
        job.name,
        job.merged_profile_json,
        job.category
      )
      return buildJobProfileCompact(profileData)
    })
    
    try {
      // OpenAI Embedding ìƒì„±
      const { embeddings } = await generateOpenAIEmbedding(openaiApiKey, textsForEmbedding)
      
      // Vectorizeì— upsert
      const vectors = jobs.results.map((job, idx) => {
        let kscoMajor: string | undefined
        let kscoMid: string | undefined
        let educationLevel: string | undefined
        
        if (job.merged_profile_json) {
          try {
            const profile = JSON.parse(job.merged_profile_json)
            kscoMajor = profile.ksco_major || profile.kscoMajor
            kscoMid = profile.ksco_mid || profile.kscoMid
            educationLevel = profile.education_level || profile.educationLevel
          } catch {}
        }
        
        return {
          id: job.id,
          values: embeddings[idx],
          metadata: {
            job_name: job.name,
            category: job.category || '',
            ksco_major: kscoMajor || '',
            ksco_mid: kscoMid || '',
            education_level: educationLevel || '',
            embedding_version: JOB_PROFILE_COMPACT_VERSION,
          },
        }
      })
      
      await vectorize.upsert(vectors)
      
      // D1ì— ì¸ë±ì‹± ìƒíƒœ ì—…ë°ì´íŠ¸
      for (const job of jobs.results) {
        await db.prepare(`
          UPDATE jobs 
          SET indexed_at = datetime('now'), embedding_version = ?
          WHERE id = ?
        `).bind(CURRENT_VERSION, job.id).run()
      }
      
      upserted += jobs.results.length
      console.log(`[Vectorize Incremental] Upserted ${upserted} jobs`)
      
    } catch (error) {
      console.error(`[Vectorize Incremental] Batch failed at offset ${offset}:`, error)
      errors += jobs.results.length
    }
    
    offset += batchSize
    
    // Rate limit
    await new Promise(resolve => setTimeout(resolve, 1000))
  }
  
  console.log(`[Vectorize Incremental] Complete. Upserted: ${upserted}, Errors: ${errors}, Skipped: ${skipped}`)
  
  return { upserted, errors, skipped }
}

/**
 * ì¸ë±ì‹±ì´ í•„ìš”í•œ ì§ì—… ìˆ˜ í™•ì¸
 */
export async function countJobsNeedingIndexing(
  db: D1Database
): Promise<{ total: number; needsIndexing: number; upToDate: number }> {
  const CURRENT_VERSION = `JPC_${JOB_PROFILE_COMPACT_VERSION}`
  
  const totalResult = await db.prepare(`
    SELECT COUNT(*) as count FROM jobs WHERE is_active = 1
  `).first<{ count: number }>()
  
  const needsResult = await db.prepare(`
    SELECT COUNT(*) as count FROM jobs 
    WHERE is_active = 1 
      AND (indexed_at IS NULL OR embedding_version != ?)
  `).bind(CURRENT_VERSION).first<{ count: number }>()
  
  const total = totalResult?.count || 0
  const needsIndexing = needsResult?.count || 0
  const upToDate = total - needsIndexing
  
  return { total, needsIndexing, upToDate }
}

/**
 * P1-2: SearchProfile ê¸°ë°˜ í›„ë³´êµ° í™•ì¥ (ìºì‹œ ì‚¬ìš©)
 * V3 Enhancement: TAG Pre-Filter ì§€ì› ì¶”ê°€
 * OpenAI Embedding ì‚¬ìš©
 * 
 * 2026-01-26: íƒœê¹… ì˜ì¡´ë„ ì™„ì „ ì œê±° (minTaggedJobs ì˜µì…˜ ì œê±°)
 */
export async function expandCandidatesV3WithCache(
  db: D1Database,
  vectorize: VectorizeIndex | undefined,
  openaiApiKey: string | undefined,
  profileInput: SearchProfileInput,
  options: {
    sessionId?: string
    targetSize?: number
    userConstraints?: UserConstraints  // Hard Constraint í•„í„°ìš©
    enableTagPreFilter?: boolean       // Pre-Filter í™œì„±í™” í”Œë˜ê·¸
    miniModule?: MiniModuleResult      // LLM ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±ìš©
  } = {}
): Promise<CandidateExpansionResult & {
  searchProfile: SearchProfile
  cacheHit: boolean
  preFilterResult?: PreFilterResult
}> {
  const { sessionId, targetSize = 500, userConstraints, enableTagPreFilter = false, miniModule } = options
  
  // P1-2: ë‹µë³€ í•´ì‹œ ê³„ì‚°
  const answersHash = computeAnswersHash(
    profileInput.narrativeFacts,
    profileInput.roundAnswers,
    profileInput.universalAnswers
  )
  
  // P1-2: ìºì‹œëœ SearchProfile í™•ì¸
  let searchProfile: SearchProfile | null = null
  let cacheHit = false
  
  if (sessionId) {
    searchProfile = await getCachedSearchProfile(db, sessionId, answersHash)
    if (searchProfile) {
      cacheHit = true
      console.log('[P1-2] SearchProfile cache hit:', { sessionId, answersHash: answersHash.substring(0, 8) })
    }
  }
  
  // ìºì‹œ ë¯¸ìŠ¤ ì‹œ ìƒˆë¡œ ìƒì„±
  if (!searchProfile) {
    searchProfile = buildSearchProfile(profileInput)
    
    // P1-2: ìºì‹œ ì €ì¥
    if (sessionId) {
      await cacheSearchProfile(db, sessionId, answersHash, searchProfile)
    }
  }
  
  // ============================================
  // V3 Enhancement: TAG Pre-Filter (RAG ì „ ì ìš©)
  // ============================================
  let preFilterResult: PreFilterResult | undefined
  let excludedJobIds: Set<string> | undefined
  
  if (enableTagPreFilter && userConstraints) {
    preFilterResult = await preFilterByHardConstraints(db, userConstraints)
    excludedJobIds = preFilterResult.excludedJobIds
    
    console.log(`[TAG Pre-Filter] Excluded ${preFilterResult.stats.excluded} jobs before RAG`, {
      totalTagged: preFilterResult.stats.totalTagged,
      remaining: preFilterResult.stats.remainingTagged,
    })
  }
  
  // í›„ë³´êµ° í™•ì¥ (Pre-Filter ê²°ê³¼ë¥¼ ì ìš©, OpenAI Embedding ì‚¬ìš©)
  const result = await expandCandidatesV3WithPreFilter(
    db,
    vectorize,
    openaiApiKey,
    searchProfile,
    { targetSize, excludedJobIds, miniModule }
  )
  
  return {
    ...result,
    searchProfile,
    cacheHit,
    preFilterResult,
  }
}

/**
 * V3 Enhancement: Pre-Filterê°€ ì ìš©ëœ í›„ë³´êµ° í™•ì¥
 * excludedJobIdsê°€ ìˆìœ¼ë©´ RAG ê²°ê³¼ì—ì„œ ì œì™¸
 * OpenAI Embedding ì‚¬ìš©
 * 
 * 2026-01-26: íƒœê¹… ì˜ì¡´ë„ ì™„ì „ ì œê±° (minTaggedJobs ì˜µì…˜ ì œê±°)
 */
async function expandCandidatesV3WithPreFilter(
  db: D1Database,
  vectorize: VectorizeIndex | undefined,
  openaiApiKey: string | undefined,
  searchProfile: SearchProfile,
  options: {
    targetSize?: number
    excludedJobIds?: Set<string>
    miniModule?: MiniModuleResult
  } = {}
): Promise<CandidateExpansionResult> {
  const { targetSize = 500, excludedJobIds, miniModule } = options
  const startTime = Date.now()

  // Vectorize ë˜ëŠ” OpenAI API í‚¤ê°€ ì—†ìœ¼ë©´ fallback
  if (!vectorize || !openaiApiKey) {
    console.log('[V3 Vectorize] Vectorize/OpenAI not available, using DB fallback')
    let fallbackResult = await getFallbackCandidatesV3(db, targetSize)

    // Pre-Filter ì ìš©
    if (excludedJobIds && excludedJobIds.size > 0) {
      fallbackResult = fallbackResult.filter(c => !excludedJobIds.has(c.job_id))
      console.log(`[V3 Fallback] After pre-filter: ${fallbackResult.length} candidates`)
    }

    return {
      candidates: fallbackResult,
      total_searched: fallbackResult.length,
      search_duration_ms: Date.now() - startTime,
      fallback_used: true,
    }
  }

  // 1. ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±: miniModule ìˆìœ¼ë©´ Multi-Query (LLM+ë¶„í• +ì°¨ì›ë³„), ì—†ìœ¼ë©´ ë‹¨ì¼ ì •ì  ì¿¼ë¦¬
  try {
    let vectorResults: VectorSearchResult[]

    if (miniModule) {
      const queries = await buildMultiSearchQueries(miniModule, openaiApiKey!)
      console.log(`[V3 Vectorize] Multi-query search: ${queries.length} queries`)

      // 2. Multi-Query ë³‘ë ¬ ë²¡í„° ê²€ìƒ‰ (ê° topK=100, ì¤‘ë³µ ì œê±°)
      vectorResults = await searchCandidatesMultiQuery(vectorize, openaiApiKey!, queries)
      console.log(`[V3 Vectorize] Multi-query results: ${vectorResults.length} unique jobs`)
    } else {
      const query = searchProfileToQuery(searchProfile)
      console.log(`[V3 Vectorize] Search query (static - interview mode): ${query.substring(0, 100)}...`)

      // 2. ë‹¨ì¼ ì¿¼ë¦¬ ë²¡í„° ê²€ìƒ‰ (ì¸í„°ë·° ëª¨ë“œ fallback)
      vectorResults = await searchCandidates(vectorize, openaiApiKey!, query, 100)
      console.log(`[V3 Vectorize] Single-query results: ${vectorResults.length}`)
    }

    // 3. Pre-Filter ì ìš© (ì œì™¸ ëŒ€ìƒ ì œê±°)
    if (excludedJobIds && excludedJobIds.size > 0) {
      const beforeCount = vectorResults.length
      vectorResults = vectorResults.filter(r => !excludedJobIds.has(r.job_id))
      console.log(`[V3 Vectorize] After pre-filter: ${vectorResults.length} (removed ${beforeCount - vectorResults.length})`)
    }

    // 4. targetSizeë¡œ ì œí•œ
    const candidates = vectorResults.slice(0, targetSize)

    return {
      candidates,
      total_searched: vectorResults.length,
      search_duration_ms: Date.now() - startTime,
      fallback_used: false,
    }
  } catch (vecError: any) {
    if (vecError?.message?.includes('remotely') || vecError?.message?.includes('Vectorize')) {
      console.warn(`[V3 Vectorize] Vectorize ë¡œì»¬ ì‹¤í–‰ ë¶ˆê°€ â†’ DB fallback: ${vecError.message}`)
      let fallbackResult = await getFallbackCandidatesV3(db, targetSize)
      if (excludedJobIds && excludedJobIds.size > 0) {
        fallbackResult = fallbackResult.filter(c => !excludedJobIds.has(c.job_id))
      }
      return {
        candidates: fallbackResult,
        total_searched: fallbackResult.length,
        search_duration_ms: Date.now() - startTime,
        fallback_used: true,
      }
    }
    throw vecError
  }
}

