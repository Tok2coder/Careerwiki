// CareerWiki AI Analyzer API Routes
// Version: v2.0.0-stage-based (Universal Intake + Stage-based Follow-up)
// Framework: Hono (Cloudflare Workers)

import { Hono } from 'hono'
import type { D1Database, VectorizeIndex, Ai } from '@cloudflare/workers-types'
import {
  VERSIONS,
  assertConstraintType,
  isValidStage,
  isMinorStage,
  isExperienceAllowed,
  type AnalysisRequestPayload,
  type AnalysisResultJSON,
  type AnalysisRequestPayloadV3,
  type UniversalAnswers,
  type AnalysisStage,
  type FollowupResponsePayload,
  type FollowupResult,
  type DeepIntakeInput,
  type UserInsight,
  type DebugInfo,
  type NarrativeFacts,
  type RoundAnswer,
} from './types'
import {
  calculateFactBoosts,
  applyFactBoostsToJob,
  normalizeDeepIntake,
  applyBalanceCap,  // P0: Can-Like ë°¸ëŸ°ìŠ¤ ìº¡
  type JobScores,
  type NormalizedDeepIntake,
} from './fact-score-mapping'
import {
  generateFollowupQuestions,
  type ScoredJob,
  type FollowupQuestion,
} from './question-generation'
// 2026-01-26: tagger-routes ì œê±°ë¨ (íƒœê¹… ì˜ì¡´ë„ ì™„ì „ ì œê±°)
import {
  UNIVERSAL_QUESTIONS,
  getUniversalQuestionsForStage,
  INSIGHT_WORDING,
  type UniversalQuestion,
} from './universal-questions'
import {
  getQuestionsForStage,
  getQuestionText,
  type StageQuestion,
} from './stage-question-banks'
import {
  extractUserConstraints,
  applyTagFilter,
  applyMiniModuleHardFilter,
  calculateMiniModuleRiskPenalty,
  deriveConstraintsFromHardBias,
  applyHardBiasPenalty,
  // P2: Can ê¸°ë°˜ TAG í•„í„°
  applyCanBasedFilter,
  extractVerifiedCanFromFacts,
  type FilteredCandidate,
  type VerifiedCanMap,
  // Major ì „ìš©
  applyMajorTagFilter,
  extractMajorUserConstraints,
  applyMajorMiniModuleHardFilter,
  type MajorFilteredCandidate,
} from './tag-filter'
// P3: ì„±ì¥ê³¡ì„  â†’ ì§ì—… ë§¤í•‘
import {
  extractGrowthPreference,
  matchGrowthCurves,
  type UserGrowthPreference,
} from './growth-curve-mapper'
// P3: ë‚´ë©´ê°ˆë“± â†’ Risk ì¡°ì •
import {
  calculateConflictRisk,
  calculateConflictSeverity,
} from './internal-conflict-risk'
// ìë™í™” í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
import {
  TEST_SCENARIOS,
  getScenarioById,
  getAllScenarioSummary,
  findAutoAnswer,
  getCanValidationAnswer,
  getConstraintIntensityAnswer,
  verifyTestResults,
  type TestScenario,
  type TestVerificationResult,
} from './test-scenarios'
import {
  handleFollowupNo,
  applyDiversityGuard,
  enforceDiversityOnTopN,
  filterUnrealisticJobs,
  sanitizeJobListOutput,
  filterNicheMaterialJobs,
  type FollowupNoResult,
  type RankChangeInfo,
  // Major ì „ìš©
  enforceMajorDiversity,
  injectArchetypeMajors,
  MAJOR_ARCHETYPE_DB_QUERIES,
} from './safe-replacement'
import {
  buildEvidenceLinks,
  generateDefaultEvidence,
  type Fact as EvidenceFact,
  type ScoredJobForEvidence,
} from './evidence-generator'
import {
  generatePremiumReport,
  type PremiumReportInput,
} from './premium-report-generator'
import {
  generatePremiumReportV3 as generateLLMPremiumReport,
  fixParticlesDeep,
  type ReporterInput,
  // Major ì „ìš©
  generateMajorPremiumReport,
  type MajorReporterInput,
} from './llm-reporter'
import {
  generatePurposeBasedFollowups,
  type PurposeBasedFollowupInput,
} from './question-generation'
import { TOKEN_TO_KOREAN } from './mini-module-questions'
import {
  saveConversationTurn,
  saveProfileSnapshot,
  buildProfileFromTurns,
  getNextTurnNumber,
  getLatestProfileSnapshot,
  extractSignalsFromAnswer,
  type TurnType,
  type ProfileSnapshot,
} from './user-profile'
import { draftRoutes } from './draft-routes'
import { historyRoutes } from './history-routes'
import { resumeRoutes } from './resume-routes'
import { profileRoutes } from './profile-routes'
import {
  expandCandidates,
  expandCandidatesV3WithCache,
  expandCandidatesV3,
  buildSearchProfileFromMiniModule,
  vectorResultsToScoredJobs,
  buildSearchQuery,
  indexJobsToVectorize,
  indexMajorsToVectorize,
  indexHowtosToVectorize,
  extractJobDescription,
  // Major ì „ìš©
  expandCandidatesV3ForMajors,
  vectorResultsToScoredMajors,
} from './vectorize-pipeline'
import { calculatePersonalizedBaseScores } from './personalized-scoring'
import { calculateMajorPersonalizedBaseScores } from './personalized-scoring-major'
import { generateOpenAIEmbedding, OPENAI_EMBEDDING_DIMENSIONS } from './openai-client'
import {
  buildAggregatedProfile,
  assertReadyForLLM,
  createEmptyProfile,
  type AggregatedProfile,
  type GatePhase,
  type DraftData as AggDraftData,
} from './aggregated-profile'
import { updateMemory } from './llm-memory'
// LLM ëª¨ë“ˆ í™œì„±í™” (2026-02-03)
import {
  judgeCandidates,
  type JudgeInput,
  type JudgeOutput,
  RECOMMENDATION_ENGINE_VERSION,
  // Major ì „ìš©
  judgeMajorCandidates,
  type MajorJudgeInput,
  type MajorJudgeResult,
} from './llm-judge'
import {
  calculateConfidenceScore,
  extractKeyDecisionVariables,
  createScoringTrace,
  type ScoringTrace,
  type KeyDecisionVariable,
  type ConfidenceResult,
} from './scoring-trace'
import {
  synthesizeVectorInsights,
  synthesizeVectorInsightsSync,
  visToPromptHints,
  type VISOutput,
} from './vis-synthesizer'
import {
  getOrCreateCAGState,
  saveCAGState,
  logAskedQuestion,
  logAnswerReceived,
  isQuestionAlreadyAsked,
  // P2: ìˆ˜ì§‘ ì§„í–‰ë„ ì¶”ì 
  updateCollectionProgress,
  syncCollectionProgressFromFacts,
  getCollectionProgressSummary,
  getMostNeededDimension,
  type CAGState,
} from './cag-manager'
// P0: Can ê²€ì¦ ì§ˆë¬¸
import {
  selectCanValidationQuestions,
  calculateCanBoost,
  type StrengthToken,
  type CanValidationQuestion,
} from './can-validation-questions'

// ============================================
// Error Handling (V3 í‘œì¤€í™”)
// ============================================
type ErrorCode = 
  | 'VALIDATION_ERROR'     // 400: ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨
  | 'INVALID_STAGE'        // 400: ì˜ëª»ëœ Stage
  | 'INVALID_PAYLOAD'      // 400: ì˜ëª»ëœ í˜ì´ë¡œë“œ í˜•ì‹
  | 'SESSION_NOT_FOUND'    // 404: ì„¸ì…˜ ì—†ìŒ
  | 'REQUEST_NOT_FOUND'    // 404: ë¶„ì„ ìš”ì²­ ì—†ìŒ
  | 'RESULT_NOT_FOUND'     // 404: ë¶„ì„ ê²°ê³¼ ì—†ìŒ
  | 'DB_ERROR'             // 500: ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜
  | 'ANALYSIS_FAILED'      // 500: ë¶„ì„ ì²˜ë¦¬ ì‹¤íŒ¨
  | 'INTERNAL_ERROR'       // 500: ë‚´ë¶€ ì˜¤ë¥˜

interface ApiError {
  error: string
  code: ErrorCode
  details?: Record<string, unknown>
  request_id?: number
  timestamp: string
}

function createErrorResponse(
  code: ErrorCode,
  message: string,
  details?: Record<string, unknown>,
  requestId?: number
): ApiError {
  return {
    error: message,
    code,
    details,
    request_id: requestId,
    timestamp: new Date().toISOString(),
  }
}

// Error logging â€” console.errorë¡œ Cloudflare Workers ë¡œê·¸ì— ê¸°ë¡
function logError(
  code: ErrorCode,
  message: string,
  context?: Record<string, unknown>
): void {
  console.error(`[AI-Analyzer] ${code}: ${message}`, context ? JSON.stringify(context) : '')
}

// Timing-safe ë¬¸ìì—´ ë¹„êµ (timing attack ë°©ì§€)
function timingSafeCompare(a: string, b: string): boolean {
  if (a.length !== b.length) return false
  const encoder = new TextEncoder()
  const bufA = encoder.encode(a)
  const bufB = encoder.encode(b)
  // crypto.subtle.timingSafeEqualì€ Cloudflare Workersì—ì„œ ì§€ì›
  if (typeof crypto !== 'undefined' && crypto.subtle && typeof (crypto.subtle as any).timingSafeEqual === 'function') {
    return (crypto.subtle as any).timingSafeEqual(bufA, bufB)
  }
  // fallback: ì „ì²´ ë°”ì´íŠ¸ ë¹„êµ (short-circuit ì—†ìŒ)
  let result = 0
  for (let i = 0; i < bufA.length; i++) {
    result |= bufA[i] ^ bufB[i]
  }
  return result === 0
}

// Admin ì¸ì¦ í™•ì¸ â€” user role ë˜ëŠ” X-Admin-Secret í—¤ë”
function checkAdminAuth(c: any): Response | null {
  const user = c.get('user')
  const isAdmin = user?.role === 'admin'
  const adminSecret = c.req.header('X-Admin-Secret')
  const isSecretValid = adminSecret && c.env.ADMIN_SECRET && timingSafeCompare(adminSecret, c.env.ADMIN_SECRET)
  if (!isAdmin && !isSecretValid) {
    return c.json({ success: false, error: 'ADMIN_AUTH_REQUIRED', message: 'ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤' }, 403)
  }
  return null
}

// ============================================
// Confidence: mini_module_result â†’ facts ë³€í™˜
// facts í…Œì´ë¸”ì´ ë¹„ì–´ìˆì„ ë•Œ miniModule ë‹µë³€ìœ¼ë¡œ confidence ê³„ì‚°
// ============================================
function buildConfidenceFactsFromMiniModule(mm: any): Array<{ fact_key: string; value_json: string }> {
  const facts: Array<{ fact_key: string; value_json: string }> = []
  if (!mm) return facts

  // í•µì‹¬ ê°€ì¹˜ â†’ priority.top1 (FACT_UNCERTAINTY_REDUCTION: 0.10)
  if (mm.value_top?.length) {
    facts.push({ fact_key: 'priority.top1', value_json: JSON.stringify(mm.value_top[0]) })
  }

  // í¥ë¯¸ â†’ profile.interest (0.04, ë°°ì—´ â†’ diversityBonus ê¸°ì—¬)
  if (mm.interest_top?.length) {
    facts.push({ fact_key: 'profile.interest', value_json: JSON.stringify(mm.interest_top) })
  }

  // ê°•ì  â†’ profile.strength (0.04)
  if (mm.strength_top?.length) {
    facts.push({ fact_key: 'profile.strength', value_json: JSON.stringify(mm.strength_top) })
  }

  // ê°€ì¹˜ â†’ profile.value (0.04)
  if (mm.value_top?.length) {
    facts.push({ fact_key: 'profile.value', value_json: JSON.stringify(mm.value_top) })
  }

  // ì œì•½ â†’ profile.constraint (0.04)
  if (mm.constraint_flags?.length) {
    facts.push({ fact_key: 'profile.constraint', value_json: JSON.stringify(mm.constraint_flags) })
  }

  // ì›Œí¬ìŠ¤íƒ€ì¼ â†’ profile.workstyle (0.04)
  if (mm.workstyle_top?.length) {
    facts.push({ fact_key: 'profile.workstyle', value_json: JSON.stringify(mm.workstyle_top) })
  }

  // ì—ë„ˆì§€/ì‹¤í–‰/ê°ˆë“± â†’ profile.behavioral (0.04, ë³µí•©)
  const behavioral: string[] = []
  if (mm.energy_drain_flags?.length) behavioral.push(...mm.energy_drain_flags)
  if (mm.execution_style) behavioral.push(mm.execution_style)
  if (mm.failure_response) behavioral.push(mm.failure_response)
  if (mm.impact_scope) behavioral.push(mm.impact_scope)
  if (behavioral.length) {
    facts.push({ fact_key: 'profile.behavioral', value_json: JSON.stringify(behavioral) })
  }

  return facts
}

// ============================================
// Phase 4 Metrics Events Helper
// ============================================
async function savePhase4MetricsEvents(
  db: D1Database,
  sessionId: string,
  userId: string | undefined,
  requestId: number,
  result: AnalysisResultJSON
): Promise<void> {
  try {
    // Phase 4 ì ìš© ì—¬ë¶€ í™•ì¸
    if (!result.phase4_applied) return
    
    // 1. Diversity Guard ì ìš© ì´ë²¤íŠ¸
    if (result.diversity_guard_active) {
      await db.prepare(`
        INSERT INTO raw_events (user_id, session_id, event_type, payload_json)
        VALUES (?, ?, 'DIVERSITY_GUARD_APPLIED', ?)
      `).bind(
        userId || null,
        sessionId,
        JSON.stringify({
          request_id: requestId,
          changes: result.diversity_changes || [],
          top3_jobs: result.fit_top3?.map(j => j.job_name) || [],
        })
      ).run()
    }
    
    // 2. Research Bias Cap ì ìš© ì—¬ë¶€ í™•ì¸ (diversity_changesì—ì„œ ì¶”ë¡ )
    const researchBiasApplied = (result.diversity_changes || []).some(
      change => change.includes('ì—°êµ¬') || change.includes('research') || change.includes('Diversity Guard')
    )
    if (researchBiasApplied) {
      await db.prepare(`
        INSERT INTO raw_events (user_id, session_id, event_type, payload_json)
        VALUES (?, ?, 'RESEARCH_BIAS_CAP_APPLIED', ?)
      `).bind(
        userId || null,
        sessionId,
        JSON.stringify({
          request_id: requestId,
          original_changes: result.diversity_changes || [],
        })
      ).run()
    }
    
  } catch (error) {
    // ë©”íŠ¸ë¦­ìŠ¤ ì €ì¥ ì‹¤íŒ¨ëŠ” ë¶„ì„ ê²°ê³¼ì— ì˜í–¥ ì—†ìŒ
  }
}

// ============================================
// Bindings (Cloudflare Workers)
// ============================================
interface Bindings {
  DB: D1Database
  VECTORIZE?: VectorizeIndex
  AI?: Ai
  GEMINI_API_KEY?: string
  OPENAI_API_KEY?: string  // .dev.varsì—ì„œ ë¡œë“œë¨
  JWT_SECRET: string
  [key: string]: unknown
}

// ============================================
// AI Analyzer Routes
// ============================================
const analyzerRoutes = new Hono<{ Bindings: Bindings }>()

// ============================================
// POST /analyze - ë¶„ì„ ìš”ì²­ (V3: Stage-based + V2 í˜¸í™˜)
// ============================================
interface AnalysisRequestPayloadV2 extends AnalysisRequestPayload {
  deep_intake?: DeepIntakeInput
}

// V3 ë˜ëŠ” V2 í˜ì´ë¡œë“œ ë‘˜ ë‹¤ ì²˜ë¦¬
type AnalyzePayload = AnalysisRequestPayloadV3 | AnalysisRequestPayloadV2

analyzerRoutes.post('/analyze', async (c) => {
  const db = c.env.DB
  const rawPayload = await c.req.json<AnalyzePayload>()
  
  // ì¸ì¦ëœ ì‚¬ìš©ì ID ê°€ì ¸ì˜¤ê¸° (authMiddlewareì—ì„œ ì„¤ì •)
  const authUser = (c as any).get('user') as { id: number } | null
  const userId = authUser?.id?.toString() || rawPayload.user_id || null
  
  // Phase 3: í¸ì§‘ ëª¨ë“œ íŒŒë¼ë¯¸í„°
  const editMode = (rawPayload as any).edit_mode === true
  const editSessionId = (rawPayload as any).edit_session_id as string | undefined
  const sourceRequestId = (rawPayload as any).source_request_id as number | undefined
  const versionNote = (rawPayload as any).version_note as string | undefined

  try {
    // V3 vs V2 íŒë³„
    const isV3 = 'stage' in rawPayload && 'universal_answers' in rawPayload
    
    // 1. ì…ë ¥ ê²€ì¦
    if (!rawPayload.session_id) {
      logError('VALIDATION_ERROR', 'session_id is required')
      return c.json(createErrorResponse('VALIDATION_ERROR', 'session_id is required'), 400)
    }
    
    // V3 ì¶”ê°€ ê²€ì¦
    let stage: AnalysisStage | undefined
    let universalAnswers: UniversalAnswers = {}
    let debugMode = false
    
    if (isV3) {
      const v3Payload = rawPayload as AnalysisRequestPayloadV3
      debugMode = v3Payload.debug || false
      
      if (!isValidStage(v3Payload.stage)) {
        logError('INVALID_STAGE', `Invalid stage: ${v3Payload.stage}`, { provided: v3Payload.stage })
        return c.json(createErrorResponse('INVALID_STAGE', `Invalid stage: ${v3Payload.stage}`, {
          provided: v3Payload.stage,
          allowed: ['job_explore', 'job_student', 'job_early', 'major_child', 'major_elementary', 'major_middle', 'major_high', 'major_freshman', 'major_student', 'major_graduate']
        }), 400)
      }
      stage = v3Payload.stage
      universalAnswers = v3Payload.universal_answers || {}
      
      // 2a. Stage ì„ íƒ ì´ë²¤íŠ¸ ì €ì¥ [ìˆ˜ì •ì‚¬í•­ 2: CHECK ì œì•½ ì—†ì´ ë¬¸ìì—´ë¡œ ê¸°ë¡]
      await db.prepare(`
        INSERT INTO raw_events (user_id, session_id, event_type, payload_json, client_meta)
        VALUES (?, ?, 'STAGE_SELECTED', ?, ?)
      `).bind(
        userId,  // ì¸ì¦ëœ ì‚¬ìš©ì ID ì‚¬ìš©
        v3Payload.session_id,
        JSON.stringify({ stage: v3Payload.stage, analysis_type: v3Payload.analysis_type }),
        c.req.header('User-Agent') || null
      ).run()
      
      // 2b. Universal ì œì¶œ ì´ë²¤íŠ¸ ì €ì¥
      if (Object.keys(universalAnswers).length > 0) {
        await db.prepare(`
          INSERT INTO raw_events (user_id, session_id, event_type, payload_json)
          VALUES (?, ?, 'UNIVERSAL_SUBMITTED', ?)
        `).bind(
          v3Payload.user_id || null,
          v3Payload.session_id,
          JSON.stringify(universalAnswers)
        ).run()
        
        // Universal answers â†’ facts ì €ì¥
        await saveUniversalFacts(db, v3Payload.session_id, v3Payload.user_id, universalAnswers, stage)
        
        // ============================================
        // Conversation Turns ì €ì¥ (P1 ê¸°ëŠ¥)
        // ============================================
        try {
          let turnNumber = await getNextTurnNumber(db, v3Payload.session_id)
          
          for (const [questionId, answer] of Object.entries(universalAnswers)) {
            if (answer === null || answer === undefined) continue
            
            const answerStr = Array.isArray(answer) ? answer.join(', ') : String(answer)
            const signals = extractSignalsFromAnswer(answerStr)
            
            await saveConversationTurn(db, {
              session_id: v3Payload.session_id,
              user_id: v3Payload.user_id,
              turn_number: turnNumber,
              turn_type: 'universal_intake',
              question_id: questionId,
              answer_raw: answerStr,
              answer_type: Array.isArray(answer) ? 'multi_choice' : 'text',
              extracted_signals: signals,
            })
            turnNumber++
          }
        } catch (turnError) {
          // ëŒ€í™” í„´ ì €ì¥ ì‹¤íŒ¨í•´ë„ ë¶„ì„ì€ ê³„ì† ì§„í–‰ (graceful degradation)
        }
      }
      
      // ============================================
      // P0: 5ì¶• ìƒíƒœì¢Œí‘œ ì €ì¥ (career_state)
      // ============================================
      if (v3Payload.career_state) {
        try {
          await saveCareerStateFacts(db, v3Payload.session_id, v3Payload.user_id, v3Payload.career_state)
        } catch (stateError) {
        }
      }
      
      // ============================================
      // P0: ì „ì´ ì‹ í˜¸ ì €ì¥ (transition_signal)
      // ============================================
      if (v3Payload.transition_signal) {
        try {
          await saveTransitionSignalFacts(db, v3Payload.session_id, v3Payload.user_id, v3Payload.transition_signal)
        } catch (transError) {
        }
      }
    } else {
      // V2: ê¸°ì¡´ ë¡œì§
      const v2Payload = rawPayload as AnalysisRequestPayloadV2
      if (!v2Payload.profile) {
        logError('VALIDATION_ERROR', 'profile is required for V2 payload', { session_id: rawPayload.session_id })
        return c.json(createErrorResponse('VALIDATION_ERROR', 'profile is required for V2 payload'), 400)
      }
      
      // 2. Raw event ì €ì¥ (V2)
      await db.prepare(`
        INSERT INTO raw_events (user_id, session_id, event_type, payload_json, client_meta)
        VALUES (?, ?, 'ANALYSIS_REQUESTED', ?, ?)
      `).bind(
        v2Payload.user_id || null,
        v2Payload.session_id,
        JSON.stringify(v2Payload),
        c.req.header('User-Agent') || null
      ).run()
    }
    
    // 3. Deep Intake ì²˜ë¦¬ (V2/V3 ê³µí†µ)
    let normalizedDeepIntake: NormalizedDeepIntake | undefined
    const deepIntake = (rawPayload as any).deep_intake as DeepIntakeInput | undefined
    
    if (deepIntake) {
      // [ìˆ˜ì •ì‚¬í•­ 3] ë¯¸ì„±ë…„ ë‹¨ê³„ì—ì„œëŠ” Deep Intake ì„œì‚¬í˜• ì§ˆë¬¸ ì œí•œ
      if (stage && isMinorStage(stage)) {
        // ë¯¸ì„±ë…„ ë‹¨ê³„: MBTI, priorityë§Œ í—ˆìš©, ì˜¤í”ˆí…ìŠ¤íŠ¸ëŠ” ë¬´ì‹œ
        const sanitizedDeepIntake: DeepIntakeInput = {
          mbti: deepIntake.mbti,
          priority_top1: deepIntake.priority_top1,
          // best_moment, worst_moment, change_reasonì€ ë¬´ì‹œ
        }
        normalizedDeepIntake = normalizeDeepIntake(sanitizedDeepIntake)
      } else {
        normalizedDeepIntake = normalizeDeepIntake(deepIntake)
      }
      
      // Deep Intake ì´ë²¤íŠ¸ ì €ì¥
      await db.prepare(`
        INSERT INTO raw_events (user_id, session_id, event_type, payload_json)
        VALUES (?, ?, 'DEEP_INTAKE_SUBMITTED', ?)
      `).bind(
        rawPayload.user_id || null,
        rawPayload.session_id,
        JSON.stringify({ raw: deepIntake, normalized: normalizedDeepIntake })
      ).run()
      
      // Deep Intake â†’ facts ì €ì¥
      await saveDeepIntakeFacts(db, rawPayload.session_id, rawPayload.user_id, normalizedDeepIntake)
    }
    
    // 4. ê¸°ì¡´ facts ì¡°íšŒ (ì´ ì„¸ì…˜ì—ì„œ ìˆ˜ì§‘ëœ)
    const existingFacts = await db.prepare(`
      SELECT fact_key, value_json, confidence, fact_level
      FROM facts
      WHERE session_id = ?
      ORDER BY fact_level ASC, collected_at DESC
    `).bind(rawPayload.session_id).all<{
      fact_key: string
      value_json: string
      confidence: number
      fact_level: number
    }>()
    
    const facts = existingFacts.results || []
    
    // 5. ë¶„ì„ ìš”ì²­ ìƒì„± (ë²„ì „ ì ê¸ˆ)
    const analysisType = isV3 
      ? ((rawPayload as AnalysisRequestPayloadV3).analysis_type || 'job')
      : ((rawPayload as AnalysisRequestPayloadV2).analysis_type || 'job')
    
    const promptPayload = isV3
      ? JSON.stringify({ stage, universal_answers: universalAnswers })
      : JSON.stringify((rawPayload as AnalysisRequestPayloadV2).profile)
    
    // Phase 3: í¸ì§‘ ëª¨ë“œ ë²„ì „ ê³„ì‚°
    let parentRequestId: number | null = null
    let versionNumber: number = 1
    let requestVersionNote: string | null = null

    if (editMode && sourceRequestId) {
      parentRequestId = sourceRequestId
      requestVersionNote = versionNote || 'ì…ë ¥ ìˆ˜ì •'
      const maxVer = await db.prepare(`
        SELECT COALESCE(MAX(version_number), 1) as max_ver
        FROM ai_analysis_requests WHERE session_id = ?
      `).bind(rawPayload.session_id).first<{ max_ver: number }>()
      versionNumber = (maxVer?.max_ver || 1) + 1
    }

    const requestResult = await db.prepare(`
      INSERT INTO ai_analysis_requests (
        session_id, user_id, analysis_type, pricing_tier, prompt_payload,
        status, recipe_version, tagger_version, scoring_version,
        parent_request_id, version_number, version_note
      )
      VALUES (?, ?, ?, ?, ?, 'processing', ?, ?, ?, ?, ?, ?)
      RETURNING id
    `).bind(
      rawPayload.session_id,
      userId,
      analysisType,
      (rawPayload as any).pricing_tier || 'free',
      promptPayload,
      VERSIONS.recipe,
      VERSIONS.tagger,
      VERSIONS.scoring,
      parentRequestId,
      versionNumber,
      requestVersionNote
    ).first<{ id: number }>()
    
    if (!requestResult) {
      logError('DB_ERROR', 'Failed to create analysis request', { session_id: rawPayload.session_id })
      return c.json(createErrorResponse('DB_ERROR', 'Failed to create analysis request'), 500)
    }
    
    const requestId = requestResult.id
    
    // 6. ë¶„ì„ ì‹¤í–‰ (V3ëŠ” stage + debug ì „ë‹¬ + Vectorize í™•ì¥)
    const env = c.env as Bindings
    const result = await runAnalysisV3(
      db, 
      rawPayload, 
      requestId, 
      facts, 
      normalizedDeepIntake,
      stage,
      debugMode,
      { VECTORIZE: env.VECTORIZE, AI: env.AI }
    )
    
    // 7. ê²°ê³¼ ì €ì¥
    await db.prepare(`
      INSERT INTO ai_analysis_results (request_id, result_json)
      VALUES (?, ?)
    `).bind(requestId, JSON.stringify(result)).run()
    
    // 8. ìš”ì²­ ìƒíƒœ ì—…ë°ì´íŠ¸
    await db.prepare(`
      UPDATE ai_analysis_requests
      SET status = 'completed', processed_at = CURRENT_TIMESTAMP
      WHERE id = ?
    `).bind(requestId).run()
    
    // 9. ì™„ë£Œ ì´ë²¤íŠ¸ ì €ì¥
    await db.prepare(`
      INSERT INTO raw_events (user_id, session_id, event_type, payload_json)
      VALUES (?, ?, 'ANALYSIS_COMPLETED', ?)
    `).bind(
      rawPayload.user_id || null,
      rawPayload.session_id,
      JSON.stringify({ 
        request_id: requestId, 
        facts_applied: facts.length,
        has_deep_intake: !!normalizedDeepIntake,
        stage: stage || null,
        is_v3: isV3,
      })
    ).run()
    
    // 10. Phase 4 ë©”íŠ¸ë¦­ìŠ¤ ì´ë²¤íŠ¸ ì €ì¥
    await savePhase4MetricsEvents(db, rawPayload.session_id, rawPayload.user_id, requestId, result)

    // 11. Phase 3: í¸ì§‘ ëª¨ë“œ ì„ì‹œ draft ì‚­ì œ
    if (editMode && editSessionId && userId) {
      try {
        await db.prepare('DELETE FROM analyzer_drafts WHERE session_id = ? AND user_id = ?')
          .bind(editSessionId, parseInt(userId)).run()
      } catch { }
    }

    return c.json({
      success: true,
      request_id: requestId,
      result,
      facts_applied: facts.length,
      deep_intake_processed: !!normalizedDeepIntake,
      stage: stage || null,
    })
    
  } catch (error) {
    const message = error instanceof Error ? error.message : 'Unknown error'
    logError('ANALYSIS_FAILED', message, {
      session_id: rawPayload.session_id,
      stack: error instanceof Error ? error.stack : undefined
    })
    return c.json(createErrorResponse('ANALYSIS_FAILED', 'Analysis failed', {
      message: 'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
      session_id: rawPayload.session_id
    }), 500)
  }
})

// ============================================
// P0: 5ì¶• ìƒíƒœì¢Œí‘œ â†’ facts ì €ì¥
// ============================================
async function saveCareerStateFacts(
  db: D1Database,
  sessionId: string,
  userId: string | undefined,
  careerState: {
    role_identity: string
    career_stage_years: string
    transition_status: string
    skill_level: number
    constraints: Record<string, { has_constraint: boolean; details?: string }>
  }
): Promise<void> {
  // ì¶• 1: role_identity
  if (careerState.role_identity) {
    await db.prepare(`
      INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level)
      VALUES (?, ?, 'state.role_identity', ?, 1.0, 'career_state', 2)
      ON CONFLICT(session_id, fact_key) DO UPDATE SET
        value_json = excluded.value_json,
        collected_at = CURRENT_TIMESTAMP
    `).bind(sessionId, userId || null, JSON.stringify({ value: careerState.role_identity })).run()
  }
  
  // ì¶• 2: career_stage_years
  if (careerState.career_stage_years) {
    await db.prepare(`
      INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level)
      VALUES (?, ?, 'state.career_stage_years', ?, 1.0, 'career_state', 2)
      ON CONFLICT(session_id, fact_key) DO UPDATE SET
        value_json = excluded.value_json,
        collected_at = CURRENT_TIMESTAMP
    `).bind(sessionId, userId || null, JSON.stringify({ value: careerState.career_stage_years })).run()
  }
  
  // ì¶• 3: transition_status
  if (careerState.transition_status) {
    await db.prepare(`
      INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level)
      VALUES (?, ?, 'state.transition_status', ?, 1.0, 'career_state', 2)
      ON CONFLICT(session_id, fact_key) DO UPDATE SET
        value_json = excluded.value_json,
        collected_at = CURRENT_TIMESTAMP
    `).bind(sessionId, userId || null, JSON.stringify({ value: careerState.transition_status })).run()
  }
  
  // ì¶• 4: skill_level
  if (careerState.skill_level !== undefined) {
    await db.prepare(`
      INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level)
      VALUES (?, ?, 'state.skill_level', ?, 1.0, 'career_state', 2)
      ON CONFLICT(session_id, fact_key) DO UPDATE SET
        value_json = excluded.value_json,
        collected_at = CURRENT_TIMESTAMP
    `).bind(sessionId, userId || null, JSON.stringify({ value: careerState.skill_level })).run()
  }
  
  // ì¶• 5: constraints (P0-6: 2ë‹¨ ì €ì¥)
  for (const [type, constraint] of Object.entries(careerState.constraints || {})) {
    // has_constraint ì €ì¥
    await db.prepare(`
      INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level)
      VALUES (?, ?, ?, ?, 1.0, 'career_state', 2)
      ON CONFLICT(session_id, fact_key) DO UPDATE SET
        value_json = excluded.value_json,
        collected_at = CURRENT_TIMESTAMP
    `).bind(
      sessionId,
      userId || null,
      `state.constraint.${type}`,
      JSON.stringify({ value: !!constraint.has_constraint })
    ).run()
    
    // detail ì €ì¥ (ìˆì„ ë•Œë§Œ)
    if (constraint.has_constraint && constraint.details) {
      await db.prepare(`
        INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level)
        VALUES (?, ?, ?, ?, 1.0, 'career_state', 2)
        ON CONFLICT(session_id, fact_key) DO UPDATE SET
          value_json = excluded.value_json,
          collected_at = CURRENT_TIMESTAMP
      `).bind(
        sessionId,
        userId || null,
        `state.constraint.${type}_detail`,
        JSON.stringify({ value: constraint.details })
      ).run()
    }
  }
}

// ============================================
// P0: ì „ì´ ì‹ í˜¸ â†’ facts ì €ì¥
// ============================================
async function saveTransitionSignalFacts(
  db: D1Database,
  sessionId: string,
  userId: string | undefined,
  transitionSignal: Record<string, string | string[]>
): Promise<void> {
  for (const [questionId, answer] of Object.entries(transitionSignal)) {
    if (answer === null || answer === undefined) continue
    
    // fact_key ë§¤í•‘
    const factKeyMap: Record<string, string> = {
      'trans_desired_type': 'transition.desired_type',
      'trans_motivation': 'transition.motivation_primary',
      'trans_blockers': 'transition.blocker',
      'trans_timeline': 'transition.timeline',
      'trans_time_invest': 'transition.time_invest_hours_bucket',
    }
    
    const factKey = factKeyMap[questionId] || `transition.${questionId}`
    
    if (Array.isArray(answer)) {
      // ë°°ì—´ ë‹µë³€: ranked ì €ì¥ (ìˆœìœ„ í¬í•¨)
      for (let i = 0; i < answer.length; i++) {
        const rankFactKey = `${factKey}[${i}]`
        await db.prepare(`
          INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level)
          VALUES (?, ?, ?, ?, 1.0, 'transition_signal', 3)
          ON CONFLICT(session_id, fact_key) DO UPDATE SET
            value_json = excluded.value_json,
            collected_at = CURRENT_TIMESTAMP
        `).bind(
          sessionId,
          userId || null,
          rankFactKey,
          JSON.stringify({ value: answer[i], rank: i + 1 })
        ).run()
      }
      
      // ì „ì²´ ë°°ì—´ë„ ì €ì¥ (í¸ì˜ìš©)
      await db.prepare(`
        INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level)
        VALUES (?, ?, ?, ?, 1.0, 'transition_signal', 3)
        ON CONFLICT(session_id, fact_key) DO UPDATE SET
          value_json = excluded.value_json,
          collected_at = CURRENT_TIMESTAMP
      `).bind(
        sessionId,
        userId || null,
        factKey,
        JSON.stringify({ value: answer })
      ).run()
    } else {
      // ë‹¨ì¼ ë‹µë³€
      await db.prepare(`
        INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level)
        VALUES (?, ?, ?, ?, 1.0, 'transition_signal', 3)
        ON CONFLICT(session_id, fact_key) DO UPDATE SET
          value_json = excluded.value_json,
          collected_at = CURRENT_TIMESTAMP
      `).bind(
        sessionId,
        userId || null,
        factKey,
        JSON.stringify({ value: answer })
      ).run()
    }
  }
}

// ============================================
// V3: Universal Answers â†’ facts ì €ì¥
// ============================================
async function saveUniversalFacts(
  db: D1Database,
  sessionId: string,
  userId: string | undefined,
  answers: UniversalAnswers,
  stage?: AnalysisStage
): Promise<void> {
  const UNIVERSAL_QUESTIONS_MAP = new Map(
    UNIVERSAL_QUESTIONS.map(q => [q.question_id, q])
  )
  
  // Universal ì œì•½ì¡°ê±´ â†’ confirmed_constraint ë§¤í•‘
  // ì‚¬ìš©ìê°€ "ì ˆëŒ€ ë¶ˆê°€"ë¡œ ì„ íƒí•œ ì œì•½ì€ Phase 4 Hard Filter ëŒ€ìƒ
  const CONSTRAINT_TO_CONFIRMED: Record<string, string> = {
    'no_overtime': 'work_hours_strict',
    'no_shift': 'shift_work_no',
    'no_travel': 'travel_impossible',
    'remote_only': 'remote_only',
    'no_degree': 'degree_impossible',
    'no_license': 'license_impossible',
  }
  
  for (const [questionId, answer] of Object.entries(answers)) {
    if (answer === null || answer === undefined) continue
    if (Array.isArray(answer) && answer.length === 0) continue
    if (typeof answer === 'string' && answer.trim() === '') continue
    
    const question = UNIVERSAL_QUESTIONS_MAP.get(questionId)
    if (!question) continue
    
    // ì •ê·œí™”
    const normalized = normalizeUniversalAnswer(question, answer)
    
    // fact_level ê²°ì •
    const factLevel = determineUniversalFactLevel(question.fact_key)
    
    await db.prepare(`
      INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level, question_id)
      VALUES (?, ?, ?, ?, 1.0, 'universal', ?, ?)
      ON CONFLICT(session_id, fact_key) DO UPDATE SET
        value_json = excluded.value_json,
        collected_at = CURRENT_TIMESTAMP
    `).bind(
      sessionId,
      userId || null,
      question.fact_key,
      JSON.stringify(normalized),
      factLevel,
      questionId
    ).run()
    
    // ğŸ”¥ Phase 4 Hard Filter ìë™ ìŠ¹ê²©
    // ì œì•½ì¡°ê±´ ì§ˆë¬¸(univ_constraint_*)ì´ë©´ confirmed_constraintë„ ì €ì¥
    if (questionId.startsWith('univ_constraint_')) {
      const values = Array.isArray(answer) ? answer : [answer]
      
      for (const value of values) {
        const confirmedType = CONSTRAINT_TO_CONFIRMED[value]
        if (confirmedType) {
          await db.prepare(`
            INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level)
            VALUES (?, ?, ?, ?, 1.0, 'universal', 1)
            ON CONFLICT(session_id, fact_key) DO UPDATE SET
              value_json = excluded.value_json,
              fact_level = 1,
              collected_at = CURRENT_TIMESTAMP
          `).bind(
            sessionId,
            userId || null,
            `confirmed_constraint.${confirmedType}`,
            JSON.stringify({ 
              confirmed: true, 
              source: 'universal_intake',
              original_value: value,
              confirmed_at: new Date().toISOString() 
            })
          ).run()
        }
      }
    }
  }
}

// Universal ë‹µë³€ ì •ê·œí™”
function normalizeUniversalAnswer(
  question: UniversalQuestion,
  answer: string | string[]
): { value: string | string[]; tags: string[]; raw?: string } {
  const values = Array.isArray(answer) ? answer : [answer]
  const tags: string[] = []
  
  // ì˜µì…˜ì—ì„œ íƒœê·¸ ì¶”ì¶œ
  if (question.options) {
    for (const val of values) {
      const option = question.options.find(o => o.value === val)
      if (option?.tags) {
        tags.push(...option.tags)
      }
    }
  }
  
  // í…ìŠ¤íŠ¸ ì •ê·œí™” (freetextìš©)
  if (question.normalize_rule === 'keywords' && typeof answer === 'string') {
    return {
      value: answer,
      tags: extractKeywordTags(answer),
      raw: answer,
    }
  }
  
  return {
    value: answer,
    tags: [...new Set(tags)],
  }
}

// í‚¤ì›Œë“œ ê¸°ë°˜ íƒœê·¸ ì¶”ì¶œ (freetextìš©)
function extractKeywordTags(text: string): string[] {
  const tags: string[] = []
  const lowerText = text.toLowerCase()
  
  // ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
  const keywordMap: Record<string, string[]> = {
    'ê±´ê°•': ['health'],
    'ì•„í”„': ['health'],
    'ëŒë´„': ['caregiving'],
    'ê°€ì¡±': ['caregiving', 'family'],
    'ì•„ì´': ['caregiving'],
    'ì›ê²©': ['remote'],
    'ì¬íƒ': ['remote'],
    'ì•¼ê·¼': ['work_hours_strict'],
    'ì €ë…': ['work_hours_strict', 'wlb'],
    'ì¶œí‡´ê·¼': ['commute'],
  }
  
  for (const [keyword, keywordTags] of Object.entries(keywordMap)) {
    if (lowerText.includes(keyword)) {
      tags.push(...keywordTags)
    }
  }
  
  return [...new Set(tags)]
}

// Universal fact_level ê²°ì •
function determineUniversalFactLevel(factKey: string): number {
  if (factKey.startsWith('profile.constraints')) return 2
  if (factKey.startsWith('priority.')) return 2
  if (factKey.startsWith('profile.life_constraint')) return 2
  if (factKey.startsWith('profile.')) return 4
  if (factKey.startsWith('discovery.')) return 3
  return 4
}

// ============================================
// Phase 1C: Deep Intake â†’ facts ì €ì¥
// ============================================
async function saveDeepIntakeFacts(
  db: D1Database,
  sessionId: string,
  userId: string | undefined,
  normalized: NormalizedDeepIntake
): Promise<void> {
  // MBTI ì €ì¥
  if (normalized.mbti) {
    await db.prepare(`
      INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level)
      VALUES (?, ?, 'profile.mbti', ?, 1.0, 'deep_intake', 4)
      ON CONFLICT(session_id, fact_key) DO UPDATE SET
        value_json = excluded.value_json,
        collected_at = CURRENT_TIMESTAMP
    `).bind(
      sessionId,
      userId || null,
      JSON.stringify({ value: normalized.mbti, traits: normalized.mbti_traits })
    ).run()
  }
  
  // best_moment ì €ì¥
  if (normalized.best_moment) {
    await db.prepare(`
      INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level)
      VALUES (?, ?, 'discovery.best_moment', ?, 0.9, 'deep_intake', 3)
      ON CONFLICT(session_id, fact_key) DO UPDATE SET
        value_json = excluded.value_json,
        collected_at = CURRENT_TIMESTAMP
    `).bind(
      sessionId,
      userId || null,
      JSON.stringify(normalized.best_moment)
    ).run()
  }
  
  // worst_moment ì €ì¥
  if (normalized.worst_moment) {
    await db.prepare(`
      INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level)
      VALUES (?, ?, 'discovery.worst_moment', ?, 0.9, 'deep_intake', 3)
      ON CONFLICT(session_id, fact_key) DO UPDATE SET
        value_json = excluded.value_json,
        collected_at = CURRENT_TIMESTAMP
    `).bind(
      sessionId,
      userId || null,
      JSON.stringify(normalized.worst_moment)
    ).run()
  }
  
  // change_reason ì €ì¥
  if (normalized.change_reason) {
    await db.prepare(`
      INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level)
      VALUES (?, ?, 'motivation.change_reason', ?, 0.9, 'deep_intake', 3)
      ON CONFLICT(session_id, fact_key) DO UPDATE SET
        value_json = excluded.value_json,
        collected_at = CURRENT_TIMESTAMP
    `).bind(
      sessionId,
      userId || null,
      JSON.stringify(normalized.change_reason)
    ).run()
  }
  
  // priority.top1 ì €ì¥
  if (normalized.priority_top1) {
    await db.prepare(`
      INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level)
      VALUES (?, ?, 'priority.top1', ?, 1.0, 'deep_intake', 2)
      ON CONFLICT(session_id, fact_key) DO UPDATE SET
        value_json = excluded.value_json,
        collected_at = CURRENT_TIMESTAMP
    `).bind(
      sessionId,
      userId || null,
      JSON.stringify({ value: normalized.priority_top1 })
    ).run()
  }
}

// ============================================
// ì‹¤ì¡´ì  ì§ˆë¬¸ ë‹µë³€ LLM ë¶„ì„ (ë¹„ë™ê¸° ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)
// "7ì¼ ë’¤ ì§€êµ¬ ë©¸ë§" ì‹œë‚˜ë¦¬ì˜¤ ë‹µë³€ì—ì„œ ì¡´ì¬ ê¸°ë°˜ ê°€ì¹˜ ì¶”ì¶œ
// ============================================
async function analyzeExistentialAnswer(
  db: D1Database,
  sessionId: string,
  userId: string | undefined,
  rawAnswer: string,
  openaiApiKey?: string,
): Promise<void> {
  if (!openaiApiKey) {
    return
  }


  // 1. ì›ë¬¸ ì €ì¥ (fact)
  await db.prepare(`
    INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level)
    VALUES (?, ?, 'existential.priority_raw', ?, 1.0, 'deep_intake', 2)
    ON CONFLICT(session_id, fact_key) DO UPDATE SET
      value_json = excluded.value_json,
      collected_at = CURRENT_TIMESTAMP
  `).bind(sessionId, userId || null, JSON.stringify(rawAnswer)).run()

  // 2. LLM êµ¬ì¡°ì  ë¶„ì„
  const systemPrompt = `ë‹¹ì‹ ì€ ì‹¬ë¦¬ ë¶„ì„ê°€ì´ì ì»¤ë¦¬ì–´ ì „ëµê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìëŠ” ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí–ˆìŠµë‹ˆë‹¤:
"ë§Œì•½ 7ì¼ ë’¤ ë˜ëŒë¦´ ìˆ˜ ì—†ëŠ” ìš°ì£¼ì  ì¬ë‚œìœ¼ë¡œ ì§€êµ¬ê°€ ì‚¬ë¼ì§„ë‹¤ë©´, ê·¸ 7ì¼ì„ ì–´ë””ì—ì„œ, ëˆ„êµ¬ì™€, ë¬´ì—‡ì„ í•˜ë©° ë³´ë‚´ê³  ì‹¶ì€ê°€? ê·¸ë¦¬ê³  ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€?"

ì•„ë˜ ì‚¬ìš©ìì˜ ë‹µë³€ì„ ê°ì •ì ìœ¼ë¡œ ìš”ì•½í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
ë„ë•ì  í‰ê°€ë¥¼ í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
ì¹­ì°¬í•˜ê±°ë‚˜ ìœ„ë¡œí•˜ì§€ ë§ˆì‹­ì‹œì˜¤.

ëŒ€ì‹ , ë‹¤ìŒ í•­ëª©ì„ êµ¬ì¡°ì ìœ¼ë¡œ ë¶„ì„í•˜ì‹­ì‹œì˜¤.

1. ì£¼ìš” í–‰ë™ ì§€í–¥ì„± (Primary Action Orientation)
ë‹¤ìŒ ì¤‘ ê°€ì¥ ê°€ê¹Œìš´ ìœ í˜•ì„ ì„ íƒ:
- ê´€ê³„ ì¤‘ì‹¬í˜•
- ì„±ì·¨ ì¶”êµ¬í˜•
- ììœ /íƒí—˜ ì§€í–¥í˜•
- ì˜ë¯¸ íƒìƒ‰í˜•
- ì±…ì„ ìˆ˜í–‰í˜•
- ìê¸°í‘œí˜„í˜•
- íšŒí”¼/ë¬´ê¸°ë ¥í˜•
- ê²½í—˜ ì†Œë¹„í˜•

2. í•µì‹¬ ê°€ì¹˜ ì‹ í˜¸ (ìµœëŒ€ 3ê°œ ì„ íƒ)
ì•„ë˜ ì¤‘ì—ì„œë§Œ ì„ íƒ:
ê´€ê³„, ì„±ì·¨, ììœ , ì•ˆì •, ì˜ë¯¸, ì˜í–¥ë ¥, ì¸ì •, ì„±ì¥, ê¸°ì—¬, ê²½í—˜, ìê¸°í‘œí˜„, ì†Œì†

3. ì‹œê°„ ì§€í–¥ì„±
ë‹¤ìŒ ì¤‘ ì„ íƒ:
- í˜„ì¬ ëª°ì…í˜•
- ê´€ê³„ ì •ë¦¬í˜•
- ìœ ì‚° ë‚¨ê¸°ê¸°í˜•
- í›„íšŒ ë³´ì™„í˜•
- ì´ˆì›”/ì² í•™í˜•

4. ì •ì„œì  í†¤
ë‹¤ìŒ ì¤‘ ì„ íƒ:
ìˆ˜ìš©, ê¸´ë°•, ë‘ë ¤ì›€, í‰ì˜¨, ì²´ë…, ì €í•­, ê³µí—ˆ, ì„±ì°°

5. ì ì¬ì  ê´´ë¦¬ ë¶„ì„
ì‚¬ìš©ìì˜ ë§ˆì§€ë§‰ 7ì¼ ì„ íƒì´ ì¼ë°˜ì ì¸ ì‚¬íšŒì  ì„±ê³µ ê²½ë¡œì™€ ì–¼ë§ˆë‚˜ ë‹¤ë¥¸ì§€ í•œ ì¤„ë¡œ ë¶„ì„í•˜ì‹­ì‹œì˜¤.

6. ì§ì—… ì„¤ê³„ì— ì‹œì‚¬ì 
ì´ ë‹µë³€ì´ ì»¤ë¦¬ì–´ ë°©í–¥ ì„¤ì •ì— ì–´ë–¤ ì‹ í˜¸ë¥¼ ì£¼ëŠ”ì§€ 2~3ì¤„ë¡œ ë¶„ì„í•˜ì‹­ì‹œì˜¤.

ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
{
  "primary_orientation": "...",
  "core_values": ["...", "..."],
  "time_orientation": "...",
  "emotional_tone": "...",
  "hidden_gap_analysis": "...",
  "career_implication": "..."
}`

  try {
    const { callOpenAI } = await import('./openai-client')
    const { response } = await callOpenAI(openaiApiKey, [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: `[USER_DATA]\n${rawAnswer}\n[/USER_DATA]` },
    ], {
      temperature: 0.3,
      max_tokens: 800,
    })

    // JSON íŒŒì‹±
    const jsonMatch = response.match(/\{[\s\S]*\}/)
    if (!jsonMatch) {
      return
    }

    const structured = JSON.parse(jsonMatch[0])

    // 3. êµ¬ì¡°ì  ë¶„ì„ ê²°ê³¼ ì €ì¥ (fact)
    await db.prepare(`
      INSERT INTO facts (session_id, user_id, fact_key, value_json, confidence, source_type, fact_level)
      VALUES (?, ?, 'existential.priority_structured', ?, 0.85, 'inferred', 2)
      ON CONFLICT(session_id, fact_key) DO UPDATE SET
        value_json = excluded.value_json,
        collected_at = CURRENT_TIMESTAMP
    `).bind(sessionId, userId || null, JSON.stringify(structured)).run()

  } catch (error) {
  }
}

// ============================================
// POST /followup - Follow-up ì‘ë‹µ ì²˜ë¦¬ (facts ì €ì¥)
// ============================================
analyzerRoutes.post('/followup', async (c) => {
  const db = c.env.DB
  const payload = await c.req.json<FollowupPayloadV2>()
  
  try {
    // 1. í•„ìˆ˜ í•„ë“œ ê²€ì¦
    if (!payload.session_id || !payload.question_id || payload.answer === undefined) {
      logError('VALIDATION_ERROR', 'session_id, question_id, and answer are required')
      return c.json(createErrorResponse('VALIDATION_ERROR', 'session_id, question_id, and answer are required'), 400)
    }
    
    // 2. Raw event ì €ì¥ (ì›ë¬¸ ê·¸ëŒ€ë¡œ)
    await db.prepare(`
      INSERT INTO raw_events (user_id, session_id, event_type, payload_json)
      VALUES (?, ?, 'FOLLOWUP_ANSWERED', ?)
    `).bind(
      payload.user_id || null,
      payload.session_id,
      JSON.stringify(payload)
    ).run()
    
    // ============================================
    // Conversation Turn ì €ì¥ (P1 ê¸°ëŠ¥)
    // ============================================
    try {
      const turnNumber = await getNextTurnNumber(db, payload.session_id)
      const answerStr = payload.answer_text || String(payload.answer)
      const signals = extractSignalsFromAnswer(answerStr)
      
      // FollowupV3 íƒ€ì…ì¸ì§€ í™•ì¸ (purpose ê¸°ë°˜)
      const turnType: TurnType = payload.question_type ? 
        (['contradiction_resolver', 'decision_variable', 'reality_constraint'].includes(payload.question_type) 
          ? 'followup_v3' 
          : 'followup_v2') 
        : 'followup_v2'
      
      await saveConversationTurn(db, {
        session_id: payload.session_id,
        user_id: payload.user_id,
        request_id: payload.request_id,
        turn_number: turnNumber,
        turn_type: turnType,
        question_id: payload.question_id,
        question_type: payload.question_type as any,
        answer_raw: answerStr,
        answer_type: payload.answer_text ? 'text' : 'single_choice',
        extracted_signals: signals,
        affected_dimensions: payload.affects_attributes,
      })
    } catch (turnError) {
      // ëŒ€í™” í„´ ì €ì¥ ì‹¤íŒ¨í•´ë„ followup ì²˜ë¦¬ëŠ” ê³„ì† ì§„í–‰
    }
    
    // 3. fact_keyì™€ value ê²°ì •
    const factKey = payload.fact_key || `answer.${payload.question_id}`
    const factLevel = determineFctLevel(factKey)
    
    // 4. facts í…Œì´ë¸”ì— ì €ì¥ (UPSERT - ê°™ì€ session+fact_keyë©´ ê°±ì‹ )
    await db.prepare(`
      INSERT INTO facts (
        session_id, user_id, fact_key, value_json, confidence, question_id, 
        source_type, fact_level
      )
      VALUES (?, ?, ?, ?, ?, ?, 'followup', ?)
      ON CONFLICT(session_id, fact_key) DO UPDATE SET
        value_json = excluded.value_json,
        confidence = excluded.confidence,
        collected_at = CURRENT_TIMESTAMP
    `).bind(
      payload.session_id,
      payload.user_id || null,
      factKey,
      JSON.stringify({ value: payload.answer, raw: payload.answer_text }),
      payload.confidence || 1.0,
      payload.question_id,
      factLevel
    ).run()
    
    // 5. question_history ì—…ë°ì´íŠ¸
    await db.prepare(`
      INSERT INTO question_history (session_id, question_id, question_type, attribute, answer_value)
      VALUES (?, ?, ?, ?, ?)
      ON CONFLICT(session_id, question_id) DO UPDATE SET
        answered_at = CURRENT_TIMESTAMP,
        answer_value = excluded.answer_value
    `).bind(
      payload.session_id,
      payload.question_id,
      payload.question_type || 'unknown',
      payload.attribute || null,
      payload.answer
    ).run()
    
    // 6. ê¸°ì¡´ constraint ê¸°ë°˜ followup ì²˜ë¦¬ (backward compatibility)
    if (payload.constraint && payload.request_id) {
      const constraint = assertConstraintType(payload.constraint)
      
      await db.prepare(`
        INSERT INTO followup_responses (
          request_id, question_id, constraint_type, job_id, job_name, answer
        )
        VALUES (?, ?, ?, ?, ?, ?)
      `).bind(
        payload.request_id,
        payload.question_id,
        constraint,
        payload.job_id || null,
        payload.job_name || null,
        payload.answer
      ).run()
      
      if (payload.answer === 'no') {
        await db.prepare(`
          INSERT OR IGNORE INTO confirmed_constraints (
            session_id, user_id, request_id, constraint_type, constraint_value
          )
          VALUES (?, ?, ?, ?, ?)
        `).bind(
          payload.session_id,
          payload.user_id || null,
          payload.request_id,
          constraint,
          'true'
        ).run()
      }
    }
    
    // 7. Phase 4: answer="no"ë©´ Safe Replacement ì²˜ë¦¬
    if (payload.answer === 'no' && payload.job_id && payload.request_id) {
      // í˜„ì¬ ê²°ê³¼ì—ì„œ í›„ë³´êµ°ê³¼ TOP3 ê°€ì ¸ì˜¤ê¸°
      const existingResult = await db.prepare(`
        SELECT result_json FROM ai_analysis_results WHERE request_id = ?
      `).bind(payload.request_id).first<{ result_json: string }>()
      
      if (existingResult) {
        try {
          const resultData = JSON.parse(existingResult.result_json)
          
          // TOP3ì™€ ì „ì²´ í›„ë³´êµ° êµ¬ì„±
          const originalTop3: ScoredJob[] = (resultData.fit_top3 || []).map((j: any) => ({
            job_id: j.job_id,
            job_name: j.job_name,
            scores: {
              fit: j.fit_score || 0,
              like: j.like_score || 0,
              can: j.can_score || 0,
              risk_penalty: 0,
            },
            attributes: {},
          }))
          
          // ì „ì²´ í›„ë³´ëŠ” like_top10ê³¼ can_top10 í•©ì³ì„œ êµ¬ì„± (dedupe)
          const allJobIds = new Set<string>()
          const allCandidates: ScoredJob[] = []
          
          for (const source of [resultData.fit_top3, resultData.like_top10, resultData.can_top10]) {
            if (!source) continue
            for (const j of source) {
              if (!allJobIds.has(j.job_id)) {
                allJobIds.add(j.job_id)
                allCandidates.push({
                  job_id: j.job_id,
                  job_name: j.job_name,
                  scores: {
                    fit: j.fit_score || j.like_score || 0,
                    like: j.like_score || 0,
                    can: j.can_score || 0,
                    risk_penalty: 0,
                  },
                  attributes: {},
                })
              }
            }
          }
          
          // constraint íƒ€ì… ê²°ì •
          const constraintType = payload.constraint || factKey.replace('answer.', '')
          
          // Phase 4 Safe Replacement ì‹¤í–‰
          const safeResult = await handleFollowupNo(
            db,
            payload.session_id,
            payload.user_id,
            payload.question_id,
            constraintType,
            payload.job_id,
            allCandidates,
            originalTop3,
            payload.request_id
          )
          
          // Phase 4 ê²°ê³¼ ë°˜í™˜
          return c.json({
            success: true,
            phase4_applied: true,
            fact_saved: {
              fact_key: factKey,
              value: payload.answer,
              fact_level: factLevel,
            },
            ...safeResult,
          })
          
        } catch (error) {
          // Phase 4 ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ì‘ë‹µì€ ë°˜í™˜
        }
      }
    }
    
    // 8. ì‘ë‹µ êµ¬ì„± (Phase 4 ë¯¸ì ìš© ì‹œ)
    const result: FollowupResultV2 = {
      success: true,
      fact_saved: {
        fact_key: factKey,
        value: payload.answer,
        fact_level: factLevel,
      },
      reanalyze_available: true,
      message: 'ë‹µë³€ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ì¬ë¶„ì„ ì‹œ ë°˜ì˜ë©ë‹ˆë‹¤.',
    }
    
    return c.json(result)
    
  } catch (error) {
    const message = error instanceof Error ? error.message : 'Unknown error'
    logError('ANALYSIS_FAILED', `Followup failed: ${message}`, {
      stack: error instanceof Error ? error.stack : undefined
    })
    return c.json(createErrorResponse('ANALYSIS_FAILED', 'Followup failed', { message }), 500)
  }
})

// ============================================
// GET /result/:requestId - ê²°ê³¼ ì¡°íšŒ (ì¸ì¦ + ì†Œìœ ê¶Œ í™•ì¸)
// ============================================
analyzerRoutes.get('/result/:requestId', async (c) => {
  const db = c.env.DB
  const requestId = parseInt(c.req.param('requestId'), 10)

  const providedId = c.req.param('requestId')
  if (isNaN(requestId)) {
    logError('VALIDATION_ERROR', 'Invalid request_id', { provided: providedId })
    return c.json(createErrorResponse('VALIDATION_ERROR', 'Invalid request_id', { provided: providedId }), 400)
  }

  try {
    const request = await db.prepare(`
      SELECT * FROM ai_analysis_requests WHERE id = ?
    `).bind(requestId).first<{
      id: number
      session_id: string
      user_id: string | null
      [key: string]: any
    }>()

    if (!request) {
      logError('REQUEST_NOT_FOUND', 'Analysis request not found', { request_id: requestId })
      return c.json(createErrorResponse('REQUEST_NOT_FOUND', 'Analysis request not found', { request_id: requestId }), 404)
    }

    // ì†Œìœ ê¶Œ í™•ì¸: ë¡œê·¸ì¸ ìœ ì € â†’ user_id ë§¤ì¹­, ë¹„ë¡œê·¸ì¸ â†’ session_id ë§¤ì¹­
    const authUser = (c as any).get('user') as { id: number; role?: string } | null
    const querySessionId = c.req.query('session_id')

    if (request.user_id) {
      // user_idê°€ ìˆëŠ” ê²°ê³¼: ë³¸ì¸ ë˜ëŠ” adminë§Œ ì ‘ê·¼ ê°€ëŠ¥
      if (!authUser) {
        return c.json(createErrorResponse('AUTH_REQUIRED', 'ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.'), 401)
      }
      if (String(authUser.id) !== String(request.user_id) && authUser.role !== 'admin') {
        return c.json(createErrorResponse('FORBIDDEN', 'ë³¸ì¸ì˜ ë¶„ì„ ê²°ê³¼ë§Œ ì¡°íšŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'), 403)
      }
    } else {
      // user_idê°€ ì—†ëŠ” ìµëª… ê²°ê³¼: session_id ë§¤ì¹­ í•„ìˆ˜
      if (!authUser && !querySessionId) {
        return c.json(createErrorResponse('AUTH_REQUIRED', 'ë¡œê·¸ì¸ ë˜ëŠ” session_idê°€ í•„ìš”í•©ë‹ˆë‹¤.'), 401)
      }
      if (!authUser || (authUser.role !== 'admin')) {
        // ë¹„ë¡œê·¸ì¸ ë˜ëŠ” ì¼ë°˜ ìœ ì €: session_id ê²€ì¦
        if (!querySessionId || querySessionId !== request.session_id) {
          return c.json(createErrorResponse('FORBIDDEN', 'ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.'), 403)
        }
      }
    }

    const result = await db.prepare(`
      SELECT * FROM ai_analysis_results WHERE request_id = ?
    `).bind(requestId).first<{ result_json: string }>()

    const followups = await db.prepare(`
      SELECT * FROM followup_responses WHERE request_id = ?
    `).bind(requestId).all()

    return c.json({
      request,
      result: result ? JSON.parse(result.result_json) : null,
      followups: followups.results,
    })

  } catch (error) {
    const message = error instanceof Error ? error.message : 'Unknown error'
    logError('DB_ERROR', `Failed to fetch result: ${message}`, {
      request_id: requestId,
      stack: error instanceof Error ? error.stack : undefined
    })
    return c.json(createErrorResponse('DB_ERROR', 'Failed to fetch result', {
      message,
      request_id: requestId
    }), 500)
  }
})

// ============================================
// GET /session/:sessionId - ì„¸ì…˜ ì´ë ¥ ì¡°íšŒ
// ============================================
analyzerRoutes.get('/session/:sessionId', async (c) => {
  const db = c.env.DB
  const sessionId = c.req.param('sessionId')
  
  try {
    const events = await db.prepare(`
      SELECT * FROM raw_events 
      WHERE session_id = ?
      ORDER BY created_at ASC
    `).bind(sessionId).all()
    
    const requests = await db.prepare(`
      SELECT * FROM ai_analysis_requests
      WHERE session_id = ?
      ORDER BY requested_at ASC
    `).bind(sessionId).all()
    
    const constraints = await db.prepare(`
      SELECT * FROM confirmed_constraints
      WHERE session_id = ?
    `).bind(sessionId).all()
    
    // Phase 1A: facts ì¡°íšŒ ì¶”ê°€
    const facts = await db.prepare(`
      SELECT * FROM facts
      WHERE session_id = ?
      ORDER BY fact_level ASC, collected_at DESC
    `).bind(sessionId).all()
    
    return c.json({
      session_id: sessionId,
      events: events.results,
      requests: requests.results,
      confirmed_constraints: constraints.results,
      facts: facts.results,  // Phase 1A ì¶”ê°€
    })
    
  } catch (error) {
    const message = error instanceof Error ? error.message : 'Unknown error'
    logError('DB_ERROR', `Failed to fetch session: ${message}`, {
      session_id: sessionId,
      stack: error instanceof Error ? error.stack : undefined
    })
    return c.json(createErrorResponse('DB_ERROR', 'Failed to fetch session', { 
      message, 
      session_id: sessionId 
    }), 500)
  }
})

// ============================================
// GET /facts/:sessionId - ì„¸ì…˜ì˜ factsë§Œ ì¡°íšŒ
// ============================================
analyzerRoutes.get('/facts/:sessionId', async (c) => {
  const db = c.env.DB
  const sessionId = c.req.param('sessionId')
  
  try {
    const facts = await db.prepare(`
      SELECT * FROM facts
      WHERE session_id = ?
      ORDER BY fact_level ASC, collected_at DESC
    `).bind(sessionId).all()
    
    return c.json({
      session_id: sessionId,
      facts: facts.results,
      count: facts.results?.length || 0,
    })
    
  } catch (error) {
    logError('DB_ERROR', 'Failed to fetch facts', { session_id: sessionId })
    return c.json(createErrorResponse('DB_ERROR', 'Failed to fetch facts', { session_id: sessionId }), 500)
  }
})

// ============================================
// Analysis Logic (Phase 1A MVE)
// ============================================

interface Fact {
  fact_key: string
  value_json: string
  confidence: number
  fact_level: number
}

async function runAnalysis(
  db: D1Database,
  payload: AnalysisRequestPayloadV2,
  requestId: number,
  facts: Fact[],
  deepIntake?: NormalizedDeepIntake
): Promise<AnalysisResultJSON> {
  // 1. jobs + job_attributes JOINìœ¼ë¡œ ì‹¤ì œ DB ì§ì—…ë§Œ ì¡°íšŒ (íƒœê¹… ì—¬ë¶€ ë¬´ê´€)
  // 2026-01-26: tagger_version ì¡°ê±´ ì œê±° - ëª¨ë“  ì§ì—… ê²€ìƒ‰ ê°€ëŠ¥
  const jobAttrs = await db.prepare(`
    SELECT
      ja.job_id, ja.job_name,
      j.slug, j.image_url, j.api_data_json, j.merged_profile_json, j.ai_data_json,
      COALESCE(ja.wlb, 50) as wlb,
      COALESCE(ja.growth, 50) as growth,
      COALESCE(ja.stability, 50) as stability,
      COALESCE(ja.income, 50) as income,
      COALESCE(ja.teamwork, 50) as teamwork,
      COALESCE(ja.solo_deep, 50) as solo_deep,
      COALESCE(ja.analytical, 50) as analytical,
      COALESCE(ja.creative, 50) as creative,
      COALESCE(ja.execution, 50) as execution,
      COALESCE(ja.people_facing, 50) as people_facing,
      COALESCE(ja.work_hours, 'regular') as work_hours,
      COALESCE(ja.shift_work, 'rare') as shift_work,
      COALESCE(ja.travel, 'rare') as travel,
      COALESCE(ja.remote_possible, 'possible') as remote_possible,
      COALESCE(ja.degree_required, 'none') as degree_required,
      COALESCE(ja.license_required, 'none') as license_required
    FROM job_attributes ja
    INNER JOIN jobs j ON ja.job_id = j.id
    ORDER BY RANDOM()
    LIMIT 500
  `).all<{
    job_id: string
    job_name: string
    slug: string
    image_url: string | null
    api_data_json: string | null
    merged_profile_json: string | null
    ai_data_json: string | null
    wlb: number
    growth: number
    stability: number
    income: number
    teamwork: number
    solo_deep: number
    analytical: number
    creative: number
    execution: number
    people_facing: number
    work_hours: string
    shift_work: string
    travel: string
    remote_possible: string
    degree_required: string
    license_required: string
  }>()

  // V2ì—ì„œë„ mini_module_result ì¶”ì¶œ (ê°œì¸í™” ìŠ¤ì½”ì–´ë§)
  const v2MiniModule = 'mini_module_result' in payload ? (payload as any).mini_module_result : undefined

  // DBì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìƒ˜í”Œ ì‚¬ìš© (ìƒ˜í”Œì€ DBì— ì—†ëŠ” ì§ì—…ì´ë¯€ë¡œ ì¶”ì²œì—ì„œ ì œì™¸)
  const sampleJobs = (jobAttrs.results && jobAttrs.results.length > 0)
    ? jobAttrs.results.map(j => {
        const personalized = calculatePersonalizedBaseScores(j, v2MiniModule)
        return {
          job_id: j.job_id,
          job_name: j.job_name,
          slug: j.slug,
          image_url: j.image_url,
          job_description: extractJobDescription(j.api_data_json, j.merged_profile_json, j.job_name, j.ai_data_json),
          base_like: personalized.like,
          base_can: personalized.can,
          base_risk: 10,  // ê¸°ë³¸ risk
          attributes: {
            wlb: j.wlb,
            growth: j.growth,
            stability: j.stability,
            income: j.income,
            remote: j.remote_possible === 'full' ? 100 : j.remote_possible === 'partial' ? 50 : 0,
            solo_work: j.solo_deep,
            people_facing: j.people_facing,
            analytical: j.analytical,
            creative: j.creative,
          },
        }
      })
    : [] // DB ì—°ê²° ì‹¤íŒ¨ì‹œ ë¹ˆ ë°°ì—´ (ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš© ì•ˆí•¨)
  
  // DB ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬ ë°˜í™˜
  if (sampleJobs.length === 0) {
    throw new Error('ì§ì—… ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. job_attributes í…Œì´ë¸”ì„ í™•ì¸í•˜ì„¸ìš”.')
  }
  
  // 2. Fact boosts ê³„ì‚°
  const factBoosts = calculateFactBoosts(facts)
  
  // 3. ê° ì§ì—…ì— ì ìˆ˜ ì ìš© (slug, image_url í¬í•¨)
  const scoredJobs: ScoredJob[] = sampleJobs.map(job => {
    const baseScores: JobScores = {
      like: job.base_like,
      can: job.base_can,
      risk_penalty: job.base_risk,
    }

    const adjusted = applyFactBoostsToJob(baseScores, job.attributes, factBoosts)

    // P0: Can-Like ë°¸ëŸ°ìŠ¤ ìº¡ ì ìš©
    const balanced = applyBalanceCap(adjusted.like, adjusted.can)
    const fit = Math.round(0.55 * balanced.like + 0.45 * balanced.can - adjusted.risk_penalty)

    // ì„ì‹œ scoredJob ê°ì²´ ìƒì„± (explanation ìƒì„±ìš©)
    const tempScoredJob: ScoredJob = {
      job_id: job.job_id,
      job_name: job.job_name,
      slug: job.slug,
      image_url: job.image_url || undefined,
      job_description: job.job_description,
      scores: {
        fit: Math.max(0, fit),
        like: balanced.like,
        can: balanced.can,
        risk_penalty: adjusted.risk_penalty,
      },
      attributes: job.attributes,
    }

    // ê·¼ê±° ìƒì„± (V2: facts ê¸°ë°˜)
    const explanation = generateJobExplanation(tempScoredJob, facts, factBoosts.applied_rules)
    const rationale = `[ì¢‹ì•„í•  ì´ìœ ] ${explanation.like_reason} [ì˜í•  ì´ìœ ] ${explanation.can_reason}`

    return {
      ...tempScoredJob,
      rationale,
      likeReason: explanation.like_reason,
      canReason: explanation.can_reason,
      riskWarning: explanation.risk_warning,
    }
  })
  
  // 4. ì •ë ¬ (Fit ê¸°ì¤€) + ì •ë¬´ì§/ì„ëª…ì§ ì œê±°
  scoredJobs.sort((a, b) => b.scores.fit - a.scores.fit)
  const filteredScoredJobs = filterNicheMaterialJobs(filterUnrealisticJobs(scoredJobs), v2MiniModule)

  // í‰ê°€ ì§ì—… 100ê°œë¡œ í™•ì¥ (ê¸°ì¡´ 10ê°œ -> 100ê°œ)
  const top10 = filteredScoredJobs.slice(0, 100)

  // Phase 4: Diversity Guard (ë‚´ë¶€ì—ì„œ Research Bias Capë„ ì ìš©)
  const rawTop5 = top10.slice(0, 5)
  const diversityResult = applyDiversityGuard(rawTop5, filteredScoredJobs)
  const top3 = diversityResult.adjusted

  // 5. Follow-up ì§ˆë¬¸ ìƒì„± (Deep Intake ì—¬ë¶€ ë°˜ì˜)
  const existingFactKeys = facts.map(f => ({ fact_key: f.fact_key }))
  const followupQuestions = generateFollowupQuestions({
    candidates: scoredJobs,
    topK: top10,
    existingFacts: existingFactKeys,
    hasDeepIntake: !!deepIntake,  // Phase 1C: Deep Intake ì—¬ë¶€ ì „ë‹¬
  }, 3)
  
  // 6. Phase 1C: User Insight ìƒì„±
  const userInsight = generateUserInsight(facts, deepIntake, factBoosts.applied_rules)
  
  // 7. Premium Report ìƒì„± (V3)
  const premiumReportInput: PremiumReportInput = {
    session_id: `session-${requestId}`,
    facts: facts.map(f => ({ fact_key: f.fact_key, value_json: f.value_json })),
    recommendations: top10.map(j => ({
      job_id: j.job_id,
      job_name: j.job_name,
      slug: j.slug,
      image_url: j.image_url,
      scores: j.scores,
      attributes: j.attributes as Record<string, number>,
    })),
    userInsight: userInsight,
  }
  const premiumReport = fixParticlesDeep(generatePremiumReport(premiumReportInput))

  // 8. ê²°ê³¼ êµ¬ì„±
  const result: AnalysisResultJSON = {
    engine_state: deepIntake ? 'phase1a_mve' : (facts.length > 0 ? 'phase1a_mve' : 'phase1a_initial'),
    engine_version: RECOMMENDATION_ENGINE_VERSION,
    mini_module_result: miniModuleForFilter || null,

    versions: {
      recipe: VERSIONS.recipe,
      tagger: VERSIONS.tagger,
      scoring: VERSIONS.scoring,
    },

    input_summary: {
      profile_revision_id: `rev-${requestId}-${Date.now()}`,
      key_interests: payload.profile.interest.keywords.slice(0, 3),
      key_skills: payload.profile.skill.map(s => s.name).slice(0, 3),
      non_negotiables: Object.entries(payload.profile.constraints || {})
        .filter(([_, v]) => v === true)
        .map(([k]) => k),
      preferences: [],
      facts_applied: facts.length,
      applied_rules: factBoosts.applied_rules,
      // Phase 1C: Deep Intake ì •ë³´ ì¶”ê°€
      deep_intake_provided: !!deepIntake,
      insight_tags: userInsight?.key_traits.map(t => t.trait) || [],
    },
    
    fit_top3: top3.map(j => {
      // Evidence ìƒì„± (facts + job attributes ê¸°ë°˜)
      // âš ï¸ EvidenceëŠ” "ì„¤ëª…ìš©"ì´ë©° ì ìˆ˜ ê³„ì‚°ì— ì˜í–¥ ì—†ìŒ
      const evidenceFacts: EvidenceFact[] = facts.map(f => ({
        fact_key: f.fact_key,
        value_json: f.value_json,
      }))
      let evidenceLinks = buildEvidenceLinks(evidenceFacts, j)
      
      // Evidenceê°€ ë¶€ì¡±í•˜ë©´ ê¸°ë³¸ Evidence ì¶”ê°€
      if (evidenceLinks.length < 3) {
        const defaultEvidence = generateDefaultEvidence(j)
        evidenceLinks = [...evidenceLinks, ...defaultEvidence].slice(0, 10)
      }
      
      // Dislike ê²½ê³  ìƒì„±
      const dislikeWarnings = generateDislikeWarnings(facts, j)
      
      return {
        job_id: j.job_id,
        job_name: j.job_name,
        slug: j.slug,
        image_url: j.image_url,
        job_description: j.job_description || null,
        rationale: j.rationale || null,
        like_reason: j.likeReason || null,
        can_reason: j.canReason || null,
        fit_score: j.scores.fit,
        like_score: j.scores.like,
        can_score: j.scores.can,
        risk_details: [],
        evidence_links: evidenceLinks,
        dislike_warnings: dislikeWarnings, // íšŒí”¼ ìš”ì†Œ ê²½ê³ 
      }
    }),

    // like_top10: like_score ê¸°ì¤€ + ë‹¤ì–‘ì„± ê°•ì œ + v3.9.2 ìµœì¢… ì•ˆì „ë§(ì •ì¹˜ì§ ì œê±°)
    like_top10: sanitizeJobListOutput(enforceDiversityOnTopN(
      [...filteredScoredJobs].filter(j => j.scores.fit >= 25).sort((a, b) => b.scores.like - a.scores.like).slice(0, 20),
      filteredScoredJobs, 'like', 10
    ).diversified.map(j => ({
        job_id: j.job_id,
        job_name: j.job_name,
        slug: j.slug,
        image_url: j.image_url,
        job_description: j.job_description || null,
        fit_score: j.scores.fit,
        like_score: j.scores.like,
        can_score: j.scores.can,
        rationale: j.rationale || null,
        like_reason: j.likeReason || null,
        can_reason: j.canReason || null,
      }))),

    // can_top10: can_score ê¸°ì¤€ + ë‹¤ì–‘ì„± ê°•ì œ + v3.9.2 ìµœì¢… ì•ˆì „ë§(ì •ì¹˜ì§ ì œê±°)
    can_top10: sanitizeJobListOutput(enforceDiversityOnTopN(
      [...filteredScoredJobs].filter(j => j.scores.fit >= 25).sort((a, b) => b.scores.can - a.scores.can).slice(0, 20),
      filteredScoredJobs, 'can', 10
    ).diversified.map(j => ({
        job_id: j.job_id,
        job_name: j.job_name,
        slug: j.slug,
        image_url: j.image_url,
        job_description: j.job_description || null,
        fit_score: j.scores.fit,
        like_score: j.scores.like,
        can_score: j.scores.can,
        rationale: j.rationale || null,
        like_reason: j.likeReason || null,
        can_reason: j.canReason || null,
      }))),

    caution_jobs: scoredJobs
      .filter(j => j.scores.risk_penalty > 20)
      .slice(0, 5)
      .map(j => ({
        job_id: j.job_id,
        job_name: j.job_name,
        slug: j.slug,
        image_url: j.image_url,
        risk_penalty: j.scores.risk_penalty,
      })),
    
    // Phase 1A: followup_questions ì¶”ê°€!
    followup_questions: followupQuestions,
    
    ux_flags: {
      has_caution_in_top3: top3.some(j => j.scores.risk_penalty > 20),
      has_unknown_in_top3: false,
      needs_followup_question: followupQuestions.length > 0,
      counts_before_filter: {
        safe_known: scoredJobs.filter(j => j.scores.risk_penalty <= 10).length,
        safe_unknown: scoredJobs.filter(j => j.scores.risk_penalty > 10 && j.scores.risk_penalty <= 20).length,
        caution: scoredJobs.filter(j => j.scores.risk_penalty > 20).length,
        total: scoredJobs.length,
      },
      counts_after_filter: {
        safe_known: scoredJobs.filter(j => j.scores.risk_penalty <= 10).length,
        safe_unknown: scoredJobs.filter(j => j.scores.risk_penalty > 10 && j.scores.risk_penalty <= 20).length,
        caution: scoredJobs.filter(j => j.scores.risk_penalty > 20).length,
        total: scoredJobs.length,
      },
    },
    
    llm_explanation: generateExplanation(facts, factBoosts.applied_rules, top3[0]?.job_name),
    generated_at: new Date().toISOString(),
    total_candidates: scoredJobs.length,
    
    // Phase 1C: User Insight ì¶”ê°€
    user_insight: userInsight,
    
    // Phase 4: Diversity Guard ì •ë³´
    phase4_applied: true,
    diversity_guard_active: diversityResult.diversityApplied,
    diversity_changes: diversityResult.changes,
    
    // V3: Premium Report
    premium_report: premiumReport,
  }
  
  return result
}

// ============================================
// í•œêµ­ì–´ ì¡°ì‚¬ í—¬í¼ (ë°›ì¹¨ ìœ ë¬´ ìë™ íŒë³„)
// ============================================
// v3.9.2: Top N likeReason ìµœì¢… ë‹¤ì–‘ì„± ë³´ì¥
// ìƒìœ„ ì§ì—…ë“¤ì´ ëª¨ë‘ ê°™ì€ íŒ¨í„´ì´ë©´ ê°•ì œ ìŠ¤íƒ€ì¼ ë¶„ì‚°
// ============================================
// ë”°ì˜´í‘œ ì¢…ë¥˜ í†µí•© ê°ì§€ (straight: ' U+0027, smart: \u2018 \u2019 \u201C \u201D)
function startsWithQuote(s: string): boolean {
  const ch = s.charAt(0)
  return ch === "'" || ch === '\u2018' || ch === '\u2019' || ch === '"' || ch === '\u201C'
}
function findClosingQuote(s: string, start: number): number {
  for (let i = start; i < s.length; i++) {
    const ch = s.charAt(i)
    if (ch === "'" || ch === '\u2019' || ch === '\u2018' || ch === '"' || ch === '\u201D') return i
  }
  return -1
}

function diversifyTopNReasons(jobs: Array<ScoredJob & { likeReason?: string }>): void {
  if (jobs.length < 2) return

  const withReason = jobs.filter(j => j.likeReason && j.likeReason.length > 10)
  if (withReason.length < 2) return

  // íŒ¨í„´ ê°ì§€: ë”°ì˜´í‘œ(straight/smart ëª¨ë‘)ë¡œ ì‹œì‘í•˜ëŠ” ë¹„ìœ¨
  const quoteStart = withReason.filter(j => startsWithQuote(j.likeReason!)).length
  if (quoteStart < 2) return


  for (let i = 0; i < withReason.length; i++) {
    const j = withReason[i]
    const original = j.likeReason!
    if (!startsWithQuote(original)) continue

    const style = i % 3

    const quoteEnd = findClosingQuote(original, 1)
    if (quoteEnd <= 1) continue

    // v3.9.8: style=0(A)ì—ì„œ ì „ì²´ê°€ ë”°ì˜´í‘œë¡œ ê°ì‹¸ì§„ ê²½ìš° â†’ ë”°ì˜´í‘œ ë²—ê¸°ê¸°
    if (style === 0) {
      const lastChar = original.charAt(original.length - 1)
      if (lastChar === "'" || lastChar === '\u2019' || lastChar === '\u201D' || lastChar === '"') {
        j.likeReason = original.substring(1, original.length - 1).trim()
      }
      continue  // ë‚˜ë¨¸ì§€ ìŠ¤íƒ€ì¼AëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
    }

    // v3.9.7: ë‹«ëŠ” ë”°ì˜´í‘œ ë’¤ ì¸ìš© ì†ì„±êµ¬ í†µí•© ì œê±°
    // "í•˜ì…¨ëŠ”ë°"ë¥¼ ì•µì»¤ë¡œ ì‚¬ìš© â€” ëª¨ë“  ì¡°ì‚¬/ì—°ê²°ì–´ë¯¸ íŒ¨í„´ ì¼ê´„ ì²˜ë¦¬
    const rawAfterQuote = original.substring(quoteEnd + 1)
    const hsIdx = rawAfterQuote.indexOf('í•˜ì…¨ëŠ”ë°')
    let afterQuote: string
    if (hsIdx >= 0 && hsIdx < 60) {
      afterQuote = rawAfterQuote.substring(hsIdx + 4).replace(/^[,.\s]*/, '').trim()
    } else {
      afterQuote = rawAfterQuote
        .replace(/^(?:[ì„ë¥¼]\s*ì¤‘ì‹œí•œë‹¤\s*)?(?:ì´?\s*ë¼ê³ \s*)?(?:ê³ \s*)?[,.\s]*/, '')
        .trim()
    }
    // v3.9.8: afterQuote ëì˜ ì”ì—¬ ë”°ì˜´í‘œ ì œê±°
    afterQuote = afterQuote.replace(/['"'\u2018\u2019\u201C\u201D]+$/g, '').trim()
    const quoteContent = original.substring(1, quoteEnd)

    // v3.9.4: ì „ì²´ê°€ ë”°ì˜´í‘œë¡œ ê°ì‹¸ì§„ ê²½ìš° (afterQuoteê°€ ë¹ˆ ë¬¸ìì—´)
    // ì˜ˆ: 'ì•ˆì •ì„ ì¤‘ì‹œí•œë‹¤ê³  í•˜ì…¨ëŠ”ë°, ì´ ì§ì—…ì€ ì•ˆì •ì„± 80/100ì´ê³ ...'
    // â†’ ë”°ì˜´í‘œ ì•ˆì—ì„œ "í•˜ì…¨ëŠ”ë°" ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
    if (afterQuote.length <= 5) {
      const splitPatterns = ['ê³  í•˜ì…¨ëŠ”ë°,', 'í•˜ì…¨ëŠ”ë°,', 'ê³  í•˜ì…¨ëŠ”ë°']
      for (const pat of splitPatterns) {
        const idx = quoteContent.indexOf(pat)
        if (idx > 0) {
          const userQuote = quoteContent.substring(0, idx).trim()
          afterQuote = quoteContent.substring(idx + pat.length).trim()
            .replace(/[\s,'"'\u2018\u2019\u201C\u201D]+$/g, '').trim()
          if (afterQuote.length > 5) {
            if (style === 1) {
              j.likeReason = `${afterQuote} ${userQuote} ì„±í–¥ê³¼ ë¶€í•©í•©ë‹ˆë‹¤`
            } else if (style === 2) {
              j.likeReason = `íŠ¹ì§•ì ìœ¼ë¡œ ${afterQuote}`
            }
          }
          break
        }
      }
      continue
    }

    if (style === 1 && afterQuote.length > 5) {
      j.likeReason = `${afterQuote} ${quoteContent} ì„±í–¥ê³¼ ë¶€í•©í•©ë‹ˆë‹¤`
    } else if (style === 2 && afterQuote.length > 5) {
      j.likeReason = `íŠ¹ì§•ì ìœ¼ë¡œ ${afterQuote}`
    }
  }
}

// ============================================
function hasBatchim(word: string): boolean {
  if (!word || word.length === 0) return false
  const last = word.charCodeAt(word.length - 1)
  if (last >= 0xAC00 && last <= 0xD7A3) return (last - 0xAC00) % 28 !== 0
  // ìˆ«ì: 0(ì˜),1(ì¼),3(ì‚¼),6(ìœ¡),7(ì¹ ),8(íŒ”) = ë°›ì¹¨ ìˆìŒ
  if (last >= 0x30 && last <= 0x39) return [0,1,3,6,7,8].includes(last - 0x30)
  return false
}
/** ì€/ëŠ” */
function ì€ëŠ”(w: string): string { return hasBatchim(w) ? 'ì€' : 'ëŠ”' }
/** ì´/ê°€ */
function ì´ê°€(w: string): string { return hasBatchim(w) ? 'ì´' : 'ê°€' }
/** ì„/ë¥¼ */
function ì„ë¥¼(w: string): string { return hasBatchim(w) ? 'ì„' : 'ë¥¼' }

// ============================================
// Explainability V3: ì§ì—…ë³„ ì¶”ì²œ ê·¼ê±° ìƒì„±
// ============================================
interface JobExplanation {
  like_reason: string    // Like ì ìˆ˜ ê·¼ê±°
  can_reason: string     // Can ì ìˆ˜ ê·¼ê±°
  risk_warning: string   // Risk ê²½ê³  (ìˆìœ¼ë©´)
}

function generateJobExplanation(
  job: ScoredJob,
  facts: Fact[],
  appliedRules: string[],
  mm?: any  // MiniModuleResult (optional)
): JobExplanation {
  const attrs = (job.attributes || {}) as Record<string, number>
  const jobName = job.job_name || 'ì´ ì§ì—…'

  // ============================================
  // Like ê·¼ê±°: ì‚¬ìš©ì í¥ë¯¸/ê°€ì¹˜ â†” ì§ì—… ì†ì„± ë§¤ì¹­
  // ============================================
  const interestLabels: Record<string, string> = {
    problem_solving: 'ë¬¸ì œí•´ê²°', data_numbers: 'ë°ì´í„°/ìˆ«ì', creating: 'ì°½ì‘/ì°½ì˜',
    influencing: 'ì˜í–¥ë ¥/ì„¤ë“', helping_teaching: 'ë„ì›€/êµìœ¡', organizing: 'ì¡°ì§/ê´€ë¦¬',
    tech: 'ê¸°ìˆ /IT', routine: 'ì •í•´ì§„ ì—…ë¬´',
  }
  const valueLabels: Record<string, string> = {
    growth: 'ì„±ì¥', stability: 'ì•ˆì •', autonomy: 'ììœ¨ì„±', wlb: 'ì›Œë¼ë°¸',
    income: 'ìˆ˜ì…', recognition: 'ì¸ì •', meaning: 'ì˜ë¯¸', expertise: 'ì „ë¬¸ì„±',
    creativity: 'ì°½ì˜ì„±',
  }
  // ì§ì—… ì†ì„±ê³¼ ê°€ì¹˜/í¥ë¯¸ ë§¤í•‘
  const valueAttrMap: Record<string, { attr: string, threshold: number }> = {
    growth: { attr: 'growth', threshold: 60 },
    stability: { attr: 'stability', threshold: 60 },
    wlb: { attr: 'wlb', threshold: 60 },
    income: { attr: 'income', threshold: 60 },
  }
  const interestAttrMap: Record<string, { attr: string, threshold: number }> = {
    data_numbers: { attr: 'analytical', threshold: 60 },
    creating: { attr: 'creative', threshold: 60 },
    tech: { attr: 'analytical', threshold: 55 },
    problem_solving: { attr: 'analytical', threshold: 55 },
    helping_teaching: { attr: 'people_facing', threshold: 60 },
    influencing: { attr: 'people_facing', threshold: 55 },
  }

  let likeReason = ''
  const likeReasons: string[] = []

  if (mm) {
    // 1) í¥ë¯¸ ë§¤ì¹­ (ì§ì—…ëª… + ì†ì„±ê°’ í¬í•¨í•˜ì—¬ ì°¨ë³„í™”)
    const interests = mm.interest_top || mm.interests || []
    for (const token of interests) {
      const mapping = interestAttrMap[token]
      const attrVal = mapping ? (attrs[mapping.attr] || 0) : 0
      if (mapping && attrVal >= mapping.threshold) {
        const label = interestLabels[token] || token
        if (attrVal >= 80) {
          likeReasons.push(`${jobName}${ì€ëŠ”(jobName)} ${label} ì—­ëŸ‰ì´ í•µì‹¬ì¸ ì§ì—…ìœ¼ë¡œ, ë‹¹ì‹ ì˜ ê´€ì‹¬ì‚¬ì™€ ë§¤ìš° ì˜ ë§ìŠµë‹ˆë‹¤`)
        } else {
          likeReasons.push(`${jobName}ì—ì„œ ${label} ê´€ë ¨ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•˜ë©° ê´€ì‹¬ì‚¬ë¥¼ ì‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤`)
        }
        break
      }
    }
    // 2) ê°€ì¹˜ ë§¤ì¹­ (ì§ì—…ëª… + êµ¬ì²´ì  ì†ì„± í¬í•¨)
    const values = mm.value_top || mm.values || []
    for (const token of values) {
      const mapping = valueAttrMap[token]
      const attrVal = mapping ? (attrs[mapping.attr] || 0) : 0
      if (mapping && attrVal >= mapping.threshold) {
        const label = valueLabels[token] || token
        if (attrVal >= 80) {
          likeReasons.push(`${label}${ì„ë¥¼(label)} ì¤‘ì‹œí•˜ëŠ” ë‹¹ì‹ ì—ê²Œ ${jobName}${ì€ëŠ”(jobName)} ë†’ì€ ${label} ì§€ìˆ˜(${attrVal}ì )ë¡œ í° ë§Œì¡±ê°ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤`)
        } else {
          likeReasons.push(`${jobName}${ì€ëŠ”(jobName)} ${label} ì¸¡ë©´ì—ì„œ ì–‘í˜¸í•œ í™˜ê²½(${attrVal}ì )ì„ ì œê³µí•©ë‹ˆë‹¤`)
        }
        break
      }
    }
    // 3) í¥ë¯¸ ë¼ë²¨ë§Œì´ë¼ë„
    if (likeReasons.length === 0 && interests.length > 0) {
      const labels = interests.slice(0, 2).map((t: string) => interestLabels[t] || t).join(', ')
      likeReasons.push(`${jobName}${ì€ëŠ”(jobName)} ${labels} ë¶„ì•¼ì— ëŒ€í•œ ê´€ì‹¬ê³¼ ì—°ê²°ë˜ëŠ” ì—…ë¬´ì…ë‹ˆë‹¤`)
    }
  }

  // facts ê¸°ë°˜ ë³´ì¡°
  if (likeReasons.length === 0) {
    const interestFacts = facts.filter(f => f.fact_key.includes('interest') || f.fact_key.includes('priority'))
    if (interestFacts.length > 0) {
      try {
        const parsed = JSON.parse(interestFacts[0].value_json)
        const val = Array.isArray(parsed.value) ? parsed.value[0] : parsed.value
        if (val && interestLabels[val]) {
          likeReasons.push(`${interestLabels[val]} ê´€ì‹¬ì‚¬ì™€ ë§¤ì¹­ë˜ëŠ” ì—…ë¬´ í™˜ê²½ì…ë‹ˆë‹¤`)
        }
      } catch { /* ignore */ }
    }
  }

  likeReason = likeReasons.length > 0
    ? likeReasons.join('. ')
    : `${jobName}${ì€ëŠ”(jobName)} ë‹¹ì‹ ì˜ ê´€ì‹¬ ë¶„ì•¼ì™€ ì—°ê´€ëœ ì§ì—…ì…ë‹ˆë‹¤`

  // ============================================
  // Can ê·¼ê±°: ì‚¬ìš©ì ê°•ì /ì›Œí¬ìŠ¤íƒ€ì¼ â†” ì§ì—… ì†ì„± ë§¤ì¹­
  // ============================================
  const strengthLabels: Record<string, string> = {
    analytical: 'ë¶„ì„ë ¥', fast_learning: 'ë¹ ë¥¸ í•™ìŠµë ¥', creative: 'ì°½ì˜ë ¥',
    communication: 'ì†Œí†µ ëŠ¥ë ¥', persistence: 'ëˆê¸°', leadership: 'ë¦¬ë”ì‹­',
    structured_execution: 'ì²´ê³„ì  ì‹¤í–‰ë ¥',
  }
  const strengthAttrMap: Record<string, { attr: string, threshold: number }> = {
    analytical: { attr: 'analytical', threshold: 55 },
    creative: { attr: 'creative', threshold: 55 },
    communication: { attr: 'people_facing', threshold: 55 },
    leadership: { attr: 'people_facing', threshold: 60 },
    structured_execution: { attr: 'execution', threshold: 55 },
  }
  const workstyleLabels: Record<string, string> = {
    solo: 'í˜¼ì ì§‘ì¤‘í•˜ëŠ”', solo_deep: 'ê¹Šì´ ëª°ì…í•˜ëŠ”', team: 'íŒ€ìœ¼ë¡œ í˜‘ë ¥í•˜ëŠ”',
    team_harmony: 'ì¡°í™”ë¡­ê²Œ ì¼í•˜ëŠ”', structured: 'ì²´ê³„ì ì¸', flexible: 'ììœ ë¡œìš´',
  }

  let canReason = ''
  const canReasons: string[] = []

  if (mm) {
    // 1) ê°•ì  ë§¤ì¹­ (ì§ì—…ëª… + ì†ì„±ê°’ í¬í•¨í•˜ì—¬ ì°¨ë³„í™”)
    const strengths = mm.strength_top || mm.strengths || []
    for (const token of strengths) {
      const mapping = strengthAttrMap[token]
      const attrVal = mapping ? (attrs[mapping.attr] || 0) : 0
      if (mapping && attrVal >= mapping.threshold) {
        const label = strengthLabels[token] || token
        if (attrVal >= 75) {
          canReasons.push(`${jobName}${ì€ëŠ”(jobName)} ${label}${ì´ê°€(label)} í•µì‹¬ ì—­ëŸ‰(${attrVal}ì )ì¸ ì§ì—…ìœ¼ë¡œ, ë‹¹ì‹ ì˜ ê°•ì ì„ ì§ì ‘ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤`)
        } else {
          canReasons.push(`${jobName}ì—ì„œ ë‹¹ì‹ ì˜ ${label} ê°•ì ì´ ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤`)
        }
        break
      }
    }
    // 2) ì›Œí¬ìŠ¤íƒ€ì¼ ë§¤ì¹­
    const workstyles = mm.workstyle_top || []
    if (workstyles.length > 0) {
      const wsLabel = workstyleLabels[workstyles[0]] || ''
      const soloAttr = attrs['solo_work'] || attrs['solo_deep'] || 0
      const peopleAttr = attrs['people_facing'] || 0
      if (workstyles[0]?.includes('solo') && soloAttr >= 60) {
        canReasons.push(`${jobName}${ì€ëŠ”(jobName)} ${wsLabel} ì—…ë¬´ ìŠ¤íƒ€ì¼ì— ë§ëŠ” ë…ë¦½ì ì¸ í™˜ê²½ì…ë‹ˆë‹¤`)
      } else if (workstyles[0]?.includes('team') && peopleAttr >= 60) {
        canReasons.push(`${jobName}${ì€ëŠ”(jobName)} ${wsLabel} ì—…ë¬´ ìŠ¤íƒ€ì¼ì— ë§ëŠ” í˜‘ì—… í™˜ê²½ì…ë‹ˆë‹¤`)
      }
    }
    // 3) ê°•ì  ë¼ë²¨ë§Œì´ë¼ë„
    if (canReasons.length === 0) {
      const strengths2 = mm.strength_top || mm.strengths || []
      if (strengths2.length > 0) {
        const sLabels = strengths2.slice(0, 2).map((t: string) => strengthLabels[t] || t)
        const joinedLabels = sLabels.length > 1 ? `${sLabels[0]}ê³¼ ${sLabels[1]}` : sLabels[0]
        canReasons.push(`${jobName}ì—ì„œ ${joinedLabels}${ì„ë¥¼(joinedLabels)} ë°œíœ˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤`)
      }
    }
  }

  // workstyle fallback from facts
  if (canReasons.length === 0 && appliedRules.includes('profile.workstyle.social')) {
    const styleFact = facts.find(f => f.fact_key === 'profile.workstyle.social')
    if (styleFact) {
      try {
        const sv = JSON.parse(styleFact.value_json)
        const styleMap: Record<string, string> = {
          solo: 'ë…ë¦½ì  ì—…ë¬´ í™˜ê²½ì— ì í•©í•©ë‹ˆë‹¤', team: 'íŒ€ í˜‘ì—… í™˜ê²½ì— ì í•©í•©ë‹ˆë‹¤',
          balanced: 'ê· í˜• ì¡íŒ ì—…ë¬´ í™˜ê²½ì— ì í•©í•©ë‹ˆë‹¤'
        }
        canReasons.push(styleMap[sv.value] || 'ì„ í˜¸í•˜ëŠ” ì—…ë¬´ ìŠ¤íƒ€ì¼ì— ë¶€í•©í•©ë‹ˆë‹¤')
      } catch { /* ignore */ }
    }
  }

  canReason = canReasons.length > 0
    ? canReasons.join('. ')
    : `${jobName}${ì€ëŠ”(jobName)} ë‹¹ì‹ ì˜ ì—­ëŸ‰ìœ¼ë¡œ ì¶©ë¶„íˆ ë„ì „í•  ìˆ˜ ìˆëŠ” ë¶„ì•¼ì…ë‹ˆë‹¤`

  // ============================================
  // Risk ê²½ê³ 
  // ============================================
  let riskWarning = ''
  const confirmedConstraints = facts.filter(f => f.fact_key.startsWith('confirmed_constraint.'))
  if (confirmedConstraints.length > 0) {
    riskWarning = 'ì œì•½ ì¡°ê±´ ì¶©ì¡±'
  }
  const riskPenalty = job.scores?.risk_penalty || job.risk_penalty || 0
  if (riskPenalty > 15) {
    riskWarning = 'ì¼ë¶€ ì£¼ì˜ í•„ìš” (ìƒì„¸ ì •ë³´ í™•ì¸ ê¶Œì¥)'
  } else if (riskPenalty > 10) {
    riskWarning = 'ê²½ë¯¸í•œ ë¶ˆí™•ì‹¤ì„± ìˆìŒ'
  }
  if (!riskWarning) {
    riskWarning = 'íŠ¹ë³„í•œ ìœ„í—˜ ìš”ì†Œ ì—†ìŒ'
  }

  return {
    like_reason: likeReason,
    can_reason: canReason,
    risk_warning: riskWarning,
  }
}

// ============================================
// Dislike ê²½ê³  ìƒì„± (íšŒí”¼ ìš”ì†Œ í¬í•¨ ì‹œ)
// ============================================
interface DislikeWarning {
  type: string
  label: string
  severity: 'high' | 'medium' | 'low'
}

function generateDislikeWarnings(facts: Fact[], job: ScoredJob): DislikeWarning[] {
  const warnings: DislikeWarning[] = []
  
  // hard_dislike facts ìˆ˜ì§‘
  const hardDislikeFacts = facts.filter(f => f.fact_key === 'profile.hard_dislike')
  const mildDislikeFacts = facts.filter(f => f.fact_key === 'profile.dislike')
  
  // hard_dislike â†’ ì§ì—… ì†ì„± ë§¤í•‘
  const DISLIKE_JOB_ATTR_MAP: Record<string, { attrs: string[]; label: string }> = {
    'sales': { attrs: ['people_facing'], label: 'ì˜ì—…/ì„¤ë“ ì—…ë¬´' },
    'overtime': { attrs: ['wlb', 'work_hours'], label: 'ì•¼ê·¼/ê¸´ ê·¼ë¬´' },
    'public_speaking': { attrs: ['people_facing'], label: 'ë°œí‘œ/ëŒ€ë©´ ì—…ë¬´' },
    'meetings': { attrs: ['teamwork'], label: 'íšŒì˜ ë§ìŒ' },
    'travel': { attrs: ['travel', 'remote_possible'], label: 'ì¶œì¥/ì´ë™' },
    'routine': { attrs: ['creative'], label: 'ë‹¨ìˆœ ë°˜ë³µ ì—…ë¬´' },
    'conflict': { attrs: ['people_facing'], label: 'ê°ˆë“±/ëŒ€ë¦½ ìƒí™©' },
    'physical': { attrs: ['execution'], label: 'ìœ¡ì²´ì  ì—…ë¬´' },
    'shift_work': { attrs: ['shift_work'], label: 'êµëŒ€ ê·¼ë¬´' },
    'woodwork': { attrs: ['execution'], label: 'ëª©ê³µ ê´€ë ¨' },
    'construction': { attrs: ['execution'], label: 'ê±´ì„¤/í˜„ì¥ ì—…ë¬´' },
    'call_center': { attrs: ['people_facing'], label: 'ì½œì„¼í„°/ì „í™” ì—…ë¬´' },
  }
  
  // hard_dislike ë§¤ì¹­ í™•ì¸
  for (const fact of hardDislikeFacts) {
    try {
      const data = JSON.parse(fact.value_json)
      const dislikeType = data.type
      const mapping = DISLIKE_JOB_ATTR_MAP[dislikeType]
      
      if (mapping) {
        // ì§ì—…ì˜ í•´ë‹¹ ì†ì„±ì´ ë†’ìœ¼ë©´ ê²½ê³ 
        const jobAttrs = job.attributes || {}
        for (const attr of mapping.attrs) {
          const attrValue = jobAttrs[attr]
          if (attrValue !== undefined && Number(attrValue) > 50) {
            warnings.push({
              type: dislikeType,
              label: `âš ï¸ ì£¼ì˜: ${mapping.label} ìš”ì†Œ í¬í•¨`,
              severity: 'high',
            })
            break
          }
        }
      }
    } catch { /* ignore */ }
  }
  
  // mild dislike ë§¤ì¹­ (ê²½ë¯¸í•œ ê²½ê³ )
  for (const fact of mildDislikeFacts) {
    try {
      const data = JSON.parse(fact.value_json)
      const dislikeType = data.type
      const mapping = DISLIKE_JOB_ATTR_MAP[dislikeType]
      
      if (mapping && !warnings.some(w => w.type === dislikeType)) {
        const jobAttrs = job.attributes || {}
        for (const attr of mapping.attrs) {
          const attrValue = jobAttrs[attr]
          if (attrValue !== undefined && Number(attrValue) > 70) {
            warnings.push({
              type: dislikeType,
              label: `â„¹ï¸ ì°¸ê³ : ${mapping.label} ìš”ì†Œ ìˆìŒ`,
              severity: 'low',
            })
            break
          }
        }
      }
    } catch { /* ignore */ }
  }
  
  return warnings
}

// ============================================
// Phase 1C: User Insight ìƒì„±
// ============================================
function generateUserInsight(
  facts: Fact[],
  deepIntake?: NormalizedDeepIntake,
  appliedRules?: string[]
): UserInsight | undefined {
  if (!deepIntake && facts.length === 0) {
    return undefined
  }
  
  const keyTraits: UserInsight['key_traits'] = []
  const appliedFacts: UserInsight['applied_facts'] = []
  
  // MBTI ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
  if (deepIntake?.mbti && deepIntake.mbti_traits) {
    const workStyles = deepIntake.mbti_traits.workStyles
    
    if (workStyles.includes('solo_deep')) {
      keyTraits.push({
        trait: 'í˜¼ì ê¹Šê²Œ íŒŒê¸°ë¥¼ ì„ í˜¸',
        evidence: `MBTI ${deepIntake.mbti}ì˜ íŠ¹ì„±`,
        score_impact: 'ë¶„ì„/ì—°êµ¬ ì¤‘ì‹¬ ì§ì—…ì— +5~10 ë¶€ìŠ¤íŠ¸',
      })
    }
    if (workStyles.includes('team_collab')) {
      keyTraits.push({
        trait: 'íŒ€ í˜‘ì—…ì„ ì„ í˜¸',
        evidence: `MBTI ${deepIntake.mbti}ì˜ íŠ¹ì„±`,
        score_impact: 'í˜‘ì—… ì¤‘ì‹¬ ì§ì—…ì— +5~10 ë¶€ìŠ¤íŠ¸',
      })
    }
    if (workStyles.includes('creative')) {
      keyTraits.push({
        trait: 'ì°½ì˜ì ì¸ ì—…ë¬´ ì„ í˜¸',
        evidence: `MBTI ${deepIntake.mbti}ì˜ íŠ¹ì„±`,
        score_impact: 'ì°½ì˜ì„± ìš”êµ¬ ì§ì—…ì— +5 ë¶€ìŠ¤íŠ¸',
      })
    }
  }
  
  // best_moment ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
  if (deepIntake?.best_moment) {
    const tags = deepIntake.best_moment.tags
    if (tags.includes('solo_deep')) {
      keyTraits.push({
        trait: 'ëª°ì…í•˜ë©° ì¼í•  ë•Œ ì—ë„ˆì§€ë¥¼ ì–»ìŒ',
        evidence: `"${deepIntake.best_moment.raw.slice(0, 30)}..."`,
        score_impact: 'ë¶„ì„/ì—°êµ¬ ì§ì—…ì— +15 ë¶€ìŠ¤íŠ¸',
      })
    }
    if (tags.includes('team_collab') || tags.includes('people_facing')) {
      keyTraits.push({
        trait: 'ì‚¬ëŒë“¤ê³¼ í•¨ê»˜í•  ë•Œ ì—ë„ˆì§€ë¥¼ ì–»ìŒ',
        evidence: `"${deepIntake.best_moment.raw.slice(0, 30)}..."`,
        score_impact: 'í˜‘ì—…/ëŒ€ì¸ ì§ì—…ì— +15 ë¶€ìŠ¤íŠ¸',
      })
    }
    if (tags.includes('creative')) {
      keyTraits.push({
        trait: 'ì°½ì‘/ê¸°íší•  ë•Œ ë³´ëŒì„ ëŠë‚Œ',
        evidence: `"${deepIntake.best_moment.raw.slice(0, 30)}..."`,
        score_impact: 'ì°½ì˜ì„± ìš”êµ¬ ì§ì—…ì— +15 ë¶€ìŠ¤íŠ¸',
      })
    }
  }
  
  // worst_moment ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
  if (deepIntake?.worst_moment) {
    const stressTrigger = deepIntake.worst_moment.stress_trigger
    if (stressTrigger === 'people') {
      keyTraits.push({
        trait: 'ëŒ€ì¸ ê°ˆë“±ì— ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ìŒ',
        evidence: `"${deepIntake.worst_moment.raw.slice(0, 30)}..."`,
        score_impact: 'ë…ë¦½ì  ì—…ë¬´ ì§ì—…ì— +15 ë¶€ìŠ¤íŠ¸',
      })
    }
    if (stressTrigger === 'deadline') {
      keyTraits.push({
        trait: 'ë§ˆê° ì••ë°•ì— ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ìŒ',
        evidence: `"${deepIntake.worst_moment.raw.slice(0, 30)}..."`,
        score_impact: 'ì›Œë¼ë°¸ ì¢‹ì€ ì§ì—…ì— +10 ë¶€ìŠ¤íŠ¸',
      })
    }
    if (stressTrigger === 'meeting') {
      keyTraits.push({
        trait: 'íšŒì˜ê°€ ë§ì€ í™˜ê²½ì„ í”¼í•˜ê³  ì‹¶ìŒ',
        evidence: `"${deepIntake.worst_moment.raw.slice(0, 30)}..."`,
        score_impact: 'ë…ë¦½ì /ì›ê²© ì§ì—…ì— +10 ë¶€ìŠ¤íŠ¸',
      })
    }
  }
  
  // priority.top1 ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
  if (deepIntake?.priority_top1) {
    const priorityMap: Record<string, string> = {
      'growth': 'ì„±ì¥ ê°€ëŠ¥ì„±',
      'stability': 'ì•ˆì •ì„±',
      'wlb': 'ì›Œë¼ë°¸',
      'income': 'ë†’ì€ ìˆ˜ì…',
    }
    keyTraits.push({
      trait: (() => { const p = priorityMap[deepIntake.priority_top1] || deepIntake.priority_top1; return `${p}${ì„ë¥¼(p)} ìµœìš°ì„ ì‹œ` })(),
      evidence: 'ì§ì ‘ ì„ íƒ',
      score_impact: `í•´ë‹¹ ì†ì„±ì— +20 ë¶€ìŠ¤íŠ¸`,
    })
  }
  
  // facts ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
  for (const fact of facts) {
    try {
      const value = JSON.parse(fact.value_json)
      
      if (fact.fact_key === 'tradeoff.salary_vs_wlb') {
        appliedFacts.push({
          fact_key: fact.fact_key,
          effect_summary: value.value === 'wlb' 
            ? 'ì›Œë¼ë°¸ì„ ì—°ë´‰ë³´ë‹¤ ì¤‘ì‹œ â†’ WLB ì§ì—…ì— +15 ë¶€ìŠ¤íŠ¸'
            : 'ì—°ë´‰ì„ ì›Œë¼ë°¸ë³´ë‹¤ ì¤‘ì‹œ â†’ ê³ ìˆ˜ì… ì§ì—…ì— +15 ë¶€ìŠ¤íŠ¸',
        })
      }
      if (fact.fact_key === 'tradeoff.growth_vs_stability') {
        appliedFacts.push({
          fact_key: fact.fact_key,
          effect_summary: value.value === 'growth'
            ? 'ì„±ì¥ì„ ì•ˆì •ë³´ë‹¤ ì¤‘ì‹œ â†’ ì„±ì¥ ê°€ëŠ¥ì„± ì§ì—…ì— +15 ë¶€ìŠ¤íŠ¸'
            : 'ì•ˆì •ì„ ì„±ì¥ë³´ë‹¤ ì¤‘ì‹œ â†’ ì•ˆì •ì  ì§ì—…ì— +15 ë¶€ìŠ¤íŠ¸',
        })
      }
      if (fact.fact_key === 'motivation.work_hours_reason') {
        appliedFacts.push({
          fact_key: fact.fact_key,
          effect_summary: `"${value.value || value.raw?.slice(0, 20)}" ì´ìœ ë¡œ ì•¼ê·¼ ê¸°í”¼ â†’ ê´€ë ¨ ë¦¬ìŠ¤í¬ í˜ë„í‹° ì¡°ì •`,
        })
      }
    } catch {
      // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
    }
  }
  
  // ìš”ì•½ ë¬¸ì¥ ìƒì„±
  let summary = ''
  if (keyTraits.length > 0) {
    const topTraits = keyTraits.slice(0, 3).map(t => t.trait)
    summary = `ë‹¹ì‹ ì€ ${topTraits.join(', ')} ì‚¬ëŒì…ë‹ˆë‹¤.`
  } else if (appliedFacts.length > 0) {
    summary = `${appliedFacts.length}ê°œì˜ ë‹µë³€ì„ ë¶„ì„í•˜ì—¬ ë§ì¶¤ ì¶”ì²œì„ ì œê³µí–ˆìŠµë‹ˆë‹¤.`
  } else {
    summary = 'ë” ë§ì€ ì •ë³´ë¥¼ ì…ë ¥í•˜ì‹œë©´ ë” ì •í™•í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë“œë¦´ ìˆ˜ ìˆì–´ìš”.'
  }
  
  return {
    summary,
    key_traits: keyTraits,
    applied_facts: appliedFacts,
  }
}

// ============================================
// ì„¤ëª… ìƒì„± (Phase 1A ê°„ë‹¨ ë²„ì „)
// ============================================
function generateExplanation(
  facts: Fact[],
  appliedRules: string[],
  topJobName?: string
): string {
  if (facts.length === 0) {
    return 'ì¶”ê°€ ì§ˆë¬¸ì— ë‹µë³€í•˜ì‹œë©´ ë” ì •í™•í•œ ì¶”ì²œì„ ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.'
  }
  
  const explanations: string[] = []
  
  for (const fact of facts) {
    try {
      const value = JSON.parse(fact.value_json)
      const choice = value.value || value
      
      if (fact.fact_key === 'tradeoff.salary_vs_wlb') {
        if (choice === 'wlb') {
          explanations.push('ì›Œë¼ë°¸ì„ ì¤‘ì‹œí•œë‹¤ëŠ” ë‹µë³€ì„ ë°˜ì˜í–ˆìŠµë‹ˆë‹¤')
        } else {
          explanations.push('ì—°ë´‰ì„ ì¤‘ì‹œí•œë‹¤ëŠ” ë‹µë³€ì„ ë°˜ì˜í–ˆìŠµë‹ˆë‹¤')
        }
      } else if (fact.fact_key === 'tradeoff.growth_vs_stability') {
        if (choice === 'growth') {
          explanations.push('ì„±ì¥ ê°€ëŠ¥ì„±ì„ ì¤‘ì‹œí•œë‹¤ëŠ” ë‹µë³€ì„ ë°˜ì˜í–ˆìŠµë‹ˆë‹¤')
        } else {
          explanations.push('ì•ˆì •ì„±ì„ ì¤‘ì‹œí•œë‹¤ëŠ” ë‹µë³€ì„ ë°˜ì˜í–ˆìŠµë‹ˆë‹¤')
        }
      } else if (fact.fact_key.startsWith('motivation.')) {
        explanations.push(`"${choice}" ë•Œë¬¸ì´ë¼ëŠ” ì´ìœ ë¥¼ ë°˜ì˜í–ˆìŠµë‹ˆë‹¤`)
      }
    } catch {
      // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
    }
  }
  
  if (explanations.length === 0) {
    return `${facts.length}ê°œì˜ ë‹µë³€ì„ ë°˜ì˜í•˜ì—¬ ì¶”ì²œí–ˆìŠµë‹ˆë‹¤.`
  }
  
  return explanations.join('. ') + '.'
}

// ============================================
// ìƒ˜í”Œ ì§ì—… ë°ì´í„° (Phase 1A)
// ============================================
interface SampleJob {
  job_id: string
  job_name: string
  base_like: number
  base_can: number
  base_risk: number
  attributes: Record<string, string | number>
}

function getSampleJobs(): SampleJob[] {
  return [
    {
      job_id: 'data-analyst',
      job_name: 'ë°ì´í„° ë¶„ì„ê°€',
      base_like: 70,
      base_can: 65,
      base_risk: 5,
      attributes: { wlb: 80, growth: 85, stability: 70, income: 75, solo_work: 70, remote: 60 },
    },
    {
      job_id: 'software-developer',
      job_name: 'ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì',
      base_like: 75,
      base_can: 60,
      base_risk: 10,
      attributes: { wlb: 50, growth: 90, stability: 75, income: 85, solo_work: 65, remote: 80 },
    },
    {
      job_id: 'ux-designer',
      job_name: 'UX ë””ìì´ë„ˆ',
      base_like: 72,
      base_can: 55,
      base_risk: 8,
      attributes: { wlb: 70, growth: 80, stability: 65, income: 70, solo_work: 50, remote: 75, creative: 90 },
    },
    {
      job_id: 'project-manager',
      job_name: 'í”„ë¡œì íŠ¸ ë§¤ë‹ˆì €',
      base_like: 68,
      base_can: 70,
      base_risk: 15,
      attributes: { wlb: 40, growth: 75, stability: 70, income: 80, people_facing: 90, solo_work: 20 },
    },
    {
      job_id: 'accountant',
      job_name: 'íšŒê³„ì‚¬',
      base_like: 60,
      base_can: 75,
      base_risk: 5,
      attributes: { wlb: 60, growth: 50, stability: 95, income: 75, solo_work: 80, analytical: 90 },
    },
    {
      job_id: 'marketing-specialist',
      job_name: 'ë§ˆì¼€íŒ… ì „ë¬¸ê°€',
      base_like: 70,
      base_can: 60,
      base_risk: 20,
      attributes: { wlb: 45, growth: 70, stability: 55, income: 65, people_facing: 75, creative: 80 },
    },
    {
      job_id: 'hr-manager',
      job_name: 'ì¸ì‚¬ ë‹´ë‹¹ì',
      base_like: 62,
      base_can: 68,
      base_risk: 10,
      attributes: { wlb: 70, growth: 60, stability: 80, income: 65, people_facing: 95, solo_work: 30 },
    },
    {
      job_id: 'financial-analyst',
      job_name: 'ì¬ë¬´ ë¶„ì„ê°€',
      base_like: 65,
      base_can: 62,
      base_risk: 25,
      attributes: { wlb: 35, growth: 75, stability: 70, income: 90, solo_work: 65, analytical: 95 },
    },
    {
      job_id: 'content-creator',
      job_name: 'ì½˜í…ì¸  í¬ë¦¬ì—ì´í„°',
      base_like: 78,
      base_can: 50,
      base_risk: 30,
      attributes: { wlb: 55, growth: 65, stability: 30, income: 50, solo_work: 75, remote: 90, creative: 95 },
    },
    {
      job_id: 'teacher',
      job_name: 'êµì‚¬',
      base_like: 60,
      base_can: 70,
      base_risk: 5,
      attributes: { wlb: 80, growth: 40, stability: 95, income: 55, people_facing: 90, impact: 85 },
    },
    {
      job_id: 'nurse',
      job_name: 'ê°„í˜¸ì‚¬',
      base_like: 55,
      base_can: 60,
      base_risk: 35,
      attributes: { wlb: 25, growth: 50, stability: 90, income: 65, people_facing: 95, impact: 95 },
    },
    {
      job_id: 'consultant',
      job_name: 'ê²½ì˜ ì»¨ì„¤í„´íŠ¸',
      base_like: 72,
      base_can: 55,
      base_risk: 40,
      attributes: { wlb: 20, growth: 95, stability: 50, income: 95, people_facing: 80, analytical: 85 },
    },
  ]
}

// ============================================
// Helper Types
// ============================================
interface FollowupPayloadV2 {
  session_id: string
  user_id?: string
  question_id: string
  question_type?: string
  attribute?: string
  fact_key?: string
  answer: string
  answer_text?: string  // ììœ ì‘ë‹µ ì›ë¬¸
  confidence?: number
  // backward compatibility
  request_id?: number
  constraint?: string
  job_id?: string
  job_name?: string
}

interface FollowupResultV2 {
  success: boolean
  fact_saved: {
    fact_key: string
    value: string
    fact_level: number
  }
  reanalyze_available: boolean
  message: string
}

function determineFctLevel(factKey: string): number {
  if (factKey.startsWith('confirmed_constraint')) return 1
  if (factKey.startsWith('priority.dealbreaker')) return 2
  if (factKey.startsWith('priority.') || factKey.startsWith('tradeoff.') || factKey.startsWith('motivation.')) return 3
  return 4
}

// ============================================
// V3: Stage-based Analysis (with stage-aware follow-ups)
// ============================================
async function runAnalysisV3(
  db: D1Database,
  payload: AnalyzePayload,
  requestId: number,
  facts: Fact[],
  deepIntake?: NormalizedDeepIntake,
  stage?: AnalysisStage,
  debugMode?: boolean,
  env?: { VECTORIZE?: VectorizeIndex; AI?: Ai }
): Promise<AnalysisResultJSON> {
  // ============================================
  // V3 Enhancement: TAG Pre-Filter ì„¤ì •
  // ============================================
  const universalAnswers = payload.universal_answers || {}
  const userConstraints = extractUserConstraints(universalAnswers, payload.career_state)
  const enableTagPreFilter = Object.values(userConstraints).some(v => v === true)
  
  if (enableTagPreFilter) {
  }
  
  // ============================================
  // P1 Vectorize ê¸°ë°˜ í›„ë³´êµ° í™•ì¥ (íƒœê¹… ë¬´ê´€)
  // ============================================
  // 2026-01-26: íƒœê¹… ì˜ì¡´ë„ ì™„ì „ ì œê±°
  // - ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ëª¨ë“  ì§ì—… ê²€ìƒ‰ ê°€ëŠ¥
  // - tagger_version ì¡°ê±´ ì—†ì´ í›„ë³´ í™•ë³´
  // ============================================
  let candidateSource: 'vectorize' | 'db_fallback' | 'sample_fallback' = 'db_fallback'
  let candidateCount = 0
  let vectorizeUsed = false
  let totalCandidates = 0

  // mini_module_result ì¶”ì¶œ (ê°œì¸í™” ìŠ¤ì½”ì–´ë§ì— ì‚¬ìš© - sampleJobs ìƒì„± ì „ì— í•„ìš”)
  const miniModuleForFilter = 'mini_module_result' in payload ? (payload as any).mini_module_result : undefined

  // Vectorize ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ (OpenAI API í‚¤ í•„ìš”)
  const openaiApiKey = (env as any)?.OPENAI_API_KEY
  const useVectorize = env?.VECTORIZE && openaiApiKey
  
  let sampleJobs: Array<{
    job_id: string
    job_name: string
    base_like: number
    base_can: number
    base_risk: number
    attributes: Record<string, number | string>
  }>
  
  if (useVectorize) {
    // Vectorize ê¸°ë°˜ í›„ë³´êµ° í™•ì¥ (OpenAI Embedding ì‚¬ìš©, íƒœê¹… ë¬´ê´€)
    try {
      const expansionResult = await expandCandidates(
        db,
        env!.VECTORIZE,
        openaiApiKey,
        facts.map(f => ({ fact_key: f.fact_key, value_json: f.value_json })),
        { targetSize: 500 }  // minTaggedJobs ì œê±°
      )
      
      if (!expansionResult.fallback_used && expansionResult.candidates.length > 0) {
        // ë²¡í„° ê²°ê³¼ë¥¼ ScoredJob í˜•íƒœë¡œ ë³€í™˜
        sampleJobs = await vectorResultsToScoredJobs(db, expansionResult.candidates, miniModuleForFilter)
        candidateSource = 'vectorize'
        vectorizeUsed = true
        totalCandidates = expansionResult.candidates.length
      } else {
        // Vectorize ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹
        throw new Error('Vectorize fallback triggered')
      }
    } catch (vectorError) {
      // Fallback: jobs JOIN job_attributes (íƒœê¹… ì—¬ë¶€ ë¬´ê´€)
      const jobAttrs = await db.prepare(`
        SELECT 
          ja.job_id, ja.job_name,
          j.slug, j.image_url,
          COALESCE(ja.wlb, 50) as wlb, 
          COALESCE(ja.growth, 50) as growth, 
          COALESCE(ja.stability, 50) as stability, 
          COALESCE(ja.income, 50) as income,
          COALESCE(ja.teamwork, 50) as teamwork, 
          COALESCE(ja.solo_deep, 50) as solo_deep, 
          COALESCE(ja.analytical, 50) as analytical, 
          COALESCE(ja.creative, 50) as creative, 
          COALESCE(ja.execution, 50) as execution, 
          COALESCE(ja.people_facing, 50) as people_facing,
          COALESCE(ja.work_hours, 'regular') as work_hours, 
          COALESCE(ja.shift_work, 'rare') as shift_work, 
          COALESCE(ja.travel, 'rare') as travel, 
          COALESCE(ja.remote_possible, 'possible') as remote_possible,
          COALESCE(ja.degree_required, 'none') as degree_required,
          COALESCE(ja.license_required, 'none') as license_required
        FROM job_attributes ja
        INNER JOIN jobs j ON ja.job_id = j.id
        ORDER BY RANDOM()
        LIMIT 500
      `).all<{
        job_id: string
        job_name: string
        slug: string
        image_url: string | null
        wlb: number
        growth: number
        stability: number
        income: number
        teamwork: number
        solo_deep: number
        analytical: number
        creative: number
        execution: number
        people_facing: number
        work_hours: string
        shift_work: string
        travel: string
        remote_possible: string
        degree_required: string
        license_required: string
      }>()

      const useDbData = jobAttrs.results && jobAttrs.results.length > 0
      candidateSource = useDbData ? 'db_fallback' : 'sample_fallback'
      candidateCount = jobAttrs.results?.length || 0

      sampleJobs = useDbData
        ? jobAttrs.results!.map(j => {
            const personalized = calculatePersonalizedBaseScores(j, miniModuleForFilter)
            return {
              job_id: j.job_id,
              job_name: j.job_name,
              slug: j.slug,
              image_url: j.image_url,
              base_like: personalized.like,
              base_can: personalized.can,
              base_risk: 10,
              attributes: {
                wlb: j.wlb,
                growth: j.growth,
                stability: j.stability,
                income: j.income,
                remote: j.remote_possible === 'full' ? 100 : j.remote_possible === 'partial' ? 50 : 0,
                solo_work: j.solo_deep,
                people_facing: j.people_facing,
                analytical: j.analytical,
                creative: j.creative,
              },
            }
          })
        : []
    }
  } else {
    // Vectorize ì—†ì´ DBì—ì„œ ì§ì ‘ ì¡°íšŒ (íƒœê¹… ì—¬ë¶€ ë¬´ê´€)
    const jobAttrs = await db.prepare(`
      SELECT
        ja.job_id, ja.job_name,
        j.slug, j.image_url, j.api_data_json, j.merged_profile_json, j.ai_data_json,
        COALESCE(ja.wlb, 50) as wlb,
        COALESCE(ja.growth, 50) as growth,
        COALESCE(ja.stability, 50) as stability,
        COALESCE(ja.income, 50) as income,
        COALESCE(ja.teamwork, 50) as teamwork,
        COALESCE(ja.solo_deep, 50) as solo_deep,
        COALESCE(ja.analytical, 50) as analytical,
        COALESCE(ja.creative, 50) as creative,
        COALESCE(ja.execution, 50) as execution,
        COALESCE(ja.people_facing, 50) as people_facing,
        COALESCE(ja.work_hours, 'regular') as work_hours,
        COALESCE(ja.shift_work, 'rare') as shift_work,
        COALESCE(ja.travel, 'rare') as travel,
        COALESCE(ja.remote_possible, 'possible') as remote_possible,
        COALESCE(ja.degree_required, 'none') as degree_required,
        COALESCE(ja.license_required, 'none') as license_required
      FROM job_attributes ja
      INNER JOIN jobs j ON ja.job_id = j.id
      ORDER BY RANDOM()
      LIMIT 500
    `).all<{
      job_id: string
      job_name: string
      slug: string
      image_url: string | null
      api_data_json: string | null
      merged_profile_json: string | null
      ai_data_json: string | null
      wlb: number
      growth: number
      stability: number
      income: number
      teamwork: number
      solo_deep: number
      analytical: number
      creative: number
      execution: number
      people_facing: number
      work_hours: string
      shift_work: string
      travel: string
      remote_possible: string
      degree_required: string
      license_required: string
    }>()
    
    const useDbData = jobAttrs.results && jobAttrs.results.length > 0
    candidateSource = useDbData ? 'db_fallback' : 'sample_fallback'
    candidateCount = jobAttrs.results?.length || 0
    
    sampleJobs = useDbData
      ? jobAttrs.results!.map(j => {
          const personalized = calculatePersonalizedBaseScores(j, miniModuleForFilter)
          return {
            job_id: j.job_id,
            job_name: j.job_name,
            slug: j.slug,
            image_url: j.image_url,
            job_description: extractJobDescription(j.api_data_json, j.merged_profile_json, j.job_name, j.ai_data_json),
            base_like: personalized.like,
            base_can: personalized.can,
            base_risk: 10,
            attributes: {
              wlb: j.wlb,
              growth: j.growth,
              stability: j.stability,
              income: j.income,
              remote: j.remote_possible === 'full' ? 100 : j.remote_possible === 'partial' ? 50 : 0,
              solo_work: j.solo_deep,
              people_facing: j.people_facing,
              analytical: j.analytical,
              creative: j.creative,
            },
          }
        })
      : []
  }
  
  // DB ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬ ë°˜í™˜
  if (sampleJobs.length === 0) {
    throw new Error('ì§ì—… ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. job_attributes í…Œì´ë¸”ì„ í™•ì¸í•˜ì„¸ìš”.')
  }
  
  // ============================================
  // ì „ì²´ ì§ì—… ìˆ˜ ì¡°íšŒ (í‰ê°€ ì§ì—… ìˆ˜ í‘œì‹œìš©)
  // ============================================
  let totalJobsInDB = sampleJobs.length
  try {
    const countResult = await db.prepare('SELECT COUNT(*) as cnt FROM jobs').first<{ cnt: number }>()
    totalJobsInDB = countResult?.cnt || sampleJobs.length
  } catch (error) {
  }
  
  // ============================================
  // Phase 2.1: ë¯¸ë‹ˆëª¨ë“ˆ ê¸°ë°˜ Hard Filter (ë²¡í„° ê²€ìƒ‰ ì „ ì ìš©)
  // ============================================
  // ë¯¸ë‹ˆëª¨ë“ˆ ê¸°ë°˜ Hard Exclusion ì ìš©
  const { filtered: filteredJobs, filterResult: miniModuleFilterResult } = applyMiniModuleHardFilter(
    sampleJobs,
    miniModuleForFilter
  )
  
  // í•„í„°ë§ ê²°ê³¼ ë¡œê·¸
  if (miniModuleFilterResult.stats.totalFiltered > 0) {
  }
  
  // í•„í„°ë§ëœ ì§ì—… ëª©ë¡ ì‚¬ìš©
  const jobsToScore = filteredJobs.length > 0 ? filteredJobs : sampleJobs
  
  // 2. Fact boosts ê³„ì‚°
  const factBoosts = calculateFactBoosts(facts)

  // P2: ê²€ì¦ëœ Can ì¶”ì¶œ (Can ê¸°ë°˜ TAG í•„í„°ìš©)
  const verifiedCan: VerifiedCanMap = extractVerifiedCanFromFacts(
    facts.map(f => ({ fact_key: f.fact_key, value_json: f.value_json }))
  )

  // ë¯¸ë‹ˆëª¨ë“ˆ ê¸°ë°˜ ì¶”ê°€ Risk Penalty (Hard Bias derived)
  const hardBiasConstraints = miniModuleForFilter?.energy_drain_flags
    ? deriveConstraintsFromHardBias(miniModuleForFilter.energy_drain_flags)
    : null

  // P3: ì„±ì¥ê³¡ì„  ì„ í˜¸ë„ ì¶”ì¶œ
  const growthPreference = extractGrowthPreference(miniModuleForFilter)

  // P3: ë‚´ë©´ê°ˆë“± ì‹¬ê°ë„ í™•ì¸
  const conflictSeverity = calculateConflictSeverity(miniModuleForFilter)

  // 3. ê° ì§ì—…ì— ì ìˆ˜ ì ìš© (slug, image_url í¬í•¨ + ë¯¸ë‹ˆëª¨ë“ˆ Risk Penalty)
  const scoredJobs: ScoredJob[] = jobsToScore.map(job => {
    const baseScores: JobScores = {
      like: job.base_like,
      can: job.base_can,
      risk_penalty: job.base_risk,
    }
    
    const adjusted = applyFactBoostsToJob(baseScores, job.attributes, factBoosts)
    
    // ë¯¸ë‹ˆëª¨ë“ˆ ê¸°ë°˜ ì¶”ê°€ Risk Penalty ì ìš©
    let additionalPenalty = 0
    const miniModulePenalty = calculateMiniModuleRiskPenalty(miniModuleForFilter, job.attributes)
    additionalPenalty += miniModulePenalty.penalty
    
    // Hard Bias ê¸°ë°˜ ì¶”ê°€ Penalty ì ìš©
    if (hardBiasConstraints && hardBiasConstraints.penalties.length > 0) {
      const hardBiasPenalty = applyHardBiasPenalty(job.attributes, hardBiasConstraints)
      additionalPenalty += hardBiasPenalty.penalty
    }

    // P2: Can ê¸°ë°˜ TAG í•„í„° í˜ë„í‹° ì ìš©
    const canFilterResult = applyCanBasedFilter(job.attributes, verifiedCan)
    additionalPenalty += canFilterResult.totalPenalty

    // P3: ì„±ì¥ê³¡ì„  ë§¤ì¹­ (Like Boost / Risk Penalty)
    const growthMatch = matchGrowthCurves(growthPreference, job.attributes, job.job_name)
    additionalPenalty += growthMatch.riskPenalty

    // P3: ë‚´ë©´ê°ˆë“± â†’ Risk ì¡°ì •
    const conflictRisk = calculateConflictRisk(miniModuleForFilter, job.attributes)
    additionalPenalty += conflictRisk.totalRiskAdjust

    const totalRiskPenalty = adjusted.risk_penalty + additionalPenalty

    // P0: Can-Like ë°¸ëŸ°ìŠ¤ ìº¡ ì ìš©
    // P3: ì„±ì¥ê³¡ì„  ë§¤ì¹­ Like Boost í¬í•¨
    const likeWithGrowthBoost = adjusted.like + growthMatch.likeBoost
    const balanced = applyBalanceCap(likeWithGrowthBoost, adjusted.can)
    const fit = Math.round(0.55 * balanced.like + 0.45 * balanced.can - totalRiskPenalty)

    // ì„ì‹œ scoredJob ê°ì²´ ìƒì„± (explanation ìƒì„±ìš©)
    const tempScoredJob: ScoredJob = {
      job_id: job.job_id,
      job_name: job.job_name,
      slug: job.slug,
      image_url: job.image_url || undefined,
      job_description: (job as any).job_description,
      scores: {
        fit: Math.max(0, fit),
        like: balanced.like,
        can: balanced.can,
        risk_penalty: totalRiskPenalty,
      },
      attributes: job.attributes,
    }

    // ê·¼ê±° ìƒì„± (V3: miniModuleForFilter ì „ë‹¬í•˜ì—¬ ê°œì¸í™”ëœ ì´ìœ  ìƒì„±)
    const explanation = generateJobExplanation(tempScoredJob, facts, factBoosts.applied_rules, miniModuleForFilter)
    const rationale = `[ì¢‹ì•„í•  ì´ìœ ] ${explanation.like_reason} [ì˜í•  ì´ìœ ] ${explanation.can_reason}`

    return {
      ...tempScoredJob,
      rationale,
      likeReason: explanation.like_reason,
      canReason: explanation.can_reason,
    }
  })

  // 4. ì •ë ¬ (Fit ê¸°ì¤€) + ì •ë¬´ì§/ì„ëª…ì§ ì œê±°
  scoredJobs.sort((a, b) => b.scores.fit - a.scores.fit)
  const filteredScoredJobs = filterNicheMaterialJobs(filterUnrealisticJobs(scoredJobs), miniModuleForFilter)

  // í‰ê°€ ì§ì—… 100ê°œë¡œ í™•ì¥ (ê¸°ì¡´ 10ê°œ -> 100ê°œ)
  const top10 = filteredScoredJobs.slice(0, 100)

  // Phase 4: Diversity Guard (Research Bias ë°©ì§€ + ë‹¤ì–‘ì„± í™•ë³´)
  const rawTop5 = top10.slice(0, 5)
  const diversityResult = applyDiversityGuard(rawTop5, filteredScoredJobs)
  const top3 = diversityResult.adjusted

  // 5. Follow-up ì§ˆë¬¸ ìƒì„± (Stage-aware)
  const existingFactKeys = facts.map(f => ({ fact_key: f.fact_key }))

  let followupQuestions: FollowupQuestion[]
  if (stage) {
    // V3: Stage ê¸°ë°˜ ì§ˆë¬¸ ìƒì„±
    followupQuestions = generateStageBasedFollowups(
      scoredJobs,
      top10,
      existingFactKeys,
      stage,
      !!deepIntake
    )
  } else {
    // V2 fallback: ê¸°ì¡´ ë°©ì‹
    followupQuestions = generateFollowupQuestions({
      candidates: scoredJobs,
      topK: top10,
      existingFacts: existingFactKeys,
      hasDeepIntake: !!deepIntake,
    }, 3)
  }

  // 5.5 P0: Can ê²€ì¦ ì§ˆë¬¸ ì¶”ê°€ (ìê¸°í‰ê°€ ê°•ì  ê²½í—˜ í™•ì¸)
  // mini_module_result ì¡°ê¸° ì¶”ì¶œ (Can ê²€ì¦ìš©)
  const mmResultForCan = 'mini_module_result' in payload ? (payload as any).mini_module_result : undefined
  if (mmResultForCan?.strength_top?.length > 0) {
    // ì´ë¯¸ ê²€ì¦ëœ ê°•ì  í† í°ë“¤ ì°¾ê¸°
    const alreadyVerified = facts
      .filter(f => f.fact_key.startsWith('can_verified_'))
      .map(f => f.fact_key.replace('can_verified_', ''))

    // Can ê²€ì¦ ì§ˆë¬¸ ì„ íƒ (ì„¸ì…˜ë‹¹ ìµœëŒ€ 2ê°œ)
    const canValidationQuestions = selectCanValidationQuestions({
      max_questions_per_session: 2,
      already_verified: alreadyVerified,
      user_strength_tokens: mmResultForCan.strength_top,
    })

    // FollowupQuestion í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€
    for (const cvq of canValidationQuestions) {
      // ì„¸ì…˜ë‹¹ ì´ ì§ˆë¬¸ ìˆ˜ ìƒí•œ (4ê°œ)
      if (followupQuestions.length >= 4) break

      followupQuestions.push({
        id: cvq.id,
        type: 'can_validation',
        question: cvq.question,
        context: cvq.why_asked,
        options: cvq.options?.map(opt => ({
          value: opt.value,
          label: opt.label,
          tags: opt.tags,
        })) || [],
        fact_key: cvq.fact_key,
        affects_attributes: ['can'] as any,  // Can ì ìˆ˜ì— ì˜í–¥
      })
    }

  }

  // 6. User Insight ìƒì„± (Stage-aware)
  const userInsight = stage
    ? generateStageAwareInsight(facts, deepIntake, factBoosts.applied_rules, stage)
    : generateUserInsight(facts, deepIntake, factBoosts.applied_rules)
  
  // 6.5. Premium Report ìƒì„± (V3 - LLM ê¸°ë°˜ í™œì„±í™”!)
  // mini_module_result ì¶”ì¶œ (payloadì—ì„œ)
  const miniModuleResult = 'mini_module_result' in payload ? (payload as any).mini_module_result : undefined
  const openaiKey = env.OPENAI_API_KEY  // Bindings íƒ€ì…ì— ì •ì˜ë¨
  const sessionId = `session-${requestId}`
  
  // â˜… ë””ë²„ê·¸: í™˜ê²½ ë³€ìˆ˜ í™•ì¸
  
  // ============================================
  // LLM Judge: í›„ë³´ ì§ì—… LLM ì¬í‰ê°€ (Llama 3.1)
  // ============================================
  let llmJudgeResults: JudgeOutput | null = null
  let llmJudgeUsed = false
  
  // top10ì„ FilteredCandidate í˜•ì‹ìœ¼ë¡œ ë³€í™˜
  const candidatesForJudge = top10.map(j => ({
    job_id: j.job_id,
    job_name: j.job_name,
    slug: j.slug,
    image_url: j.image_url,
    attributes: j.attributes as Record<string, number>,
    base_scores: {
      like: j.scores.like,
      can: j.scores.can,
      risk_penalty: j.scores.risk_penalty,
    },
    exclusion_reasons: [],
  }))
  
  // SearchProfile êµ¬ì„±
  const searchProfile = {
    interests: miniModuleResult?.interests || [],
    values: miniModuleResult?.values || [],
    strengths: miniModuleResult?.strengths || [],
    constraints: userConstraints,
    sacrifice_flags: miniModuleResult?.sacrifice_flags || [],
    energy_drain_flags: miniModuleResult?.energy_drain_flags || [],
  }
  
  // roundAnswers êµ¬ì„± (deep_intakeì—ì„œ ì¶”ì¶œ)
  const roundAnswers = deepIntake?.questions?.map((q, i) => ({
    round: Math.min(3, Math.floor(i / 3) + 1) as 1 | 2 | 3,
    questionId: `q${i + 1}`,
    question: q.question,
    answer: q.answer,
    timestamp: new Date().toISOString(),
  })) || []
  
  // ë””ë²„ê·¸ ë¡œê·¸: LLM ì¡°ê±´ í™•ì¸
  
  // LLM Judge: OpenAI API í‚¤ê°€ ìˆì„ ë•Œë§Œ ì‹œë„ (ì—†ìœ¼ë©´ ìŠ¤í‚µ)
  if (openaiKey && candidatesForJudge.length > 0) {
    try {
      // v3.13: V2 pathì—ì„œë„ ë°°ê²½ ë°ì´í„° ì „ë‹¬
      let v2CareerState: { role_identity: string; career_stage_years: string } | undefined
      let v2CareerBackground: string | undefined
      if (payload.career_state) {
        v2CareerState = {
          role_identity: payload.career_state.role_identity || '',
          career_stage_years: payload.career_state.career_stage_years || '',
        }
      }
      try {
        const draftRow = await db.prepare(`SELECT aggregated_profile_json FROM analyzer_drafts WHERE session_id = ?`)
          .bind(payload.session_id).first<{ aggregated_profile_json?: string }>()
        if (draftRow?.aggregated_profile_json) {
          const profile = JSON.parse(draftRow.aggregated_profile_json)
          v2CareerBackground = profile?.narrative?.career_background
        }
      } catch { /* non-critical */ }

      const judgeInput: JudgeInput = {
        candidates: candidatesForJudge,
        searchProfile,
        roundAnswers,
        universalAnswers: universalAnswers,
        miniModuleResult: miniModuleResult,
        careerState: v2CareerState,
        careerBackground: v2CareerBackground,
      }
      llmJudgeResults = await judgeCandidates(openaiKey, db, judgeInput)
      llmJudgeUsed = true
    } catch (judgeError) {
    }
  }

  // LLM Judge ê²°ê³¼ë¥¼ scoredJobsì— ë³‘í•© (ê°œì¸í™”ëœ ì´ìœ  ë°˜ì˜)
  if (llmJudgeUsed && llmJudgeResults) {
    for (const judgeResult of llmJudgeResults.results) {
      const job = scoredJobs.find(j => j.job_id === judgeResult.job_id)
      if (job) {
        if (judgeResult.likeReason) job.likeReason = judgeResult.likeReason
        if (judgeResult.canReason) job.canReason = judgeResult.canReason
        if (judgeResult.rationale) job.rationale = judgeResult.rationale
      }
    }
  }

  // v3.9.2: Top 3 likeReason ìµœì¢… ë‹¤ì–‘ì„± ë³´ì¥
  // Top 3ê°€ ëª¨ë‘ ê°™ì€ íŒ¨í„´ì´ë©´ ê°•ì œ ìŠ¤íƒ€ì¼ ë¶„ì‚°
  diversifyTopNReasons(top3)

  // ============================================
  // Scoring Trace: í™•ì‹ ë„ + ê²°ì •ë³€ìˆ˜ ê³„ì‚°
  // ============================================
  const scoringTrace = createScoringTrace(
    top10.map(j => ({
      job_id: j.job_id,
      job_name: j.job_name,
      scores: j.scores,
      attributes: j.attributes as Record<string, number>,
    })),
    facts.map(f => ({ fact_key: f.fact_key, value_json: f.value_json }))
  )
  
  const confidenceResult = calculateConfidenceScore(
    facts.map(f => ({
      fact_key: f.fact_key,
      source: f.fact_key.startsWith('followup') ? 'followup' as const : 'minimodule' as const,
      value_json: f.value_json,
    })),
    roundAnswers.length,
    top10.map(j => j.scores.fit)
  )
  
  const keyDecisionVars = extractKeyDecisionVariables(
    scoringTrace,
    facts.map(f => ({ fact_key: f.fact_key, value_json: f.value_json }))
  )
  
  // ============================================
  // LLM Reporter: ì‹¬ë¦¬ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± (GPT-4o-mini)
  // ============================================
  let premiumReport
  
  // Hard Cut ë¦¬ìŠ¤íŠ¸ êµ¬ì„± (í•„í„°ë§ëœ ì§ì—…ë“¤)
  const hardCutList = miniModuleFilterResult?.excluded?.map(j => ({
    job_id: j.job_id,
    job_name: j.job_name,
    rule_id: j.rule_id || 'mini_module_filter',
    reason: j.reason || 'ë¯¸ë‹ˆëª¨ë“ˆ ê¸°ë°˜ ì œì™¸',
  })) || []
  

  // ============================================
  // NarrativeFacts ì¡°íšŒ (ì‹¬ë¦¬ ë¶„ì„ìš©)
  // ============================================
  let narrativeFacts: NarrativeFacts | undefined
  try {
    const narrativeRow = await db.prepare(`
      SELECT high_alive_moment, lost_moment
      FROM narrative_facts
      WHERE session_id = ?
    `).bind(payload.session_id).first<{
      high_alive_moment: string | null
      lost_moment: string | null
    }>()

    if (narrativeRow && (narrativeRow.high_alive_moment || narrativeRow.lost_moment)) {
      narrativeFacts = {
        highAliveMoment: narrativeRow.high_alive_moment || '',
        lostMoment: narrativeRow.lost_moment || '',
      }
    } else {
    }
  } catch (narrativeError) {
  }

  // RoundAnswers ì¡°íšŒ (DBì—ì„œ ì‹¤ì œ ì €ì¥ëœ 3ë¼ìš´ë“œ ë‹µë³€ ê°€ì ¸ì˜¤ê¸°)
  let dbRoundAnswers: Array<{
    roundNumber: 1 | 2 | 3
    questionId: string
    answer: string
  }> = []

  try {
    const roundAnswersRows = await db.prepare(`
      SELECT round_number, question_id, answer
      FROM round_answers
      WHERE session_id = ?
      ORDER BY round_number, question_id
    `).bind(payload.session_id).all<{
      round_number: number
      question_id: string
      answer: string
    }>()

    if (roundAnswersRows.results && roundAnswersRows.results.length > 0) {
      dbRoundAnswers = roundAnswersRows.results.map(row => ({
        roundNumber: row.round_number as 1 | 2 | 3,
        questionId: row.question_id,
        answer: row.answer,
      }))
    } else {
    }
  } catch (roundError) {
  }

  // roundAnswers ë³‘í•©: DB ìš°ì„ , deep_intakeëŠ” fallback
  const finalRoundAnswers = dbRoundAnswers.length > 0
    ? dbRoundAnswers
    : (roundAnswers || [])


  // LLM Reporter: OpenAI í‚¤ë§Œ ìˆìœ¼ë©´ í˜¸ì¶œ (í›„ë³´ê°€ ìˆì„ ë•Œ)
  if (openaiKey && candidatesForJudge.length > 0) {
    try {
      const reporterInput: ReporterInput = {
        sessionId,
        judgeResults: llmJudgeResults?.results || [],
        searchProfile,
        narrativeFacts,  // â˜… ì¶”ê°€!
        roundAnswers: finalRoundAnswers,  // â˜… DBì—ì„œ ì¡°íšŒí•œ ì‹¤ì œ ë‹µë³€ ì‚¬ìš©!
        universalAnswers: universalAnswers,
        hardCutList,
        miniModuleResult,
      }
      premiumReport = await generateLLMPremiumReport(
        env?.AI || null,
        reporterInput,
        openaiKey
      )
    } catch (reporterError) {
      // Fallback: ê·œì¹™ ê¸°ë°˜ ë¦¬í¬íŠ¸
      const premiumReportInputV3: PremiumReportInput = {
        session_id: sessionId,
        facts: facts.map(f => ({ fact_key: f.fact_key, value_json: f.value_json })),
        recommendations: top10.map(j => ({
          job_id: j.job_id,
          job_name: j.job_name,
          slug: j.slug,
          image_url: j.image_url,
          scores: j.scores,
          attributes: j.attributes as Record<string, number>,
        })),
        userInsight: userInsight,
        stage: stage,
        miniModuleResult: miniModuleResult,
      }
      premiumReport = fixParticlesDeep(generatePremiumReport(premiumReportInputV3))
    }
  } else {
    // OpenAI í‚¤ ì—†ìŒ: ê·œì¹™ ê¸°ë°˜ ë¦¬í¬íŠ¸
    const premiumReportInputV3: PremiumReportInput = {
      session_id: sessionId,
      facts: facts.map(f => ({ fact_key: f.fact_key, value_json: f.value_json })),
      recommendations: top10.map(j => ({
        job_id: j.job_id,
        job_name: j.job_name,
        slug: j.slug,
        image_url: j.image_url,
        scores: j.scores,
        attributes: j.attributes as Record<string, number>,
      })),
      userInsight: userInsight,
      stage: stage,
      miniModuleResult: miniModuleResult,
    }
    premiumReport = fixParticlesDeep(generatePremiumReport(premiumReportInputV3))
  }
  
  // 7. ì…ë ¥ ì •ë³´ ì •ë¦¬
  const lifeConstraints = extractLifeConstraints(facts)
  const universalFactsCount = facts.filter(f => f.fact_key.startsWith('profile.')).length
  const confirmedConstraints = facts
    .filter(f => f.fact_key.startsWith('confirmed_constraint.'))
    .map(f => f.fact_key.replace('confirmed_constraint.', ''))
  
  // Legacy profile ì¶”ì¶œ (V2 í˜¸í™˜)
  const legacyProfile = 'profile' in payload && payload.profile
    ? payload.profile
    : { interest: { keywords: [] }, value: { priority: [] }, skill: [], dislike: { keywords: [] }, constraints: {} }
  
  // 8. ê²°ê³¼ êµ¬ì„±
  const result: AnalysisResultJSON = {
    engine_state: stage
      ? 'phase2_stage_based'  // V3: Stage-based ë¶„ì„
      : (deepIntake ? 'phase1a_mve' : (facts.length > 0 ? 'phase1a_mve' : 'phase1a_initial')),
    engine_version: RECOMMENDATION_ENGINE_VERSION,
    mini_module_result: miniModuleResult || null,

    versions: {
      recipe: VERSIONS.recipe,
      tagger: VERSIONS.tagger,
      scoring: VERSIONS.scoring,
    },

    input_summary: {
      profile_revision_id: `rev-${requestId}-${Date.now()}`,
      key_interests: legacyProfile.interest?.keywords?.slice(0, 3) || [],
      key_skills: legacyProfile.skill?.map(s => s.name).slice(0, 3) || [],
      non_negotiables: Object.entries(legacyProfile.constraints || {})
        .filter(([_, v]) => v === true)
        .map(([k]) => k),
      preferences: [],
      facts_applied: facts.length,
      applied_rules: factBoosts.applied_rules,
      deep_intake_provided: !!deepIntake,
      insight_tags: userInsight?.key_traits.map(t => t.trait) || [],
      // V3 ì¶”ê°€ í•„ë“œ
      stage: stage,
      universal_facts_count: universalFactsCount,
      life_constraints: lifeConstraints,
      confirmed_constraints: confirmedConstraints,
    },
    
    fit_top3: top3.map(j => {
      // Evidence ìƒì„± (facts + job attributes ê¸°ë°˜)
      // âš ï¸ EvidenceëŠ” "ì„¤ëª…ìš©"ì´ë©° ì ìˆ˜ ê³„ì‚°ì— ì˜í–¥ ì—†ìŒ
      const evidenceFacts: EvidenceFact[] = facts.map(f => ({
        fact_key: f.fact_key,
        value_json: f.value_json,
      }))
      let evidenceLinks = buildEvidenceLinks(evidenceFacts, j)
      
      // Evidenceê°€ ë¶€ì¡±í•˜ë©´ ê¸°ë³¸ Evidence ì¶”ê°€
      if (evidenceLinks.length < 3) {
        const defaultEvidence = generateDefaultEvidence(j)
        evidenceLinks = [...evidenceLinks, ...defaultEvidence].slice(0, 10)
      }
      
      // Dislike ê²½ê³  ìƒì„±
      const dislikeWarnings = generateDislikeWarnings(facts, j)

      return {
        job_id: j.job_id,
        job_name: j.job_name,
        slug: j.slug,
        image_url: j.image_url,
        job_description: j.job_description || null,
        rationale: j.rationale || null,
        like_reason: j.likeReason || null,
        can_reason: j.canReason || null,
        fit_score: j.scores.fit,
        like_score: j.scores.like,
        can_score: j.scores.can,
        risk_details: [],
        evidence_links: evidenceLinks,
        dislike_warnings: dislikeWarnings,
      }
    }),

    // like_top10: like_score ê¸°ì¤€ + ë‹¤ì–‘ì„± ê°•ì œ + v3.9.2 ìµœì¢… ì•ˆì „ë§(ì •ì¹˜ì§ ì œê±°)
    like_top10: sanitizeJobListOutput(enforceDiversityOnTopN(
      [...filteredScoredJobs].filter(j => j.scores.fit >= 25).sort((a, b) => b.scores.like - a.scores.like).slice(0, 20),
      filteredScoredJobs, 'like', 10
    ).diversified.map(j => ({
        job_id: j.job_id,
        job_name: j.job_name,
        slug: j.slug,
        image_url: j.image_url,
        job_description: j.job_description || null,
        fit_score: j.scores.fit,
        like_score: j.scores.like,
        can_score: j.scores.can,
        rationale: j.rationale || null,
        like_reason: j.likeReason || null,
        can_reason: j.canReason || null,
      }))),

    // can_top10: can_score ê¸°ì¤€ + ë‹¤ì–‘ì„± ê°•ì œ + v3.9.2 ìµœì¢… ì•ˆì „ë§(ì •ì¹˜ì§ ì œê±°)
    can_top10: sanitizeJobListOutput(enforceDiversityOnTopN(
      [...filteredScoredJobs].filter(j => j.scores.fit >= 25).sort((a, b) => b.scores.can - a.scores.can).slice(0, 20),
      filteredScoredJobs, 'can', 10
    ).diversified.map(j => ({
        job_id: j.job_id,
        job_name: j.job_name,
        slug: j.slug,
        image_url: j.image_url,
        job_description: j.job_description || null,
        fit_score: j.scores.fit,
        like_score: j.scores.like,
        can_score: j.scores.can,
        rationale: j.rationale || null,
        like_reason: j.likeReason || null,
        can_reason: j.canReason || null,
      }))),

    caution_jobs: scoredJobs
      .filter(j => j.scores.risk_penalty > 20)
      .slice(0, 5)
      .map(j => ({
        job_id: j.job_id,
        job_name: j.job_name,
        slug: j.slug,
        image_url: j.image_url,
        risk_penalty: j.scores.risk_penalty,
      })),

    followup_questions: followupQuestions,
    
    ux_flags: {
      has_caution_in_top3: top3.some(j => j.scores.risk_penalty > 20),
      has_unknown_in_top3: false,
      needs_followup_question: followupQuestions.length > 0,
      counts_before_filter: {
        safe_known: scoredJobs.filter(j => j.scores.risk_penalty <= 10).length,
        safe_unknown: scoredJobs.filter(j => j.scores.risk_penalty > 10 && j.scores.risk_penalty <= 20).length,
        caution: scoredJobs.filter(j => j.scores.risk_penalty > 20).length,
        total: scoredJobs.length,
      },
      counts_after_filter: {
        safe_known: scoredJobs.filter(j => j.scores.risk_penalty <= 10).length,
        safe_unknown: scoredJobs.filter(j => j.scores.risk_penalty > 10 && j.scores.risk_penalty <= 20).length,
        caution: scoredJobs.filter(j => j.scores.risk_penalty > 20).length,
        total: scoredJobs.length,
      },
    },
    
    llm_explanation: generateExplanation(facts, factBoosts.applied_rules, top3[0]?.job_name),
    generated_at: new Date().toISOString(),
    // ì „ì²´ ì§ì—… ìˆ˜ í‘œì‹œ (DBì˜ ëª¨ë“  ì§ì—… = í‰ê°€ ëŒ€ìƒ)
    total_candidates: totalJobsInDB,
    // ì‹¤ì œ ì ìˆ˜ ê³„ì‚°ëœ ì§ì—… ìˆ˜ (í•„í„°ë§ í›„)
    scored_candidates: scoredJobs.length,
    // ë¯¸ë‹ˆëª¨ë“ˆ í•˜ë“œ í•„í„°ë¡œ ì œì™¸ëœ ì§ì—… ìˆ˜
    filtered_out_candidates: miniModuleFilterResult.stats.totalFiltered,
    
    user_insight: userInsight,
    
    // Phase 4: Diversity Guard ì •ë³´
    phase4_applied: true,
    diversity_guard_active: diversityResult.diversityApplied,
    diversity_changes: diversityResult.changes,
    
    // V3: Stage ê¸°ë°˜ ë¶„ì„ ì •ë³´
    analysis_stage: stage,
    stage_specific_insights: stage ? generateStageInsights(stage, facts) : undefined,
    
    // V3: Premium Report (í™•ì‹ ë„ í¬í•¨ â€” í”„ë¡ íŠ¸ì—”ë“œì—ì„œ report._confidenceë¡œ ì ‘ê·¼)
    premium_report: {
      ...premiumReport,
      _confidence: confidenceResult.score,
    },

    // V3: LLM ëª¨ë“ˆ ì •ë³´ (2026-02-03 í™œì„±í™”)
    llm_modules: {
      judge_used: llmJudgeUsed,
      judge_stats: llmJudgeResults?.stats || null,
      reporter_used: !!openaiKey,
      // ë””ë²„ê·¸ ì •ë³´ (í™˜ê²½ ë³€ìˆ˜ í™•ì¸ìš©)
      env_check: {
        openai_key_exists: !!openaiKey,
        openai_key_prefix: openaiKey ? String(openaiKey).substring(0, 7) : null,
        ai_binding_exists: !!env.AI,
        candidates_count: candidatesForJudge.length,
      },
    },
    
    // V3: í™•ì‹ ë„ + ê²°ì •ë³€ìˆ˜ (scoring-trace.ts)
    confidence: confidenceResult,
    key_decision_variables: keyDecisionVars.slice(0, 5),  // Top 5
    scoring_trace_summary: {
      total_features: scoringTrace.candidates[0]?.feature_contributions.length || 0,
      top_decision_variable: scoringTrace.decision_variables[0]?.fact_key || null,
    },
    
    // Debug info (only included when debugMode=true)
    debug_info: debugMode ? generateDebugInfo(
      candidateSource,
      candidateCount,
      sampleJobs.length,
      top3,
      sampleJobs,
      factBoosts,
      facts,
      followupQuestions[0],
      diversityResult
    ) : undefined,
  }
  
  // v3.9.2 ìµœì¢… ë°©ì–´: ê²°ê³¼ ë°˜í™˜ ì§ì „ ì •ì¹˜ì§/ì„ëª…ì§ ì™„ì „ ì œê±°
  // sanitizeJobListOutputì´ ì´ë¯¸ ì ìš©ë˜ì—ˆì§€ë§Œ, í˜¹ì‹œ ë†“ì¹œ ê²½ìš° ì—¬ê¸°ì„œ í•œ ë²ˆ ë”
  if (result.like_top10) {
    const before1 = result.like_top10.length
    result.like_top10 = result.like_top10.filter((j: any) => {
      const name = (j.job_name || '').trim()
      for (const p of ['ì°¨ê´€', 'ì¥ê´€', 'ë²•ì›ì¥', 'ëŒ€ë²•ê´€', 'í—Œë²•ì¬íŒê´€', 'ê²€ì°°ì´ì¥', 'ê°ì‚¬ì›ì¥', 'êµ­ë¬´ì´ë¦¬', 'ëŒ€í†µë ¹', 'êµ­íšŒì˜ì›', 'ë„ì§€ì‚¬', 'ì´ì˜ì‚¬']) {
        if (name.includes(p)) return false
      }
      if (['ëŒ€ì‚¬', 'ê³µì‚¬', 'ì‹œì¥', 'êµ°ìˆ˜', 'êµ¬ì²­ì¥'].includes(name)) return false
      return true
    })
  }
  if (result.can_top10) {
    const before2 = result.can_top10.length
    result.can_top10 = result.can_top10.filter((j: any) => {
      const name = (j.job_name || '').trim()
      for (const p of ['ì°¨ê´€', 'ì¥ê´€', 'ë²•ì›ì¥', 'ëŒ€ë²•ê´€', 'í—Œë²•ì¬íŒê´€', 'ê²€ì°°ì´ì¥', 'ê°ì‚¬ì›ì¥', 'êµ­ë¬´ì´ë¦¬', 'ëŒ€í†µë ¹', 'êµ­íšŒì˜ì›', 'ë„ì§€ì‚¬', 'ì´ì˜ì‚¬']) {
        if (name.includes(p)) return false
      }
      if (['ëŒ€ì‚¬', 'ê³µì‚¬', 'ì‹œì¥', 'êµ°ìˆ˜', 'êµ¬ì²­ì¥'].includes(name)) return false
      return true
    })
  }
  if (result.fit_top3) {
    result.fit_top3 = result.fit_top3.filter((j: any) => {
      const name = (j.job_name || '').trim()
      for (const p of ['ì°¨ê´€', 'ì¥ê´€', 'ë²•ì›ì¥', 'ëŒ€ë²•ê´€', 'í—Œë²•ì¬íŒê´€', 'ê²€ì°°ì´ì¥', 'ê°ì‚¬ì›ì¥', 'êµ­ë¬´ì´ë¦¬', 'ëŒ€í†µë ¹', 'êµ­íšŒì˜ì›', 'ë„ì§€ì‚¬', 'ì´ì˜ì‚¬']) {
        if (name.includes(p)) return false
      }
      if (['ëŒ€ì‚¬', 'ê³µì‚¬', 'ì‹œì¥', 'êµ°ìˆ˜', 'êµ¬ì²­ì¥'].includes(name)) return false
      return true
    })
  }

  return result
}

// ============================================
// Debug Info Generator (for test UI)
// ============================================
interface SampleJobWithBase {
  job_id: string
  job_name: string
  base_like: number
  base_can: number
  base_risk: number
  attributes: Record<string, number>
}

function generateDebugInfo(
  candidateSource: 'vectorize' | 'db_fallback' | 'sample_fallback' | 'vector' | 'random',
  candidateCount: number,
  totalInDb: number,
  top3: ScoredJob[],
  sampleJobs: SampleJobWithBase[],
  factBoosts: { like_boost: number; can_boost: number; risk_boost: number; applied_rules: string[] },
  facts: Fact[],
  firstFollowup: FollowupQuestion | undefined,
  diversityResult: { diversityApplied: boolean; changes: string[] }
): DebugInfo {
  // Score breakdown for TOP3
  const scoreBreakdown = top3.map(job => {
    const baseJob = sampleJobs.find(s => s.job_id === job.job_id)
    const baseLike = baseJob?.base_like || 50
    const baseCan = baseJob?.base_can || 50
    const baseRisk = baseJob?.base_risk || 10
    
    // Calculate boosts per rule (simplified)
    const likeBoosts = factBoosts.applied_rules
      .filter(r => r.includes('interest') || r.includes('priority') || r.includes('value'))
      .map(r => ({ rule: r, delta: Math.round(factBoosts.like_boost / Math.max(1, factBoosts.applied_rules.length)) }))
    
    const canBoosts = factBoosts.applied_rules
      .filter(r => r.includes('workstyle') || r.includes('strength') || r.includes('skill'))
      .map(r => ({ rule: r, delta: Math.round(factBoosts.can_boost / Math.max(1, factBoosts.applied_rules.length)) }))
    
    const riskBoosts = factBoosts.applied_rules
      .filter(r => r.includes('constraint') || r.includes('dislike'))
      .map(r => ({ rule: r, delta: factBoosts.risk_boost }))
    
    return {
      job_id: job.job_id,
      job_name: job.job_name,
      base_like: baseLike,
      base_can: baseCan,
      base_risk: baseRisk,
      like_boosts: likeBoosts,
      can_boosts: canBoosts,
      risk_boosts: riskBoosts,
      final_like: job.scores.like,
      final_can: job.scores.can,
      final_risk: job.scores.risk_penalty,
      final_fit: job.scores.fit,
    }
  })
  
  // Applied facts summary
  const appliedFacts = facts.slice(0, 10).map(f => {
    let valueStr = ''
    try {
      const parsed = JSON.parse(f.value_json)
      valueStr = Array.isArray(parsed.value) ? parsed.value.join(', ') : String(parsed.value || '')
    } catch {
      valueStr = f.value_json
    }
    return {
      fact_key: f.fact_key,
      value: valueStr.slice(0, 50),
      effect: factBoosts.applied_rules.includes(f.fact_key) ? 'applied' : 'stored',
    }
  })
  
  // Followup rationale
  const followupRationale = firstFollowup ? {
    split_attribute: firstFollowup.affects_attributes?.[0] || firstFollowup.constraint || 'unknown',
    split_gain: 0.5, // Placeholder - actual splitGain calculation is complex
    reason: firstFollowup.context || 'TOP3 ì§ì—… ê°„ ë¶„ë³„ë ¥ í–¥ìƒ',
  } : undefined
  
  return {
    candidate_source: candidateSource,
    candidate_count: candidateCount,
    total_in_db: totalInDb,
    score_breakdown: scoreBreakdown,
    followup_rationale: followupRationale,
    applied_facts: appliedFacts,
    versions: {
      recipe: VERSIONS.recipe,
      tagger: VERSIONS.tagger,
      scoring: VERSIONS.scoring,
      embedding: 'bge-base-en-v1.5', // Vectorize í™œì„±í™” (2026-01-16)
    },
    diversity_guard_triggered: diversityResult.diversityApplied,
    research_bias_cap_applied: diversityResult.changes.some(c => c.includes('Research')),
  }
}

// V3: Stageë³„ ë§ì¶¤ ì¸ì‚¬ì´íŠ¸ ìƒì„±
function generateStageInsights(stage: AnalysisStage, facts: Fact[]): string[] {
  const insights: string[] = []
  
  switch (stage) {
    case 'job_explore':
      insights.push('íƒìƒ‰ ë‹¨ê³„: ë‹¤ì–‘í•œ ì§ì—…êµ°ì„ í­ë„“ê²Œ ê²€í† í•˜ê³  ìˆìŠµë‹ˆë‹¤.')
      if (facts.some(f => f.fact_key.includes('interest'))) {
        insights.push('ê´€ì‹¬ ë¶„ì•¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œì´ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤.')
      }
      break
    case 'job_student':
      insights.push('í•™ìƒ ë‹¨ê³„: ì „ê³µÂ·ì§„ë¡œ ì—°ê³„ì„±ì´ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.')
      if (facts.some(f => f.fact_key.includes('constraints'))) {
        insights.push('ìê²©Â·ì‹œê°„ ì œì•½ì´ ê³ ë ¤ë˜ì—ˆìŠµë‹ˆë‹¤.')
      }
      break
    case 'job_early':
      insights.push('ì´ˆê¸° ê²½ë ¥ ë‹¨ê³„: ì„±ì¥ ê°€ëŠ¥ì„±ì´ ê°•ì¡°ë˜ì—ˆìŠµë‹ˆë‹¤.')
      if (facts.some(f => f.fact_key.includes('dislike'))) {
        insights.push('ê¸°í”¼ ìš”ì†Œê°€ ì œì™¸ í•„í„°ì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.')
      }
      break
    default:
      break
  }
  
  return insights
}

// ============================================
// Stage-based Follow-up ì§ˆë¬¸ ìƒì„±
// ============================================
function generateStageBasedFollowups(
  candidates: ScoredJob[],
  topK: ScoredJob[],
  existingFacts: { fact_key: string }[],
  stage: AnalysisStage,
  hasDeepIntake: boolean
): FollowupQuestion[] {
  // Stageì— ë§ëŠ” ì§ˆë¬¸ í’€ ê°€ì ¸ì˜¤ê¸°
  const stageQuestions = getQuestionsForStage(stage)
  
  // ì´ë¯¸ ë‹µë³€í•œ fact_key ì œì™¸
  const answeredKeys = new Set(existingFacts.map(f => f.fact_key))
  const availableQuestions = stageQuestions.filter(q => !answeredKeys.has(q.fact_key))
  
  if (availableQuestions.length === 0) {
    // Stage ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ fallback
    return generateFollowupQuestions({
      candidates,
      topK,
      existingFacts,
      hasDeepIntake,
    }, 3)
  }
  
  // ì •ë³´ì´ë“ ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨ ë²„ì „)
  const scoredQuestions = availableQuestions.map(q => {
    let score = 0
    
    // 1. íƒ€ì…ë³„ ê¸°ë³¸ ì ìˆ˜
    if (q.type === 'behavior' && !hasDeepIntake) score += 10
    if (q.type === 'tradeoff') score += 8
    if (q.type === 'projection') score += 6
    if (q.type === 'scenario') score += 5
    if (q.type === 'narrative' && hasDeepIntake) score += 7
    
    // 2. TOP10 ì°¨ë³„í™” ê°€ëŠ¥ì„±
    const affectedAttrs = q.affects_attributes
    const attrVariance = calculateAttributeVariance(topK, affectedAttrs)
    score += attrVariance * 2
    
    return { question: q, score }
  })
  
  // ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
  scoredQuestions.sort((a, b) => b.score - a.score)
  
  // ìƒìœ„ 3~5ê°œ ì„ íƒ
  const maxQuestions = hasDeepIntake ? 3 : 5
  const selected = scoredQuestions.slice(0, maxQuestions)
  
  // FollowupQuestion í˜•ì‹ìœ¼ë¡œ ë³€í™˜
  return selected.map(sq => ({
    id: sq.question.question_id,
    type: sq.question.type as any,
    question: getQuestionText(sq.question, stage),
    context: `Stage: ${stage}`,
    options: sq.question.options.map(o => ({
      value: o.value,
      label: o.label,
      tags: o.tags,
    })),
    fact_key: sq.question.fact_key,
    affects_attributes: sq.question.affects_attributes,
  }))
}

// ì†ì„± ë¶„ì‚° ê³„ì‚° (TOP10 ê°„ ì°¨ì´)
function calculateAttributeVariance(jobs: ScoredJob[], attrs: string[]): number {
  if (jobs.length === 0 || attrs.length === 0) return 0
  
  let totalVariance = 0
  for (const attr of attrs) {
    const values = jobs.map(j => {
      const attrValue = (j.attributes as any)[attr]
      return typeof attrValue === 'number' ? attrValue : 50
    })
    
    const mean = values.reduce((a, b) => a + b, 0) / values.length
    const variance = values.reduce((sum, v) => sum + Math.pow(v - mean, 2), 0) / values.length
    totalVariance += Math.sqrt(variance)
  }
  
  return totalVariance / attrs.length
}

// ============================================
// Stage-aware User Insight ìƒì„±
// ============================================
function generateStageAwareInsight(
  facts: Fact[],
  deepIntake: NormalizedDeepIntake | undefined,
  appliedRules: string[],
  stage: AnalysisStage
): UserInsight | undefined {
  // ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±
  const baseInsight = generateUserInsight(facts, deepIntake, appliedRules)
  
  if (!baseInsight) {
    // factsê°€ ì—†ì–´ë„ stage ê¸°ë°˜ ê¸°ë³¸ ë©”ì‹œì§€
    const wording = INSIGHT_WORDING[stage]
    return {
      summary: 'ë” ë§ì€ ì •ë³´ë¥¼ ì…ë ¥í•˜ì‹œë©´ ë§ì¶¤ ì¸ì‚¬ì´íŠ¸ë¥¼ ë“œë¦´ ìˆ˜ ìˆì–´ìš”.',
      key_traits: [],
      applied_facts: [],
    }
  }
  
  // Stageë³„ wording ì ìš©
  const wording = INSIGHT_WORDING[stage]
  
  // ìš”ì•½ ë¬¸ì¥ ì¬ìƒì„±
  const topTraits = baseInsight.key_traits.slice(0, 3).map(t => t.trait)
  let summary = ''
  
  if (topTraits.length > 0) {
    summary = `${wording.summary_prefix}${topTraits.join(', ')} ì„±í–¥ì´ ë³´ì…ë‹ˆë‹¤.`
  } else if (baseInsight.applied_facts.length > 0) {
    summary = `${baseInsight.applied_facts.length}ê°œì˜ ë‹µë³€ì„ ë¶„ì„í•˜ì—¬ ë§ì¶¤ ì¶”ì²œì„ ì œê³µí–ˆìŠµë‹ˆë‹¤.`
  } else {
    summary = 'ë” ë§ì€ ì •ë³´ë¥¼ ì…ë ¥í•˜ì‹œë©´ ë” ì •í™•í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë“œë¦´ ìˆ˜ ìˆì–´ìš”.'
  }
  
  // evidence ë¼ë²¨ ì—…ë°ì´íŠ¸
  const updatedTraits = baseInsight.key_traits.map(trait => ({
    ...trait,
    evidence: trait.evidence.includes('ì„ íƒ') 
      ? trait.evidence.replace('ì„ íƒ', wording.evidence_label)
      : trait.evidence,
  }))
  
  return {
    summary,
    key_traits: updatedTraits,
    applied_facts: baseInsight.applied_facts,
  }
}

// Life constraints ì¶”ì¶œ
function extractLifeConstraints(facts: Fact[]): string[] {
  const lifeConstraintFact = facts.find(f => f.fact_key === 'profile.life_constraint')
  if (!lifeConstraintFact) return []
  
  try {
    const value = JSON.parse(lifeConstraintFact.value_json)
    return Array.isArray(value.value) ? value.value : [value.value]
  } catch {
    return []
  }
}

// ============================================
// V3 Premium Report API
// ============================================
analyzerRoutes.post('/v3/report', async (c) => {
  const env = c.env as { DB: D1Database }
  const db = env.DB

  try {
    const body = await c.req.json<{
      request_id: number
      session_id?: string
    }>()

    // request_idë¡œ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (ai_analysis_requests + ai_analysis_results JOIN)
    const requestRow = await db.prepare(`
      SELECT
        req.id as request_id,
        req.prompt_payload as request_payload,
        req.session_id,
        res.result_json
      FROM ai_analysis_requests req
      LEFT JOIN ai_analysis_results res ON req.id = res.request_id
      WHERE req.id = ?
    `).bind(body.request_id).first<{
      request_id: number
      request_payload: string
      session_id: string | null
      result_json: string | null
    }>()

    // ì†Œìœ ê¶Œ ê²€ì¦: session_idê°€ ì¼ì¹˜í•´ì•¼ ì ‘ê·¼ ê°€ëŠ¥
    if (requestRow && body.session_id && requestRow.session_id !== body.session_id) {
      return c.json({ error: 'FORBIDDEN', message: 'ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤' }, 403)
    }
    
    if (!requestRow) {
      return c.json({ 
        error: 'NOT_FOUND',
        message: 'ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
      }, 404)
    }
    
    if (!requestRow.result_json) {
      return c.json({
        error: 'NOT_READY',
        message: 'ë¶„ì„ì´ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'
      }, 400)
    }
    
    // ë¶„ì„ ê²°ê³¼ íŒŒì‹±
    const analysisResult = JSON.parse(requestRow.result_json)
    
    // facts ì¡°íšŒ (facts í…Œì´ë¸”ì—ì„œ, ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´)
    let facts: { fact_key: string; value_json: string }[] = []
    try {
      const factsResult = await db.prepare(`
        SELECT fact_key, value_json
        FROM facts
        WHERE session_id = ?
        ORDER BY collected_at DESC
      `).bind(body.session_id || `session-${body.request_id}`).all<{
        fact_key: string
        value_json: string
      }>()
      facts = factsResult.results || []
    } catch (e) {
      // facts í…Œì´ë¸”ì´ ì—†ê±°ë‚˜ ì—ëŸ¬ì‹œ ë¹ˆ ë°°ì—´ ìœ ì§€
    }
    
    // ì¶”ì²œ ê²°ê³¼ë¥¼ ScoredJobForEvidence í˜•íƒœë¡œ ë³€í™˜
    const recommendations: ScoredJobForEvidence[] = (analysisResult.fit_top3 || []).map((job: any) => ({
      job_id: job.job_id,
      job_name: job.job_name,
      scores: {
        fit: job.fit_score || 50,
        like: job.like_score || 50,
        can: job.can_score || 50,
        risk_penalty: 0,
      },
      attributes: {
        wlb: 50,
        growth: 50,
        stability: 50,
        income: 50,
        ...job.attributes,
      },
    }))
    
    // Premium Report ìƒì„±
    const sessionId = body.session_id || `session-${body.request_id}`
    const reportInput: PremiumReportInput = {
      session_id: sessionId,
      facts: facts.map(f => ({
        fact_key: f.fact_key,
        value_json: f.value_json,
      })),
      recommendations,
      userInsight: analysisResult.user_insight,
      stage: analysisResult.input_summary?.stage,
    }
    
    const premiumReport = generatePremiumReport(reportInput)
    
    // ============================================
    // User Profile ìŠ¤ëƒ…ìƒ· ì €ì¥ (P1 ê¸°ëŠ¥)
    // ============================================
    try {
      // ì´ì „ ìŠ¤ëƒ…ìƒ· ì¡°íšŒ
      const previousSnapshot = await getLatestProfileSnapshot(db, sessionId)
      
      // í”„ë¡œí•„ ë¹Œë“œ
      const profile = await buildProfileFromTurns(db, sessionId, previousSnapshot?.profile)
      
      // ìŠ¤ëƒ…ìƒ· ì €ì¥
      await saveProfileSnapshot(
        db,
        sessionId,
        undefined, // user_idëŠ” ì„¸ì…˜ì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìœ¼ë©´ ì¶”ê°€
        body.request_id,
        premiumReport.report_id,
        'premium_report',
        profile,
        previousSnapshot?.id
      )
      
    } catch (profileError) {
      // í”„ë¡œí•„ ì €ì¥ ì‹¤íŒ¨í•´ë„ ë³´ê³ ì„œëŠ” ë°˜í™˜ (graceful degradation)
    }
    
    return c.json({
      success: true,
      report: premiumReport,
    })
    
  } catch (error) {
    return c.json({
      error: 'INTERNAL_ERROR',
      message: error instanceof Error ? error.message : 'Unknown error',
    }, 500)
  }
})

// ============================================
// V3 Purpose-based Followup API
// ============================================
analyzerRoutes.post('/v3/followup-questions', async (c) => {
  const env = c.env as { DB: D1Database }
  const db = env.DB
  
  try {
    const body = await c.req.json<{
      request_id: number
      session_id?: string
    }>()
    
    // ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (ai_analysis_results í…Œì´ë¸”ì—ì„œ)
    const requestRow = await db.prepare(`
      SELECT result_json
      FROM ai_analysis_results
      WHERE request_id = ?
    `).bind(body.request_id).first<{ result_json: string | null }>()
    
    if (!requestRow?.result_json) {
      return c.json({
        error: 'NOT_FOUND',
        message: 'ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
      }, 404)
    }
    
    const analysisResult = JSON.parse(requestRow.result_json)
    
    // facts ì¡°íšŒ (facts í…Œì´ë¸”ì—ì„œ, ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´)
    let facts: { fact_key: string; value_json: string }[] = []
    try {
      const factsResult = await db.prepare(`
        SELECT fact_key, value_json
        FROM facts
        WHERE session_id = ?
        ORDER BY collected_at DESC
      `).bind(body.session_id || `session-${body.request_id}`).all<{
        fact_key: string
        value_json: string
      }>()
      facts = factsResult.results || []
    } catch (e) {
    }
    
    // ì¶”ì²œ ê²°ê³¼ ë³€í™˜
    const topK = (analysisResult.fit_top3 || []).map((job: any) => ({
      job_id: job.job_id,
      job_name: job.job_name,
      scores: {
        fit: job.fit_score || 50,
        like: job.like_score || 50,
        can: job.can_score || 50,
        risk_penalty: 0,
      },
      attributes: {
        wlb: 50,
        growth: 50,
        stability: 50,
        income: 50,
        people_facing: 50,
        remote_possible: 50,
        ...job.attributes,
      },
    }))
    
    // Purpose-based Followup ìƒì„±
    const input: PurposeBasedFollowupInput = {
      candidates: topK,
      topK,
      facts,
      maxQuestions: 3,
    }
    
    const followupQuestions = generatePurposeBasedFollowups(input)
    
    return c.json({
      success: true,
      followup_questions: followupQuestions,
      question_count: followupQuestions.length,
    })
    
  } catch (error) {
    return c.json({
      error: 'INTERNAL_ERROR',
      message: error instanceof Error ? error.message : 'Unknown error',
    }, 500)
  }
})

// ============================================
// Tagger Routes ì œê±°ë¨ (2026-01-26)
// íƒœê¹… ì˜ì¡´ë„ ì™„ì „ ì œê±° - ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´
// ============================================

// ============================================
// Mount Draft Routes (P0: ì„ì‹œì €ì¥)
// ============================================
analyzerRoutes.route('/draft', draftRoutes)

// ============================================
// Mount History Routes (ê²°ê³¼ ì´ë ¥)
// ============================================
analyzerRoutes.route('/history', historyRoutes)

// ============================================
// Mount Resume Routes (P0: ì´ë ¥ì„œ í…ìŠ¤íŠ¸ íŒŒì‹±)
// ============================================
analyzerRoutes.route('/resume', resumeRoutes)

// ============================================
// Mount Profile Routes (í”„ë¡œí•„ ì¡°íšŒ/ì—…ë°ì´íŠ¸)
// ============================================
analyzerRoutes.route('/profile', profileRoutes)

// ============================================
// POST /api/ai-analyzer/add-context
// ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì €ì¥ + ë²„ì „ ê´€ë¦¬ ìš”ì²­ ìƒì„±
// ============================================
analyzerRoutes.post('/add-context', async (c) => {
  const env = c.env as Bindings
  const db = env.DB

  const authUser = c.get('user') as { id: number } | undefined
  if (!authUser?.id) {
    return c.json({ error: 'UNAUTHORIZED', message: 'Login required' }, 401)
  }
  const userId = authUser.id

  try {
    const { request_id, additional_text } = await c.req.json<{
      request_id: number
      additional_text: string
    }>()

    if (!request_id || !additional_text || additional_text.trim().length < 30) {
      return c.json({ error: 'VALIDATION_ERROR', message: 'ì¶”ê°€ í…ìŠ¤íŠ¸ëŠ” 30ì ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.' }, 400)
    }

    // ê¸°ì¡´ request ì¡°íšŒ
    const existingReq = await db.prepare(`
      SELECT req.id, req.session_id, req.analysis_type, req.user_id, req.version_number
      FROM ai_analysis_requests req
      WHERE req.id = ? AND req.user_id = ?
    `).bind(request_id, userId).first<{
      id: number; session_id: string; analysis_type: string; user_id: number; version_number: number | null
    }>()

    if (!existingReq) {
      return c.json({ error: 'NOT_FOUND', message: 'í•´ë‹¹ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.' }, 404)
    }

    // ë™ì‹œ ë¶„ì„ ë°©ì§€: ê°™ì€ session_idì— processing ìƒíƒœê°€ ìˆëŠ”ì§€ í™•ì¸
    const processing = await db.prepare(`
      SELECT id FROM ai_analysis_requests WHERE session_id = ? AND status = 'processing'
    `).bind(existingReq.session_id).first<{ id: number }>()
    if (processing) {
      return c.json({ error: 'CONFLICT', message: 'ì´ë¯¸ ë¶„ì„ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.' }, 429)
    }

    const currentVersion = existingReq.version_number || 1
    const newVersion = currentVersion + 1
    const trimmedText = additional_text.trim()
    const versionNote = 'ë‚´ìš© ì¶”ê°€: ' + (trimmedText.length > 30 ? trimmedText.substring(0, 30) + '...' : trimmedText)

    // ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ë¥¼ analyzer_factsì— ì €ì¥
    await db.prepare(`
      INSERT INTO analyzer_facts (user_id, session_id, fact_key, value_json, value_text, source, confidence_weight, created_at)
      VALUES (?, ?, 'additional_context', ?, ?, 'user_input', 1.0, datetime('now'))
    `).bind(userId, existingReq.session_id, JSON.stringify(trimmedText), trimmedText).run()

    // ìƒˆ ë²„ì „ ìš”ì²­ ìƒì„±
    const newReqResult = await db.prepare(`
      INSERT INTO ai_analysis_requests (
        user_id, session_id, analysis_type, status,
        parent_request_id, version_number, version_note,
        payload_json, created_at
      ) VALUES (?, ?, ?, 'pending', ?, ?, ?, ?, datetime('now'))
      RETURNING id
    `).bind(
      userId,
      existingReq.session_id,
      existingReq.analysis_type,
      request_id,
      newVersion,
      versionNote,
      JSON.stringify({ add_context: true, additional_text: trimmedText, source_request_id: request_id })
    ).first<{ id: number }>()

    if (!newReqResult) {
      return c.json({ error: 'INTERNAL_ERROR', message: 'ìš”ì²­ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.' }, 500)
    }

    // ë¶„ì„ í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ URL ìƒì„± (ê¸°ì¡´ ì„¸ì…˜ ë°ì´í„° + ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ë¡œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰)
    const analyzerUrl = `/${existingReq.analysis_type === 'major' ? 'analyzer/major' : 'analyzer/job'}?session_id=${encodeURIComponent(existingReq.session_id)}&add_context=true&request_id=${newReqResult.id}`

    return c.json({
      success: true,
      new_request_id: newReqResult.id,
      version_number: newVersion,
      redirect_url: analyzerUrl,
      message: 'ì¶”ê°€ ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ì¬ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤.',
    })
  } catch (error) {
    return c.json({ error: 'INTERNAL_ERROR', message: error instanceof Error ? error.message : 'Unknown error' }, 500)
  }
})

// ============================================
// V3: 3ë¼ìš´ë“œ ì‹¬ì¸µ ì§ˆë¬¸ ìƒì„± API (2026-01-16)
// POST /api/ai-analyzer/v3/round-questions
// ============================================
import { generateRoundQuestions, generateMajorRoundQuestions, buildSearchProfileFromAnswers } from './llm-interviewer'

analyzerRoutes.post('/v3/round-questions', async (c) => {
  const env = c.env as Bindings
  const db = env.DB
  
  try {
    const body = await c.req.json<{
      session_id: string
      round_number: 1 | 2 | 3
      analysis_type?: 'job' | 'major'
      narrative_facts?: { highAliveMoment: string; lostMoment: string; life_story?: string; storyAnswer?: string; existentialAnswer?: string }
      previous_round_answers?: Array<{
        questionId: string
        questionText?: string  // ì§ˆë¬¸ í…ìŠ¤íŠ¸ (ë‹¤ìŒ ë¼ìš´ë“œ ì»¨í…ìŠ¤íŠ¸ìš©)
        roundNumber: 1 | 2 | 3
        answer: string
        answeredAt: string
      }>
      universal_answers?: Record<string, string | string[]>
      career_state?: {
        role_identity: string
        career_stage_years: string
        transition_status: string
      }
      transition_signal?: Record<string, any>
      // ë¯¸ë‹ˆëª¨ë“ˆ ê²°ê³¼ (LLM íŒë‹¨ ì•µì»¤!)
      mini_module_result?: {
        interest_top: string[]
        value_top: string[]
        strength_top: string[]
        constraint_flags: string[]
        low_confidence_flags?: string[]
        internal_conflict_flags?: string[]
      }
    }>()

    const { session_id, round_number, analysis_type, narrative_facts, previous_round_answers, universal_answers, career_state, transition_signal, mini_module_result } = body
    
    // ê²€ì¦
    if (!session_id) {
      return c.json({ success: false, error: 'session_id is required' }, 400)
    }
    if (![1, 2, 3].includes(round_number)) {
      return c.json({ success: false, error: 'round_number must be 1, 2, or 3' }, 400)
    }
    
    // ============================================
    // LLM Gate: í•„ìˆ˜ ë°ì´í„° ê²€ì¦ + í´ë°± ì§ˆë¬¸ ë°˜í™˜
    // ============================================
    // AggregatedProfile ë¹Œë“œ (ìš”ì²­ ë°ì´í„°ë¡œ ì„ì‹œ ìƒì„±)
    const tempProfile: AggregatedProfile = {
      profile_version: 0,
      generated_at: new Date().toISOString(),
      anchors: {
        interest_top: mini_module_result?.interest_top || [],
        value_top: mini_module_result?.value_top || [],
        strength_top: mini_module_result?.strength_top || [],
        constraint_flags: mini_module_result?.constraint_flags || [],
        low_confidence_flags: mini_module_result?.low_confidence_flags,
        internal_conflict_flags: mini_module_result?.internal_conflict_flags,
      },
      narrative: {
        life_story: narrative_facts?.life_story || narrative_facts?.storyAnswer,
        high_alive: narrative_facts?.highAliveMoment,
        lost_moment: narrative_facts?.lostMoment,
      },
      universals: {
        priority: universal_answers?.univ_priority as string | undefined,
        interests: universal_answers?.univ_interest as string[] | undefined,
        dislikes: universal_answers?.univ_dislike as string[] | undefined,
      },
      transition: {},
      rounds: previous_round_answers ? [{
        round: (round_number > 1 ? round_number - 1 : 1) as 1|2|3,
        questions: [],
        answers: previous_round_answers.map(a => ({ question_id: a.questionId, answer: a.answer })),
      }] : [],
      memory: {
        stable_drivers: [],
        recurring_fears: [],
        decision_rules: [],
        contradictions: [],
        open_loops: [],
        resolved_loops: [],
        emotional_triggers: [],
      },
      evidence_index: {},
    }
    
    // Gate ê²€ì¦ (ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  LLM í˜¸ì¶œì€ ê³„ì† ì§„í–‰)
    const gatePhase: GatePhase = `round${round_number}` as GatePhase
    const gateResult = assertReadyForLLM(tempProfile, gatePhase)
    
    if (!gateResult.passed) {
      // Gate ì‹¤íŒ¨í•´ë„ LLM í˜¸ì¶œì€ ê³„ì† ì§„í–‰ (ë°ì´í„° ë¶€ì¡±í•´ë„ ì§ˆë¬¸ ìƒì„± ì‹œë„)
    }
    
    // ============================================
    // DBì—ì„œ Memory ì¡°íšŒ (ëˆ„ì  ë©”ëª¨ë¦¬)
    // ============================================
    let memoryData = undefined
    try {
      const draft = await db
        .prepare('SELECT memory_json FROM analyzer_drafts WHERE session_id = ?')
        .bind(session_id)
        .first<{ memory_json?: string }>()
      
      if (draft?.memory_json) {
        memoryData = JSON.parse(draft.memory_json)
      }
    } catch (memError) {
    }
    
    // ============================================
    // CAG Manager: ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ (2026-02-03 í™œì„±í™”)
    // ============================================
    let cagState: CAGState | null = null
    try {
      cagState = await getOrCreateCAGState(db, session_id)
    } catch (cagError) {
    }
    
    // ì´ì „ ë¼ìš´ë“œ ë‹µë³€ì„ CAGì— ê¸°ë¡
    if (cagState && previous_round_answers && previous_round_answers.length > 0) {
      for (const ans of previous_round_answers) {
        logAnswerReceived(cagState, ans.questionId, ans.answer)
      }
    }
    
    // ============================================
    // LLM Interviewer í˜¸ì¶œ (Gate í†µê³¼ + Memory + CAG í¬í•¨)
    // analysis_type === 'major' â†’ ì „ê³µìš© ì¸í„°ë·°ì–´, ê·¸ ì™¸ â†’ ì§ì—…ìš© ì¸í„°ë·°ì–´
    // ============================================
    const interviewerInput = {
      sessionId: session_id,
      roundNumber: round_number,
      narrativeFacts: narrative_facts,
      previousRoundAnswers: previous_round_answers || [],
      universalAnswers: universal_answers,
      careerState: career_state,
      transitionSignal: transition_signal,
      miniModuleResult: mini_module_result,
      memory: memoryData,
      openaiApiKey: (env as any).OPENAI_API_KEY,
    }
    const result = analysis_type === 'major'
      ? await generateMajorRoundQuestions(env.AI || null, interviewerInput)
      : await generateRoundQuestions(env.AI || null, interviewerInput)
    
    // ============================================
    // CAG: ìƒì„±ëœ ì§ˆë¬¸ ë¡œê·¸ ê¸°ë¡ + ì¤‘ë³µ í•„í„°
    // ============================================
    let filteredQuestions = result.questions
    if (cagState) {
      // ì¤‘ë³µ ì§ˆë¬¸ í•„í„°ë§ (ì„ê³„ê°’ 0.6ìœ¼ë¡œ ê°•í™”)
      filteredQuestions = result.questions.filter(q => {
        // questionTextê°€ ìˆì„ ë•Œë§Œ ì¤‘ë³µ ì²´í¬ (undefined ë°©ì§€)
        if (!q.questionText) return true
        const isDuplicate = isQuestionAlreadyAsked(cagState!, q.questionText, 0.6)
        if (isDuplicate) {
        }
        return !isDuplicate
      })

      // H1 safeguard: í•„í„°ë§ í›„ ìµœì†Œ 3ê°œ ì§ˆë¬¸ ë³´ì¥
      if (filteredQuestions.length < 3 && result.questions.length >= 3) {
        filteredQuestions = result.questions
      }

      // ìƒì„±ëœ ì§ˆë¬¸ ë¡œê·¸ ê¸°ë¡
      for (const q of filteredQuestions) {
        logAskedQuestion(cagState, {
          questionId: q.questionId,
          questionText: q.questionText,
          round: round_number,
          askedAt: new Date().toISOString(),
          answered: false,
        })
      }
      
      // CAG ìƒíƒœ ì €ì¥
      try {
        await saveCAGState(db, cagState)
      } catch (saveError) {
      }
    }
    
    // P2: ìˆ˜ì§‘ ì§„í–‰ë„ ìš”ì•½ ìƒì„±
    const collectionProgressSummary = cagState
      ? getCollectionProgressSummary(cagState)
      : null

    return c.json({
      success: true,
      round: result.round,
      questions: filteredQuestions,
      generated_by: result.generatedBy,
      metadata: {
        ...result.metadata,
        cag_filtered: result.questions.length - filteredQuestions.length,
        total_questions_asked: cagState?.asked_questions_log.length || 0,
      },
      collection_progress: collectionProgressSummary,
    })
    
  } catch (error: any) {
    return c.json({
      success: false,
      error: error.message || 'Unknown error',
      detail: error.stack ? error.stack.split('\n')[0] : undefined,
    }, 500)
  }
})

// ============================================
// V3: ë¼ìš´ë“œ ë‹µë³€ ì €ì¥ API
// POST /api/ai-analyzer/v3/round-answers
// ============================================
analyzerRoutes.post('/v3/round-answers', async (c) => {
  const env = c.env as Bindings
  const db = env.DB
  
  try {
    const body = await c.req.json<{
      session_id: string
      request_id?: number
      round_number: 1 | 2 | 3
      answers: Array<{
        question_id: string
        question_text?: string
        purpose_tag: 'ENGINE' | 'AVOIDANCE' | 'INTEGRATION'
        answer: string
      }>
    }>()
    
    const { session_id, request_id, round_number, answers } = body
    
    // P0-1: session_id ê²€ì¦ ê°•í™”
    if (!session_id || session_id.trim() === '') {
      return c.json({ 
        success: false, 
        error: 'session_id is required and cannot be empty',
        detail: 'session_id_validation_failed'
      }, 400)
    }
    
    if (!answers || answers.length === 0) {
      return c.json({ success: false, error: 'answers array is required' }, 400)
    }
    
    // P0-1: ì…ë ¥ê°’ ë¡œê¹…
    
    // ë‹µë³€ ì €ì¥
    const insertStmt = db.prepare(`
      INSERT INTO round_answers (session_id, request_id, round_number, question_id, question_text, purpose_tag, answer)
      VALUES (?, ?, ?, ?, ?, ?, ?)
    `)
    
    const results = await Promise.all(
      answers.map(ans => 
        insertStmt.bind(
          session_id,
          request_id || null,
          round_number,
          ans.question_id,
          ans.question_text || null,
          ans.purpose_tag,
          ans.answer
        ).run()
      )
    )
    
    const successCount = results.filter(r => r.success).length
    
    // ============================================
    // P2: ìˆ˜ì§‘ ì§„í–‰ë„ ì—…ë°ì´íŠ¸ (Round ë‹µë³€ ì €ì¥ í›„)
    // ============================================
    let collectionProgressSummary = null
    try {
      const cagState = await getOrCreateCAGState(db, session_id)

      // ë‹µë³€ purpose_tag â†’ fact_key ë§¤í•‘
      for (const ans of answers) {
        // purpose_tagì— ë”°ë¼ fact key prefix ê²°ì •
        let factKeyPrefix = ''
        if (ans.purpose_tag === 'ENGINE') {
          // ENGINE = Like (ê´€ì‹¬ì‚¬, ê°€ì¹˜ê´€)
          factKeyPrefix = 'like.round_answer'
        } else if (ans.purpose_tag === 'AVOIDANCE') {
          // AVOIDANCE = Risk (ì œì•½ì¡°ê±´)
          factKeyPrefix = 'risk.round_answer'
        } else if (ans.purpose_tag === 'INTEGRATION') {
          // INTEGRATION = Can (ëŠ¥ë ¥, ê²½í—˜)
          factKeyPrefix = 'can.round_answer'
        }

        if (factKeyPrefix) {
          const factKey = `${factKeyPrefix}.r${round_number}.${ans.question_id}`
          updateCollectionProgress(cagState, factKey)
        }
      }

      // ì €ì¥ ë° ìš”ì•½ ìƒì„±
      await saveCAGState(db, cagState)
      collectionProgressSummary = getCollectionProgressSummary(cagState)
    } catch (progressError: any) {
    }

    // ============================================
    // Memory ì—…ë°ì´íŠ¸ (Round ë‹µë³€ ì €ì¥ í›„)
    // ============================================
    let memoryUpdated = false
    try {
      // 1. Draftì—ì„œ í˜„ì¬ AggregatedProfile ì¡°íšŒ
      const draft = await db
        .prepare('SELECT * FROM analyzer_drafts WHERE session_id = ?')
        .bind(session_id)
        .first<any>()
      
      if (draft) {
        // 2. ê¸°ì¡´ profile ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
        let aggregatedProfile: AggregatedProfile
        if (draft.aggregated_profile_json) {
          aggregatedProfile = JSON.parse(draft.aggregated_profile_json)
        } else {
          aggregatedProfile = createEmptyProfile(draft.profile_version || 0)
        }
        
        // 3. Round ë‹µë³€ì„ RoundAnswer í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        const roundAnswers = answers.map(ans => ({
          questionId: ans.question_id,
          roundNumber: round_number,
          answer: ans.answer,
          answeredAt: new Date().toISOString(),
        }))
        
        // 4. Memory ì—…ë°ì´íŠ¸ í˜¸ì¶œ
        const updatedMemory = await updateMemory(
          env.AI || null,
          aggregatedProfile,
          { type: 'round_answers', data: roundAnswers, roundNumber: round_number },
          (env as any).OPENAI_API_KEY
        )
        
        // 5. Draftì— memory_json ì €ì¥
        aggregatedProfile.memory = updatedMemory
        await db
          .prepare(`
            UPDATE analyzer_drafts SET
              memory_json = ?,
              aggregated_profile_json = ?
            WHERE session_id = ?
          `)
          .bind(
            JSON.stringify(updatedMemory),
            JSON.stringify(aggregatedProfile),
            session_id
          )
          .run()
        
        memoryUpdated = true
      }
    } catch (memoryError: any) {
      // Memory ì—…ë°ì´íŠ¸ ì‹¤íŒ¨í•´ë„ ë‹µë³€ ì €ì¥ì€ ì„±ê³µ
    }
    
    return c.json({
      success: true,
      saved_count: successCount,
      round_number,
      memory_updated: memoryUpdated,
      collection_progress: collectionProgressSummary,
    })
    
  } catch (error: any) {
    // P0-1: ìƒì„¸ ì—ëŸ¬ ë¡œê¹…
    const errorDetail = {
      message: error.message || 'Unknown error',
      cause: error.cause?.message || error.cause || null,
      code: error.code || null,
      stack: error.stack?.substring(0, 500) || null,
    }
    
    return c.json({
      success: false,
      error: error.message || 'Database save failed',
      detail: errorDetail.cause || 'round_answers INSERT failed',
      code: errorDetail.code,
    }, 500)
  }
})

// ============================================
// V3: ì„œìˆ í˜• ë‹µë³€ ì €ì¥ API
// POST /api/ai-analyzer/v3/narrative-facts
// ============================================
analyzerRoutes.post('/v3/narrative-facts', async (c) => {
  const env = c.env as Bindings
  const db = env.DB
  
  try {
    const body = await c.req.json<{
      session_id: string
      user_id?: string
      high_alive_moment: string
      lost_moment: string
      existential_answer?: string
    }>()

    const { session_id, user_id, high_alive_moment, lost_moment, existential_answer } = body

    // P0-1: session_id ê²€ì¦ ê°•í™”
    if (!session_id || session_id.trim() === '') {
      return c.json({
        success: false,
        error: 'session_id is required and cannot be empty',
        detail: 'session_id_validation_failed'
      }, 400)
    }

    // P0-1: ì…ë ¥ê°’ ë¡œê¹…

    // UPSERT (ê¸°ì¡´ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸)
    const result = await db.prepare(`
      INSERT INTO narrative_facts (session_id, user_id, high_alive_moment, lost_moment, existential_answer)
      VALUES (?, ?, ?, ?, ?)
      ON CONFLICT(session_id) DO UPDATE SET
        high_alive_moment = excluded.high_alive_moment,
        lost_moment = excluded.lost_moment,
        existential_answer = excluded.existential_answer,
        created_at = datetime('now')
    `).bind(session_id, user_id || null, high_alive_moment, lost_moment, existential_answer || null).run()

    // ì‹¤ì¡´ì  ì§ˆë¬¸ ë‹µë³€ì´ ìˆìœ¼ë©´ ë¹„ë™ê¸°ë¡œ LLM ë¶„ì„ ì‹¤í–‰
    if (existential_answer && existential_answer.trim().length > 10) {
      c.executionCtx.waitUntil(
        analyzeExistentialAnswer(db, session_id, user_id, existential_answer, (env as any).OPENAI_API_KEY)
          .catch(() => {})
      )
    }

    
    return c.json({
      success: true,
      session_id,
      meta: result.meta,
    })
    
  } catch (error: any) {
    // P0-1: ìƒì„¸ ì—ëŸ¬ ë¡œê¹…
    const errorDetail = {
      message: error.message || 'Unknown error',
      cause: error.cause?.message || error.cause || null,
      code: error.code || null,
      stack: error.stack?.substring(0, 500) || null,
    }
    
    return c.json({
      success: false,
      error: error.message || 'Database save failed',
      detail: errorDetail.cause || 'narrative_facts UPSERT failed',
      code: errorDetail.code,
    }, 500)
  }
})

// ============================================
// Vectorize í…ŒìŠ¤íŠ¸ API (2026-01-16)
// GET /api/ai-analyzer/vectorize-test?query=ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì
// ============================================
analyzerRoutes.get('/vectorize-test', async (c) => {
  const env = c.env as Bindings
  const query = c.req.query('query') || 'ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ í”„ë¡œê·¸ë˜ë°'
  const topK = parseInt(c.req.query('topK') || '10')
  
  // Vectorize ë°”ì¸ë”© í™•ì¸
  const openaiApiKey = (env as any).OPENAI_API_KEY
  
  if (!env.VECTORIZE) {
    return c.json({
      success: false,
      error: 'VECTORIZE_NOT_AVAILABLE',
      message: 'Vectorize ë°”ì¸ë”©ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤',
      hint: 'wrangler.jsoncì—ì„œ vectorize ë°”ì¸ë”©ì„ í™•ì¸í•˜ì„¸ìš”',
    }, 503)
  }
  
  if (!openaiApiKey) {
    return c.json({
      success: false,
      error: 'OPENAI_API_KEY_NOT_SET',
      message: 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤',
      hint: '.dev.vars ë˜ëŠ” Cloudflare Dashboardì—ì„œ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”',
    }, 503)
  }
  
  try {
    // ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (OpenAI - í•œêµ­ì–´ ì§ì ‘ ì²˜ë¦¬)
    const startTime = Date.now()
    const { embeddings } = await generateOpenAIEmbedding(openaiApiKey, query)
    const embeddingTime = Date.now() - startTime
    
    const queryEmbedding = embeddings[0]
    
    // ë²¡í„° ê²€ìƒ‰
    // Cloudflare Vectorize limits: returnMetadata='indexed' â†’ max topK=100
    const clampedTopK = Math.min(topK, 100)
    const searchStart = Date.now()
    const searchResult = await env.VECTORIZE.query(queryEmbedding, {
      topK: clampedTopK,
      returnValues: false,
      returnMetadata: 'indexed',
    })
    const searchTime = Date.now() - searchStart
    
    // ê²°ê³¼ ë³€í™˜
    const results = searchResult.matches.map(match => ({
      job_id: match.id,
      job_name: (match.metadata?.job_name as string) || match.id,
      score: match.score.toFixed(4),
      metadata: match.metadata,
    }))
    
    return c.json({
      success: true,
      query,
      topK,
      embedding_model: 'text-embedding-3-small',
      embedding_dimensions: OPENAI_EMBEDDING_DIMENSIONS,
      results_count: results.length,
      timing: {
        embedding_ms: embeddingTime,
        search_ms: searchTime,
        total_ms: embeddingTime + searchTime,
      },
      results,
    })
    
  } catch (error) {
    return c.json({
      success: false,
      error: 'VECTORIZE_ERROR',
      message: error instanceof Error ? error.message : 'Unknown error',
    }, 500)
  }
})

// ============================================
// ê´€ë¦¬ì: ì§ì—… ë°ì´í„° ì¬ì¸ë±ì‹± (OpenAI Embedding)
// ============================================
analyzerRoutes.post('/admin/reindex-jobs', async (c) => {
  const authError = checkAdminAuth(c)
  if (authError) return authError
  const env = c.env as Bindings
  const db = env.DB
  const openaiApiKey = (env as any).OPENAI_API_KEY
  
  if (!env.VECTORIZE) {
    return c.json({
      success: false,
      error: 'VECTORIZE_NOT_AVAILABLE',
      message: 'Vectorize ë°”ì¸ë”©ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤',
    }, 503)
  }
  
  if (!openaiApiKey) {
    return c.json({
      success: false,
      error: 'OPENAI_API_KEY_NOT_SET',
      message: 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤',
    }, 503)
  }
  
  try {
    const startTime = Date.now()
    
    const result = await indexJobsToVectorize(
      db,
      env.VECTORIZE,
      openaiApiKey,
      50  // ë°°ì¹˜ í¬ê¸° (OpenAI rate limit ê³ ë ¤)
    )
    
    const duration = Date.now() - startTime
    
    
    return c.json({
      success: true,
      indexed: result.indexed,
      errors: result.errors,
      duration_ms: duration,
      embedding_model: 'text-embedding-3-small',
      embedding_dimensions: 1536,
    })
    
  } catch (error) {
    return c.json({
      success: false,
      error: 'REINDEX_ERROR',
      message: error instanceof Error ? error.message : 'Unknown error',
    }, 500)
  }
})

// ============================================
// ê´€ë¦¬ì: ì „ê³µ ë°ì´í„° ì¬ì¸ë±ì‹±
// ============================================
analyzerRoutes.post('/admin/reindex-majors', async (c) => {
  const authError = checkAdminAuth(c)
  if (authError) return authError
  const env = c.env as Bindings
  const db = env.DB
  const openaiApiKey = (env as any).OPENAI_API_KEY

  if (!env.VECTORIZE) {
    return c.json({ success: false, error: 'VECTORIZE_NOT_AVAILABLE', message: 'Vectorize ë°”ì¸ë”©ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤' }, 503)
  }
  if (!openaiApiKey) {
    return c.json({ success: false, error: 'OPENAI_API_KEY_NOT_SET', message: 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤' }, 503)
  }

  try {
    const startTime = Date.now()
    const result = await indexMajorsToVectorize(db, env.VECTORIZE, openaiApiKey, 50)
    const duration = Date.now() - startTime
    return c.json({ success: true, target: 'majors', indexed: result.indexed, errors: result.errors, duration_ms: duration })
  } catch (error) {
    return c.json({ success: false, error: 'REINDEX_ERROR', message: error instanceof Error ? error.message : 'Unknown error' }, 500)
  }
})

// ============================================
// ê´€ë¦¬ì: HowTo/ê°€ì´ë“œ ë°ì´í„° ì¬ì¸ë±ì‹±
// ============================================
analyzerRoutes.post('/admin/reindex-howtos', async (c) => {
  const authError = checkAdminAuth(c)
  if (authError) return authError
  const env = c.env as Bindings
  const db = env.DB
  const openaiApiKey = (env as any).OPENAI_API_KEY

  if (!env.VECTORIZE) {
    return c.json({ success: false, error: 'VECTORIZE_NOT_AVAILABLE', message: 'Vectorize ë°”ì¸ë”©ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤' }, 503)
  }
  if (!openaiApiKey) {
    return c.json({ success: false, error: 'OPENAI_API_KEY_NOT_SET', message: 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤' }, 503)
  }

  try {
    const startTime = Date.now()
    const result = await indexHowtosToVectorize(db, env.VECTORIZE, openaiApiKey, 50)
    const duration = Date.now() - startTime
    return c.json({ success: true, target: 'howtos', indexed: result.indexed, errors: result.errors, duration_ms: duration })
  } catch (error) {
    return c.json({ success: false, error: 'REINDEX_ERROR', message: error instanceof Error ? error.message : 'Unknown error' }, 500)
  }
})

// ============================================
// ê´€ë¦¬ì: ì „ì²´ ì¬ì¸ë±ì‹± (ì§ì—… + ì „ê³µ + HowTo)
// ============================================
analyzerRoutes.post('/admin/reindex-all', async (c) => {
  const authError = checkAdminAuth(c)
  if (authError) return authError
  const env = c.env as Bindings
  const db = env.DB
  const openaiApiKey = (env as any).OPENAI_API_KEY

  if (!env.VECTORIZE) {
    return c.json({ success: false, error: 'VECTORIZE_NOT_AVAILABLE', message: 'Vectorize ë°”ì¸ë”©ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤' }, 503)
  }
  if (!openaiApiKey) {
    return c.json({ success: false, error: 'OPENAI_API_KEY_NOT_SET', message: 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤' }, 503)
  }

  try {
    const startTime = Date.now()
    const [jobResult, majorResult, howtoResult] = await Promise.all([
      indexJobsToVectorize(db, env.VECTORIZE, openaiApiKey, 50),
      indexMajorsToVectorize(db, env.VECTORIZE, openaiApiKey, 50),
      indexHowtosToVectorize(db, env.VECTORIZE, openaiApiKey, 50),
    ])
    const duration = Date.now() - startTime
    return c.json({
      success: true,
      target: 'all',
      jobs: { indexed: jobResult.indexed, errors: jobResult.errors },
      majors: { indexed: majorResult.indexed, errors: majorResult.errors },
      howtos: { indexed: howtoResult.indexed, errors: howtoResult.errors },
      duration_ms: duration,
    })
  } catch (error) {
    return c.json({ success: false, error: 'REINDEX_ERROR', message: error instanceof Error ? error.message : 'Unknown error' }, 500)
  }
})

// ============================================
// Freeze v1.1: Recommendation Mode API
// ============================================
// ì œì¶œ ì‹œì ì—ë§Œ ìµœì¢… ì¶”ì²œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
// Interview Modeì™€ ë¶„ë¦¬í•˜ì—¬ ì„¤ë¬¸ ì¤‘ í¸í–¥ ë°©ì§€
// ============================================
import { generateQSP, qspToPromptHints } from './qsp-generator'
import { createEmptyAxisCoverage, updateAxisCoverage } from './axis-framework'
import { incrementalUpsertToVectorize, incrementalUpsertMajorsToVectorize, incrementalUpsertHowtosToVectorize, countJobsNeedingIndexing } from './vectorize-pipeline'

// Fallback ì‹¬ë¦¬ë¶„ì„ ìƒì„± (LLM ì‹¤íŒ¨ ì‹œ)
function generateFallbackWorkStyle(miniModule: {
  interest_top?: string[]
  value_top?: string[]
  strength_top?: string[]
  energy_drain_flags?: string[]
}): string {
  const parts: string[] = []

  const INTEREST_MAP: Record<string, string> = {
    problem_solving: 'ë¬¸ì œ í•´ê²°',
    data_numbers: 'ë°ì´í„°ì™€ ìˆ«ì',
    tech: 'ê¸°ìˆ /IT',
    creative: 'ì°½ì‘/ì˜ˆìˆ ',
    people: 'ì‚¬ëŒê³¼ ì†Œí†µ',
    helping: 'íƒ€ì¸ ë•ê¸°',
    business: 'ë¹„ì¦ˆë‹ˆìŠ¤',
    creating: 'ì°½ì‘ í™œë™',
    influencing: 'ì˜í–¥ë ¥ ë°œíœ˜',
  }

  const VALUE_MAP: Record<string, string> = {
    growth: 'ì„±ì¥',
    autonomy: 'ììœ¨ì„±',
    stability: 'ì•ˆì •ì„±',
    income: 'ë†’ì€ ìˆ˜ì…',
    meaning: 'ì˜ë¯¸ì™€ ì‚¬íšŒ ê¸°ì—¬',
    recognition: 'ì¸ì •ê³¼ ì˜í–¥ë ¥',
    wlb: 'ì¼ê³¼ ì‚¶ì˜ ê· í˜•',
  }

  const STRENGTH_MAP: Record<string, string> = {
    analytical: 'ë¶„ì„ë ¥',
    fast_learning: 'ë¹ ë¥¸ í•™ìŠµ ëŠ¥ë ¥',
    creativity: 'ì°½ì˜ì„±',
    communication: 'ì†Œí†µ ëŠ¥ë ¥',
    leadership: 'ë¦¬ë”ì‹­',
    empathy: 'ê³µê° ëŠ¥ë ¥',
  }

  if (miniModule.interest_top?.length) {
    const interests = miniModule.interest_top
      .map(i => INTEREST_MAP[i] || i)
      .slice(0, 2)
      .join('ê³¼ ')
    parts.push(`${interests}ì— ê´€ì‹¬ì´ ë§ìŠµë‹ˆë‹¤`)
  }

  if (miniModule.value_top?.length) {
    const values = miniModule.value_top
      .map(v => VALUE_MAP[v] || v)
      .slice(0, 2)
      .join('ê³¼ ')
    parts.push(`${values}${ì„ë¥¼(values)} ì¤‘ìš”í•˜ê²Œ ì—¬ê¹ë‹ˆë‹¤`)
  }

  if (miniModule.strength_top?.length) {
    const strengths = miniModule.strength_top
      .map(s => STRENGTH_MAP[s] || s)
      .slice(0, 2)
      .join(', ')
    parts.push(`${strengths}${ì´ê°€(strengths)} ê°•ì ì…ë‹ˆë‹¤`)
  }

  if (parts.length === 0) {
    return 'ë‹¹ì‹ ì˜ ì»¤ë¦¬ì–´ ì„±í–¥ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤.'
  }

  return `ë‹¹ì‹ ì€ ${parts.join('. ')}. ì´ëŸ¬í•œ íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ì í•©í•œ ì§ì—…ì„ ì¶”ì²œí•´ ë“œë¦½ë‹ˆë‹¤.`
}

interface RecommendationModePayload {
  session_id: string
  // ìµœì¢… SearchProfile (Interview Modeì—ì„œ ìˆ˜ì§‘ëœ ëª¨ë“  ë°ì´í„°)
  searchProfile?: {
    desiredThemes: string[]
    dislikedThemes: string[]
    strengthsHypothesis: string[]
    environmentPreferences: string[]
    hardConstraints: string[]
    riskSignals: string[]
    keywords: string[]
  }
  // ë¯¸ë‹ˆëª¨ë“ˆ ê²°ê³¼ (MiniModule Hard Filterìš©)
  mini_module_result?: {
    interest_top: string[]
    value_top: string[]
    strength_top: string[]
    constraint_flags: string[]
    sacrifice_flags?: string[]
    energy_drain_flags?: string[]
    achievement_feedback_top?: string[]
    execution_style?: string
    impact_scope?: string
    failure_response?: string
    persistence_anchor?: string
    external_expectation?: string
    // v3.13: ë°°ê²½ ë°ì´í„° (Feasibility í‰ê°€ìš©)
    background_flags?: string[]
    language_skills?: Array<{ language: string; level: 'basic' | 'business' | 'native' }>
  }
  // ì˜µì…˜: payloadì—ì„œ ì§ì ‘ ì „ë‹¬í•˜ëŠ” career_state (DBì— ì—†ì„ ë•Œ fallback)
  career_state?: {
    role_identity: string
    career_stage_years: string
  }
  // ì˜µì…˜: ê¸°ì¡´ draft_idë¡œ ìë™ í”„ë¡œí•„ ë¹Œë“œ
  draft_id?: number
  // ì˜µì…˜
  topK?: number  // ê¸°ë³¸: 800
  judgeTopN?: number  // ê¸°ë³¸: 20
  debug?: boolean
}

analyzerRoutes.post('/v3/recommend', async (c) => {
  const env = c.env as Bindings
  const db = env.DB
  const openaiApiKey = c.env.OPENAI_API_KEY
  const payload = await c.req.json<RecommendationModePayload>()

  // ì¸ì¦ëœ ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ìˆìœ¼ë©´)
  const authUser = c.get('user') as { id: number } | undefined
  const userId = authUser?.id || null

  const { session_id, draft_id, topK = 800, judgeTopN = 20, debug = false, skipReport = false } = payload
  
  if (!session_id) {
    return c.json(createErrorResponse(
      'VALIDATION_ERROR',
      'session_id is required'
    ), 400)
  }
  
  if (!openaiApiKey) {
    return c.json(createErrorResponse(
      'INTERNAL_ERROR',
      'OpenAI API key not configured'
    ), 500)
  }
  
  try {
    const startTime = Date.now()
    
    // 1. SearchProfile í™•ì •
    let searchProfile = payload.searchProfile
    
    if (!searchProfile && draft_id) {
      // Draftì—ì„œ í”„ë¡œí•„ ë¹Œë“œ
      const draft = await db.prepare(`
        SELECT * FROM ai_analysis_drafts WHERE id = ?
      `).bind(draft_id).first<AggDraftData>()
      
      if (draft) {
        const aggregated = buildAggregatedProfile(draft)
        // AggregatedProfile â†’ SearchProfile ë³€í™˜
        searchProfile = {
          desiredThemes: [
            ...aggregated.anchors.interest_top,
            ...aggregated.anchors.value_top,
          ],
          dislikedThemes: aggregated.universals.dislikes || [],
          strengthsHypothesis: aggregated.anchors.strength_top,
          environmentPreferences: [],
          hardConstraints: aggregated.anchors.constraint_flags,
          riskSignals: [],
          keywords: [
            ...aggregated.anchors.interest_top,
            ...aggregated.anchors.strength_top,
            ...Object.values(aggregated.universals.interests || []),
          ],
        }
      }
    }
    
    // Fallback: mini_module_resultì—ì„œ SearchProfile ìë™ ë¹Œë“œ
    if (!searchProfile && payload.mini_module_result) {
      searchProfile = buildSearchProfileFromMiniModule(payload.mini_module_result)
    }

    // Fallback 2: ì„¸ì…˜ DBì—ì„œ ë¯¸ë‹ˆëª¨ë“ˆ ë°ì´í„° ë³µì›
    if (!searchProfile) {
      try {
        const analysisResult = await db.prepare(`
          SELECT result_json FROM ai_analysis_results
          WHERE request_id IN (
            SELECT id FROM ai_analysis_requests WHERE session_id = ? ORDER BY id DESC LIMIT 1
          )
        `).bind(session_id).first<{ result_json: string }>()

        if (analysisResult?.result_json) {
          const parsed = JSON.parse(analysisResult.result_json)
          // ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ì˜ input_summaryì—ì„œ í”„ë¡œí•„ ë³µì›
          const mm = parsed.mini_module_result || (parsed as any).miniModuleResult
          if (mm) {
            searchProfile = buildSearchProfileFromMiniModule(mm)
            if (!payload.mini_module_result) {
              ;(payload as any).mini_module_result = mm
            }
          }
        }
      } catch (err) {
      }
    }

    if (!searchProfile) {
      return c.json(createErrorResponse(
        'VALIDATION_ERROR',
        'searchProfile or draft_id or mini_module_result required'
      ), 400)
    }
    
    // 2. Vectorize 1íšŒ (TopK=800)

    // â˜… ì¤‘ìš”: mini_module_resultê°€ ìˆìœ¼ë©´ ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ SearchProfile ìƒì„±
    // ì´ë ‡ê²Œ í•´ì•¼ "ë¶„ì„í˜• ìœ ì €"ì—ê²Œ ë¶„ì„ ê´€ë ¨ ì§ì—…ì´ ê²€ìƒ‰ë¨
    let vectorSearchProfile = searchProfile
    if (payload.mini_module_result) {
      vectorSearchProfile = buildSearchProfileFromMiniModule(payload.mini_module_result)
    }

    const expansionResult = await expandCandidatesV3(
      db,
      env.VECTORIZE,
      openaiApiKey,
      vectorSearchProfile,
      {
        targetSize: topK,
        miniModule: payload.mini_module_result,
      }
    )

    
    // 3. TAG Hard Filter
    const userConstraints = extractUserConstraints(
      searchProfile.hardConstraints.reduce((acc, c) => {
        if (c.includes('time') || c.includes('ì‹œê°„')) acc.work_hours_strict = true
        if (c.includes('remote') || c.includes('ì›ê²©')) acc.remote_only = true
        if (c.includes('shift') || c.includes('êµëŒ€')) acc.shift_work_no = true
        if (c.includes('degree') || c.includes('í•™ìœ„')) acc.degree_impossible = true
        if (c.includes('license') || c.includes('ìê²©')) acc.license_impossible = true
        return acc
      }, {} as { [key: string]: boolean }),
      {}
    )
    
    // 3-1. TAG Filter ë¨¼ì € ì ìš© (VectorSearchResult íƒ€ì…)

    let tagFilterResult
    try {
      tagFilterResult = await applyTagFilter(db, expansionResult.candidates, userConstraints)
    } catch (tagError) {
      throw tagError
    }

    // 3-2. í•„í„°ë§ëœ ê²°ê³¼ë¥¼ ScoredJobìœ¼ë¡œ ë³€í™˜
    const tagPassedAsVectorResults = tagFilterResult.passed.map(p => ({
      job_id: p.job_id,
      job_name: p.job_name,
      score: p.score,  // VectorSearchResultì˜ score
    }))

    let scoredJobs
    try {
      scoredJobs = await vectorResultsToScoredJobs(db, tagPassedAsVectorResults, payload.mini_module_result)
      // v3.9.4: ì •ì¹˜ì§/ì„ëª…ì§ í•„í„°ë§ (ì°¨ê´€, ë²•ì›ì¥ ë“± ì¶”ì²œ ë¶€ì í•© ì§ì—… ì œê±°)
      scoredJobs = filterUnrealisticJobs(scoredJobs)
      // v3.9.9: ë‹ˆì¹˜ ì†Œì¬/ë¶„ì•¼ ì§ì—… ì¡°ê±´ë¶€ í•„í„°ë§ (ë°°ê²½ì´ ë°›ì³ì¤„ ë•ŒëŠ” í†µê³¼)
      scoredJobs = filterNicheMaterialJobs(scoredJobs, payload.mini_module_result)
      // ğŸ” DEBUG: ì²« ë²ˆì§¸ ì§ì—…ì˜ image_url, job_description í™•ì¸
      if (scoredJobs.length > 0) {
        const sample = scoredJobs[0]
      }
    } catch (scoreError) {
      throw scoreError
    }

    // 3-3. MiniModule Hard Filter (ë¶„ì„í˜• ê°•ì  â†’ í˜„ì¥ì§ ì œì™¸ ë“±)

    let filteredJobs, mmFilterResult
    try {
      const mmResult = applyMiniModuleHardFilter(scoredJobs, payload.mini_module_result)
      filteredJobs = mmResult.filtered
      mmFilterResult = mmResult.filterResult
    } catch (mmError) {
      throw mmError
    }

    if (mmFilterResult.appliedRules.length > 0) {
    }
    
    // 4. LLM Judge í˜¸ì¶œ (Top 20 ê²°ì • + rationale ìƒì„±)
    let topJobs: any[]

    // v3.10: ë²¡í„° ê²€ìƒ‰ ë¯¸ìŠ¤ ì‹œ DBì—ì„œ ì•„í‚¤íƒ€ì… ì§ì—… ì§ì ‘ ì£¼ì…
    // ë²¡í„° ê²€ìƒ‰ì´ ìœ ì €ì˜ í•µì‹¬ í¥ë¯¸ì— í•´ë‹¹í•˜ëŠ” ì§ì—…ì„ ëª» ì°¾ì€ ê²½ìš°, DBì—ì„œ ì§ì ‘ ì¡°íšŒí•˜ì—¬ filteredJobsì— ì£¼ì…
    const ARCHETYPE_DB_QUERIES: Record<string, { patterns: string[], likePatterns: string[] }> = {
      helping_teaching: {
        patterns: ['êµì‚¬', 'ë³µì§€ì‚¬', 'ê°„í˜¸', 'ìƒë‹´', 'ë³´ìœ¡'],
        likePatterns: ['%êµì‚¬%', '%ë³µì§€ì‚¬%', '%ê°„í˜¸%', '%ìƒë‹´ì‚¬%', '%ë³´ìœ¡%'],
      },
      helping: {  // ëŒë´„/ë´‰ì‚¬ â€” helping_teachingê³¼ ë™ì¼ + ì§€ë„ì›/ëŒë´„ ì¶”ê°€
        patterns: ['êµì‚¬', 'ë³µì§€ì‚¬', 'ê°„í˜¸', 'ìƒë‹´', 'ë³´ìœ¡', 'ì§€ë„ì›', 'ëŒë´„'],
        likePatterns: ['%êµì‚¬%', '%ë³µì§€ì‚¬%', '%ê°„í˜¸%', '%ìƒë‹´ì‚¬%', '%ë³´ìœ¡%', '%ì§€ë„ì›%', '%ëŒë´„%'],
      },
      helping_feedback: {  // ì§ì ‘ ë„ì›€ â€” ì‚¬íšŒì„œë¹„ìŠ¤ ê³„ì—´
        patterns: ['ë³µì§€ì‚¬', 'ìƒë‹´', 'ì§€ë„ì›', 'ê°„í˜¸', 'ëŒë´„'],
        likePatterns: ['%ë³µì§€ì‚¬%', '%ìƒë‹´%', '%ì§€ë„ì›%', '%ê°„í˜¸%', '%ëŒë´„%'],
      },
      organizing: {
        patterns: ['í–‰ì •', 'ì‚¬ë¬´', 'ê´€ë¦¬ì', 'ê³µë¬´ì›'],
        likePatterns: ['%í–‰ì •%', '%ì‚¬ë¬´%', '%ê´€ë¦¬ì%', '%ê³µë¬´ì›%'],
      },
      tech: {
        patterns: ['ê°œë°œì', 'ì—”ì§€ë‹ˆì–´', 'í”„ë¡œê·¸ë˜ë¨¸', 'SW', 'ì†Œí”„íŠ¸ì›¨ì–´'],
        likePatterns: ['%ê°œë°œì%', '%ì—”ì§€ë‹ˆì–´%', '%í”„ë¡œê·¸ë˜ë¨¸%', '%SW%', '%ì†Œí”„íŠ¸ì›¨ì–´%'],
      },
      creating: {
        patterns: ['ë””ìì´ë„ˆ', 'ê¸°íšì', 'ì‘ê°€', 'ì˜ˆìˆ '],
        likePatterns: ['%ë””ìì´ë„ˆ%', '%ê¸°íšì%', '%ì‘ê°€%', '%ì˜ˆìˆ %'],
      },
      data_numbers: {
        patterns: ['ë¶„ì„', 'í†µê³„', 'íšŒê³„', 'ë°ì´í„°'],
        likePatterns: ['%ë¶„ì„%', '%í†µê³„%', '%íšŒê³„%', '%ë°ì´í„°%'],
      },
      problem_solving: {
        patterns: ['ì»¨ì„¤í„´íŠ¸', 'ì—°êµ¬ì›', 'ë¶„ì„ê°€'],
        likePatterns: ['%ì»¨ì„¤í„´íŠ¸%', '%ì—°êµ¬ì›%', '%ë¶„ì„ê°€%'],
      },
      influencing: {
        patterns: ['ë§ˆì¼€í„°', 'í™ë³´', 'ì˜ì—…'],
        likePatterns: ['%ë§ˆì¼€í„°%', '%í™ë³´%', '%ì˜ì—…%'],
      },
      // í™•ì¥ í† í° (ì‹œë‚˜ë¦¬ì˜¤/í™•ì¥ ì…ë ¥ìš©)
      creative: {  // 'creating' alias
        patterns: ['ë””ìì´ë„ˆ', 'ê¸°íšì', 'ì‘ê°€', 'ì˜ˆìˆ ', 'í¬ë¦¬ì—ì´í„°'],
        likePatterns: ['%ë””ìì´ë„ˆ%', '%ê¸°íšì%', '%ì‘ê°€%', '%ì˜ˆìˆ %', '%í¬ë¦¬ì—ì´í„°%'],
      },
      design: {
        patterns: ['ë””ìì´ë„ˆ', 'ê·¸ë˜í”½', 'UI', 'UX', 'ì‹œê°'],
        likePatterns: ['%ë””ìì´ë„ˆ%', '%ê·¸ë˜í”½%', '%UI%', '%UX%', '%ì‹œê°%'],
      },
      art: {
        patterns: ['ì˜ˆìˆ ', 'ì‘ê°€', 'ì¼ëŸ¬ìŠ¤íŠ¸', 'ë¯¸ìˆ ', 'ê³µì˜ˆ'],
        likePatterns: ['%ì˜ˆìˆ %', '%ì‘ê°€%', '%ì¼ëŸ¬ìŠ¤íŠ¸%', '%ë¯¸ìˆ %', '%ê³µì˜ˆ%'],
      },
      research: {
        patterns: ['ì—°êµ¬ì›', 'ë¶„ì„ê°€', 'ë¦¬ì„œì²˜', 'ì—°êµ¬', 'ì¡°ì‚¬'],
        likePatterns: ['%ì—°êµ¬ì›%', '%ë¶„ì„ê°€%', '%ë¦¬ì„œì²˜%', '%ì—°êµ¬%', '%ì¡°ì‚¬%'],
      },
      routine: {
        patterns: ['í–‰ì •', 'ì‚¬ë¬´', 'ê³µë¬´ì›', 'ê²½ë¦¬', 'ì´ë¬´'],
        likePatterns: ['%í–‰ì •%', '%ì‚¬ë¬´%', '%ê³µë¬´ì›%', '%ê²½ë¦¬%', '%ì´ë¬´%'],
      },
    }

    const existingJobIds = new Set(filteredJobs.map(j => String(j.job_id)))
    const injectedJobNames = new Set<string>()  // ë™ì¼ ì§ì—…ëª… ì¤‘ë³µ ì£¼ì… ë°©ì§€
    const mmInterests = (payload.mini_module_result?.interest_top || []) as string[]

    // v3.10.6: Archetype DB ì¿¼ë¦¬ ë³‘ë ¬í™” (2ê°œ interestë¥¼ ë™ì‹œì— ì¡°íšŒ)
    const archetypeQueries: Array<{ interest: string; config: typeof ARCHETYPE_DB_QUERIES[string]; existingCount: number }> = []
    for (const interest of mmInterests.slice(0, 2)) {
      const config = ARCHETYPE_DB_QUERIES[interest]
      if (!config) continue
      const existingCount = filteredJobs.filter(j => config.patterns.some(p => j.job_name.includes(p))).length
      if (existingCount >= 8) {
        continue
      }
      archetypeQueries.push({ interest, config, existingCount })
    }

    // DB ì¿¼ë¦¬ë§Œ ë³‘ë ¬ ì‹¤í–‰, ê²°ê³¼ ì²˜ë¦¬ëŠ” ìˆœì°¨ (ì¤‘ë³µ ì œê±° ë¡œì§ ìœ ì§€)
    const archetypeDbResults = await Promise.all(
      archetypeQueries.map(async ({ interest, config }) => {
        const likeConditions = config.likePatterns.map(() => 'ja.job_name LIKE ?').join(' OR ')
        try {
          const dbResult = await db.prepare(`
            SELECT
              ja.job_id, ja.job_name,
              j.slug, j.image_url, j.api_data_json, j.merged_profile_json,
              ja.wlb, ja.growth, ja.stability, ja.income,
              ja.teamwork, ja.solo_deep, ja.analytical, ja.creative, ja.execution, ja.people_facing,
              ja.work_hours, ja.shift_work, ja.travel, ja.remote_possible,
              ja.degree_required, ja.license_required
            FROM job_attributes ja
            JOIN jobs j ON ja.job_id = j.id
            WHERE (${likeConditions}) AND j.slug IS NOT NULL
            GROUP BY ja.job_name
            ORDER BY ja.people_facing DESC, ja.stability DESC
            LIMIT 30
          `).bind(...config.likePatterns).all()
          return { interest, results: dbResult.results || [], error: null }
        } catch (dbErr) {
          return { interest, results: [], error: dbErr }
        }
      })
    )

    // ê²°ê³¼ ì²˜ë¦¬ (ìˆœì°¨ - ì¤‘ë³µ ì œê±° ìƒíƒœ ê³µìœ )
    for (let qi = 0; qi < archetypeQueries.length; qi++) {
      const { interest, existingCount } = archetypeQueries[qi]
      const { results } = archetypeDbResults[qi]
      if (results.length === 0) {
        continue
      }

      const injected: string[] = []
      const needed = 10 - existingCount

      for (const row of results as any[]) {
        if (existingJobIds.has(String(row.job_id))) continue
        if (injectedJobNames.has(row.job_name)) continue
        if (injected.length >= needed) break

        const personalized = calculatePersonalizedBaseScores(row, payload.mini_module_result)
        const baseLike = Math.min(100, personalized.like)
        const baseCan = Math.min(100, personalized.can)
        const baseRisk = 10
        const archetypeBoost = 12
        const boostedLike = Math.min(100, baseLike + archetypeBoost)
        const boostedCan = Math.min(100, baseCan + Math.round(archetypeBoost * 0.5))

        let kscoMajor = ''
        if (row.merged_profile_json) {
          try {
            const profile = JSON.parse(row.merged_profile_json)
            kscoMajor = profile.ksco_major || profile.kscoMajor || ''
          } catch {}
        }

        const scoredJob = {
          job_id: row.job_id,
          job_name: row.job_name,
          slug: row.slug || undefined,
          image_url: row.image_url || undefined,
          job_description: extractJobDescription(row.api_data_json, row.merged_profile_json, row.job_name),
          base_like: baseLike,
          base_can: baseCan,
          base_risk: baseRisk,
          like_score: boostedLike,
          can_score: boostedCan,
          risk_penalty: baseRisk,
          final_score: Math.round(0.55 * boostedLike + 0.45 * boostedCan - baseRisk),
          ksco_major: kscoMajor,
          tag_source: 'archetype_inject' as const,
          attributes: {
            wlb: row.wlb,
            growth: row.growth,
            stability: row.stability,
            income: row.income,
            remote: row.remote_possible === 'full' ? 100 : row.remote_possible === 'partial' ? 50 : 0,
            solo_work: row.solo_deep,
            solo_deep: row.solo_deep,
            people_facing: row.people_facing,
            analytical: row.analytical,
            creative: row.creative,
            execution: row.execution,
            teamwork: row.teamwork,
            work_hours: row.work_hours,
            shift_work: row.shift_work,
            degree_required: row.degree_required,
            license_required: row.license_required,
            ksco_major: kscoMajor,
          },
        }

        filteredJobs.push(scoredJob as any)
        existingJobIds.add(String(row.job_id))
        injectedJobNames.add(row.job_name)
        injected.push(`${row.job_name}(like:${boostedLike},can:${boostedCan},fit:${scoredJob.final_score})`)
      }
    }

    // v3.9.5: ì‚¬ì „ í•„í„°ëœ ìƒìœ„ í›„ë³´êµ° (Like/Can/Final 3ì¶• ë¶„ë¦¬ë¡œ ë‹¤ì–‘í•œ í›„ë³´ í™•ë³´)
    // Like í¸í–¥ í›„ë³´: like_score ìƒìœ„ 20ê°œ
    const likeBiasedJobs = [...filteredJobs]
      .sort((a, b) => (b.like_score || 0) - (a.like_score || 0))
      .slice(0, 20)
    // Can í¸í–¥ í›„ë³´: can_score ìƒìœ„ 20ê°œ
    const canBiasedJobs = [...filteredJobs]
      .sort((a, b) => (b.can_score || 0) - (a.can_score || 0))
      .slice(0, 20)
    // Final í¸í–¥ í›„ë³´: final_score ìƒìœ„ 20ê°œ (ê°œì¸í™” ì ìˆ˜ ê¸°ë°˜ ì¢…í•© ìµœì )
    const finalBiasedJobs = [...filteredJobs]
      .sort((a, b) => (b.final_score || 0) - (a.final_score || 0))
      .slice(0, 20)
    // í•©ì§‘í•© (ì¤‘ë³µ ì œê±°) â†’ ~40-50ê°œ unique í›„ë³´
    const preFilterJobIdSet = new Set<string>()
    const preFilteredJobs: typeof filteredJobs = []
    for (const job of [...likeBiasedJobs, ...canBiasedJobs, ...finalBiasedJobs]) {
      if (!preFilterJobIdSet.has(job.job_id)) {
        preFilterJobIdSet.add(job.job_id)
        preFilteredJobs.push(job)
      }
    }

    // v3.10: ì•„í‚¤íƒ€ì… ë³´ì¥ â€” DBì—ì„œ ì£¼ì…í•œ ì§ì—…ì´ pre-filterì—ì„œ ë°€ë ¤ë‚¬ìœ¼ë©´ ê°•ì œ ì¶”ê°€
    // ìµœì†Œ 5ê°œ ì•„í‚¤íƒ€ì… ì§ì—…ì´ LLM Judgeì— ë„ë‹¬í•˜ë„ë¡ ë³´ì¥
    for (const interest of mmInterests.slice(0, 2)) {
      const config = ARCHETYPE_DB_QUERIES[interest]
      if (!config) continue
      const inPreFilter = preFilteredJobs.filter(j => config.patterns.some(p => j.job_name.includes(p)))
      const guaranteeMin = 5  // ìµœì†Œ 5ê°œ ë³´ì¥ (ê¸°ì¡´ 3ê°œ â†’ 5ê°œë¡œ ìƒí–¥)
      if (inPreFilter.length >= guaranteeMin) {
        continue
      }
      // filteredJobsì—ì„œ í•´ë‹¹ ì•„í‚¤íƒ€ì… ì§ì—… ì¤‘ pre-filterì— ì—†ëŠ” ê²ƒ ê°•ì œ ì¶”ê°€
      const missing = filteredJobs
        .filter(j => config.patterns.some(p => j.job_name.includes(p)) && !preFilterJobIdSet.has(j.job_id))
        .sort((a, b) => (b.final_score || 0) - (a.final_score || 0))
        .slice(0, guaranteeMin - inPreFilter.length)
      for (const job of missing) {
        preFilterJobIdSet.add(job.job_id)
        preFilteredJobs.push(job)
      }
      if (missing.length > 0) {
      }
    }

    // ScoredJobì„ FilteredCandidate í˜•íƒœë¡œ ë³€í™˜ (attributes í¬í•¨!)
    const candidatesForJudge: FilteredCandidate[] = preFilteredJobs.map(job => ({
      job_id: job.job_id,
      job_name: job.job_name,
      score: job.final_score || job.like_score || 0,
      riskPenalty: job.risk_penalty || 0,
      riskWarnings: [],
      tagSource: 'tagged' as const,
      attributes: job.attributes,  // â˜… job_attributes ìˆ˜ì¹˜ ì „ë‹¬ (LLM Judge ê·¼ê±° í’ˆì§ˆ í–¥ìƒ)
    } as FilteredCandidate & { attributes?: Record<string, number | string> }))

    // ê°„ë‹¨í•œ rationale ìƒì„± í•¨ìˆ˜ (LLM Judge ì—†ì„ ë•Œ ì‚¬ìš©)
    const generateSimpleRationale = (job: any, mm: any) => {
      const parts: string[] = []
      const interestMap: Record<string, string> = {
        problem_solving: 'ë¬¸ì œí•´ê²°', data_numbers: 'ë°ì´í„°/ìˆ«ì', tech: 'ê¸°ìˆ /IT',
        creative: 'ì°½ì‘/ì˜ˆìˆ ', helping: 'ë„ì›€/ê°€ë¥´ì¹¨', organizing: 'ì¡°ì§/ê´€ë¦¬'
      }
      const strengthMap: Record<string, string> = {
        analytical: 'ë¶„ì„ë ¥', fast_learning: 'ë¹ ë¥¸ í•™ìŠµ', communication: 'ì†Œí†µ',
        persistence: 'ëˆê¸°', creativity: 'ì°½ì˜ì„±', leadership: 'ë¦¬ë”ì‹­'
      }

      if (mm?.interest_top?.length > 0) {
        const interests = mm.interest_top.slice(0, 2).map((i: string) => interestMap[i] || i).join(', ')
        parts.push(`${interests} ë¶„ì•¼ì— ëŒ€í•œ ê´€ì‹¬`)
      }
      if (mm?.strength_top?.length > 0) {
        const strengths = mm.strength_top.slice(0, 2).map((s: string) => strengthMap[s] || s).join(', ')
        parts.push(`${strengths} ê°•ì  í™œìš©`)
      }

      if (parts.length > 0) {
        return `ë‹¹ì‹ ì˜ ${parts.join('ê³¼ ')}ì— ì í•©í•œ ì§ì—…ì…ë‹ˆë‹¤.`
      }
      return null
    }

    // v3.13: ë°°ê²½ ë°ì´í„° ë¡œë“œ (LLM Judge Feasibility í‰ê°€ì— ì‚¬ìš©)
    let careerState: { role_identity: string; career_stage_years: string } | undefined
    let careerBackground: string | undefined
    try {
      const [roleRow, stageRow, draftRow] = await Promise.all([
        db.prepare(`SELECT value_json FROM facts WHERE session_id = ? AND fact_key = 'state.role_identity'`)
          .bind(session_id).first<{ value_json: string }>(),
        db.prepare(`SELECT value_json FROM facts WHERE session_id = ? AND fact_key = 'state.career_stage_years'`)
          .bind(session_id).first<{ value_json: string }>(),
        db.prepare(`SELECT aggregated_profile_json FROM analyzer_drafts WHERE session_id = ?`)
          .bind(session_id).first<{ aggregated_profile_json?: string }>(),
      ])
      careerState = {
        role_identity: roleRow ? JSON.parse(roleRow.value_json).value : '',
        career_stage_years: stageRow ? JSON.parse(stageRow.value_json).value : '',
      }
      // payload fallback: DBì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ (í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ë“±) payloadì˜ career_state ì‚¬ìš©
      if (!careerState.role_identity && payload.career_state?.role_identity) {
        careerState.role_identity = payload.career_state.role_identity
      }
      if (!careerState.career_stage_years && payload.career_state?.career_stage_years) {
        careerState.career_stage_years = payload.career_state.career_stage_years
      }
      if (draftRow?.aggregated_profile_json) {
        try {
          const profile = JSON.parse(draftRow.aggregated_profile_json)
          careerBackground = profile?.narrative?.career_background
        } catch { /* parse error, skip */ }
      }
    } catch (bgErr) {
    }

    if (openaiApiKey && candidatesForJudge.length > 0) {
      try {

        const judgeInput: JudgeInput = {
          candidates: candidatesForJudge,
          searchProfile,
          miniModuleResult: payload.mini_module_result,
          careerState,
          careerBackground,
        }

        const judgeResults = await judgeCandidates(openaiApiKey, db, judgeInput)

        // Judge ê²°ê³¼ë¥¼ topJobsì— ë§¤í•‘ (rationale + likeReason/canReason í¬í•¨)
        // ì ìˆ˜ ë§¤í•‘ ì •ì •:
        //   desireScore (í¥ë¯¸/ê°€ì¹˜ ë§¤ì¹­) â†’ like_score (ì¢‹ì•„í•  ê°€ëŠ¥ì„±)
        //   fitScore (ê°•ì /ì—­ëŸ‰ ë§¤ì¹­) â†’ can_score (ì˜í•  ê°€ëŠ¥ì„±)
        //   overallScore (ì¢…í•©) â†’ fit_score (ì¢…í•© ì í•©ë„)
        //   feasibilityScore (ë°°ê²½ì í•©ë„+ì§„ì…ì¥ë²½) â†’ Fit ê³µì‹ì— 10% ë°˜ì˜
        // ì „ì²´ Judge ê²°ê³¼ë¥¼ ë§¤í•‘ (Like/Can ë¶„ë¦¬ë¥¼ ìœ„í•´ sliceí•˜ì§€ ì•ŠìŒ)
        // diverseTop10ì—ì„œ like_score/can_score ê¸°ì¤€ìœ¼ë¡œ ê°ê° ë½‘ìœ¼ë¯€ë¡œ
        // ì—¬ê¸°ì„œ overallScore ìƒìœ„ Nê°œë¡œ ìë¥´ë©´ Like/Canì´ ë™ì¼í•´ì§
        topJobs = judgeResults.results.map(result => {
          const originalJob = preFilteredJobs.find(j => j.job_id === result.job_id)
          return {
            ...originalJob,
            like_score: result.desireScore,       // Like = í¥ë¯¸/ê°€ì¹˜ ë§¤ì¹­
            can_score: result.fitScore,            // Can = ê°•ì /ì—­ëŸ‰ ë§¤ì¹­
            fit_score: result.overallScore,        // Fit = ì¢…í•© (CanÃ—0.50 + LikeÃ—0.40 + BackgroundÃ—0.10 - Risk)
            final_score: result.overallScore,
            risk_penalty: result.riskPenalty,
            feasibility_score: result.feasibilityScore,  // í˜„ì‹¤ì„± ì ìˆ˜ (ì°¸ê³ ìš©)
            rationale: result.rationale,
            like_reason: result.likeReason,   // ì¢‹ì•„í•  ì´ìœ 
            can_reason: result.canReason,     // ì˜í•  ì´ìœ 
            evidence_quotes: result.evidenceQuotes,
          }
        })

        // ğŸ” DEBUG: topJobsì— image_url, job_descriptionì´ ìˆëŠ”ì§€ í™•ì¸
        if (topJobs.length > 0) {
          const sample = topJobs[0]
        }
      } catch (judgeError) {
        // LLM Judge ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°˜í™˜ (fallback ì—†ìŒ)
        const errorMessage = judgeError instanceof Error ? judgeError.message : String(judgeError)
        return c.json(createErrorResponse(
          'LLM_JUDGE_FAILED',
          `LLM ë¶„ì„ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ${errorMessage}`
        ), 500)
      }
    } else {
      // API í‚¤ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬ (ìœ„ì—ì„œ ì´ë¯¸ ì²´í¬í•˜ë¯€ë¡œ ì—¬ê¸° ë„ë‹¬í•˜ë©´ ì•ˆë¨)
      return c.json(createErrorResponse(
        'INTERNAL_ERROR',
        'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
      ), 500)
    }

    // ============================================
    // 5. LLM Reporter: ì‹¬ë¦¬ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± (skipReport=trueì´ë©´ ê±´ë„ˆëœ€)
    // ============================================
    let premiumReport: any = null
    let reportMode: 'llm' | 'fallback' | 'none' | 'deferred' = skipReport ? 'deferred' : 'none'
    let narrativeFacts: { highAliveMoment: string; lostMoment: string; existentialAnswer?: string } | undefined
    let roundAnswers: Array<{ roundNumber: 1 | 2 | 3; questionId: string; answer: string }> = []

    if (!skipReport) {
    // v3.10.6: NarrativeFacts + RoundAnswers ë³‘ë ¬ ì¡°íšŒ (ìˆœì°¨â†’ë³‘ë ¬ë¡œ ~1ì´ˆ ì ˆì•½)
    const [narrativeResult, roundAnswersResult] = await Promise.allSettled([
      // 5-1. NarrativeFacts
      db.prepare(`
        SELECT high_alive_moment, lost_moment, existential_answer
        FROM narrative_facts
        WHERE session_id = ?
      `).bind(session_id).first<{
        high_alive_moment: string | null
        lost_moment: string | null
        existential_answer: string | null
      }>(),
      // 5-2. RoundAnswers
      db.prepare(`
        SELECT round_number, question_id, answer
        FROM round_answers
        WHERE session_id = ?
        ORDER BY round_number, question_id
      `).bind(session_id).all<{
        round_number: number
        question_id: string
        answer: string
      }>(),
    ])

    if (narrativeResult.status === 'fulfilled' && narrativeResult.value) {
      const narrativeRow = narrativeResult.value
      if (narrativeRow.high_alive_moment || narrativeRow.lost_moment) {
        narrativeFacts = {
          highAliveMoment: narrativeRow.high_alive_moment || '',
          lostMoment: narrativeRow.lost_moment || '',
          existentialAnswer: narrativeRow.existential_answer || undefined,
        }
      }
    } else if (narrativeResult.status === 'rejected') {
    }

    if (roundAnswersResult.status === 'fulfilled' && roundAnswersResult.value?.results?.length) {
      roundAnswers = roundAnswersResult.value.results.map(row => ({
        roundNumber: row.round_number as 1 | 2 | 3,
        questionId: row.question_id,
        answer: row.answer,
      }))
    } else if (roundAnswersResult.status === 'rejected') {
    }

    // 5-3. LLM Reporter í˜¸ì¶œ
    if (openaiApiKey && topJobs.length > 0) {
      try {

        // excluded jobs ëª©ë¡ (Hard Cut)
        const hardCutList = mmFilterResult.excludedJobIds.map((jobId, idx) => ({
          job_id: jobId,
          job_name: `Excluded Job ${idx + 1}`,
          rule_id: mmFilterResult.appliedRules[0]?.ruleId || 'mini_module_filter',
          reason: mmFilterResult.appliedRules[0]?.description || 'ë¯¸ë‹ˆëª¨ë“ˆ ê¸°ë°˜ ì œì™¸',
        })).slice(0, 10)

        // Reporterì—ëŠ” fit_score ìƒìœ„ 20ê°œë§Œ ì „ë‹¬ (í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì œí•œ)
        const topJobsForReporter = [...topJobs]
          .sort((a, b) => (b.final_score || 0) - (a.final_score || 0))
          .slice(0, judgeTopN)
        const reporterInput: ReporterInput = {
          sessionId: session_id,
          judgeResults: topJobsForReporter.map(job => ({
            job_id: job.job_id,
            job_name: job.job_name,
            slug: job.slug || '',
            image_url: job.image_url || undefined,
            like_score: job.like_score || 50,
            can_score: job.can_score || 50,
            fit_verdict: job.like_score && job.like_score >= 70 ? 'STRONG_FIT' : 'MODERATE_FIT',
            fit_summary: job.job_description || `${job.job_name}${ì€ëŠ”(job.job_name)} ë‹¹ì‹ ì˜ ê´€ì‹¬ì‚¬ì™€ ì˜ ë§ìŠµë‹ˆë‹¤.`,
            risk_note: job.risk_penalty && job.risk_penalty > 0 ? 'ì¼ë¶€ ì œì•½ ì¡°ê±´ ê³ ë ¤ í•„ìš”' : undefined,
          })),
          searchProfile,
          narrativeFacts,
          roundAnswers,
          universalAnswers: {},
          hardCutList,
          miniModuleResult: payload.mini_module_result,
        }

        premiumReport = await generateLLMPremiumReport(
          env?.AI || null,
          reporterInput,
          openaiApiKey
        )
        // LLM ë¦¬í¬íŠ¸ì¸ì§€ fallbackì¸ì§€ í™•ì¸ (metaCognition._meta.generated_byë¡œ íŒë‹¨)
        reportMode = premiumReport?.metaCognition?._meta?.generated_by === 'rule' ? 'fallback' : 'llm'
      } catch (reporterError) {
        reportMode = 'fallback'
        // Fallback: ê¸°ë³¸ ì‹¬ë¦¬ ë¶„ì„ ì œê³µ
        const mm = payload.mini_module_result
        const toKo = (t: string) => TOKEN_TO_KOREAN[t] || t
        premiumReport = fixParticlesDeep({
          workStyleNarrative: mm ?
            generateFallbackWorkStyle(mm) : null,
          lifeVersionStatement: {
            oneLiner: 'ë‹¹ì‹ ì˜ ì„ íƒì„ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.',
            expanded: [],
          },
          // profileInterpretation fallback
          profileInterpretation: mm ? {
            interests: (mm.interest_top || []).map((t: string) => ({
              token: t,
              label: toKo(t),
              meaning: `${toKo(t)}ì— ê´€ì‹¬ì´ ìˆìŠµë‹ˆë‹¤.`
            })),
            interests_summary: (mm.interest_top || []).length ? `ë‹¹ì‹ ì€ ${(mm.interest_top || []).map(toKo).join('ê³¼(ì™€) ')}ì— ê´€ì‹¬ì´ ìˆìŠµë‹ˆë‹¤.` : '',
            strengths: (mm.strength_top || []).map((t: string) => ({
              token: t,
              label: toKo(t),
              meaning: `${toKo(t)}ì´(ê°€) ê°•ì ì…ë‹ˆë‹¤.`
            })),
            strengths_summary: (mm.strength_top || []).length ? `ë‹¹ì‹ ì€ ${(mm.strength_top || []).map(toKo).join('ê³¼(ì™€) ')}ì— ê°•ì ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.` : '',
            values: (mm.value_top || []).map((t: string) => ({
              token: t,
              label: toKo(t),
              meaning: `${toKo(t)}ì„(ë¥¼) ì¤‘ìš”í•˜ê²Œ ìƒê°í•©ë‹ˆë‹¤.`
            })),
            values_summary: (mm.value_top || []).length ? `ë‹¹ì‹ ì—ê²Œ ${(mm.value_top || []).map(toKo).join('ê³¼(ì™€) ')}ì€(ëŠ”) ì¤‘ìš”í•œ ê°€ì¹˜ì…ë‹ˆë‹¤.` : '',
            constraints: (mm.constraint_flags || []).map((t: string) => ({
              token: t,
              label: toKo(t),
              meaning: `${toKo(t)}ì„(ë¥¼) í”¼í•˜ê³  ì‹¶ì–´í•©ë‹ˆë‹¤.`
            })),
            constraints_summary: (() => { const flags = (mm.constraint_flags || []).map(toKo); if (!flags.length) return ''; return `ë‹¹ì‹ ì€ ${flags.join('ê³¼(ì™€) ')}ì„(ë¥¼) í”¼í•˜ê³  ì‹¶ì–´í•©ë‹ˆë‹¤.` })(),
            overall_profile: 'í”„ë¡œí•„ ë¶„ì„ì„ ìœ„í•´ ë” ë§ì€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.'
          } : undefined,
        })
      }
    }
    } // end if (!skipReport)

    // v3.10.2: í¬ìŠ¤íŠ¸-Judge ì•„í‚¤íƒ€ì… ë³´ì¥
    // LLM Judgeê°€ ìœ ì €ì˜ í•µì‹¬ í¥ë¯¸ ì•„í‚¤íƒ€ì… ì§ì—…ì— ë‚®ì€ ì ìˆ˜ë¥¼ ì¤„ ê²½ìš°,
    // ìµœì¢… ê²°ê³¼ì— ìµœì†Œ 2ê°œ ì•„í‚¤íƒ€ì… ì§ì—…ì´ í¬í•¨ë˜ë„ë¡ ì ìˆ˜ ë³´ì •
    if (topJobs.length > 0 && mmInterests.length > 0) {
      const primaryInterest = mmInterests[0]
      const primaryConfig = ARCHETYPE_DB_QUERIES[primaryInterest]
      if (primaryConfig) {
        const archetypeInTop = topJobs.filter(j =>
          primaryConfig.patterns.some(p => j.job_name.includes(p))
        )

        if (archetypeInTop.length > 0) {
          // topJobsë¥¼ fit ìˆœìœ¼ë¡œ ì •ë ¬í–ˆì„ ë•Œ ì•„í‚¤íƒ€ì… ì§ì—…ì´ top10 ë°–ì´ë©´ ë¶€ìŠ¤íŠ¸
          const sortedByFit = [...topJobs].sort((a, b) => (b.final_score || 0) - (a.final_score || 0))
          const top10Threshold = sortedByFit[Math.min(9, sortedByFit.length - 1)]?.final_score || 0

          const archetypeBelowThreshold = archetypeInTop.filter(j => (j.final_score || 0) < top10Threshold)
          if (archetypeBelowThreshold.length > 0) {
            // ìƒìœ„ 3ê°œ ì•„í‚¤íƒ€ì… ì§ì—…ì— ë¶€ìŠ¤íŠ¸ ì ìš©
            const toBoost = archetypeBelowThreshold
              .sort((a: any, b: any) => (b.final_score || 0) - (a.final_score || 0))
              .slice(0, 3)
            for (const job of toBoost) {
              const oldLike = job.like_score || 0
              const oldCan = job.can_score || 0
              const oldFit = job.final_score || 0
              // ìœ ì €ì˜ #1 í¥ë¯¸ì™€ ì§ì ‘ ë§¤ì¹­ë˜ëŠ” ì§ì—… â†’ Like + Can ë¶€ìŠ¤íŠ¸
              job.like_score = Math.min(100, oldLike + 15)
              job.can_score = Math.min(100, oldCan + 8)
              job.final_score = Math.round(0.55 * job.like_score + 0.45 * job.can_score - (job.risk_penalty || 0))
            }
          }
        }
      }
    }

    // 6. ê²°ê³¼ ë°˜í™˜
    const duration = Date.now() - startTime

    // ì¹´í…Œê³ ë¦¬ ë‹¤ì–‘ì„± ì ìš© Top 10 ì„ íƒ í•¨ìˆ˜
    // ê°™ì€ KSCO ëŒ€ë¶„ë¥˜ì—ì„œ ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ í—ˆìš©, ë¶€ì¡±í•˜ë©´ fallbackìœ¼ë¡œ ì±„ì›€
    const diverseTop10 = (
      jobs: any[],
      scoreKey: 'like_score' | 'can_score',
      maxPerCategory: number = 3
    ) => {
      const sorted = [...jobs]
        .filter(job => (job.final_score || job.fit_score || 0) >= 25)
        .sort((a, b) => {
          const scoreDiff = (b[scoreKey] || 0) - (a[scoreKey] || 0)
          // ì ìˆ˜ ì°¨ì´ 3ì  ì´ë‚´ â†’ í¸í–¥ tie-break: likeëŠ” desire>fit ìš°ì„ , canì€ fit>desire ìš°ì„ 
          if (Math.abs(scoreDiff) <= 3) {
            if (scoreKey === 'like_score') {
              return ((b.like_score || 0) - (b.can_score || 0)) - ((a.like_score || 0) - (a.can_score || 0))
            } else {
              return ((b.can_score || 0) - (b.like_score || 0)) - ((a.can_score || 0) - (a.like_score || 0))
            }
          }
          return scoreDiff
        })

      const result: any[] = []
      const selectedIds = new Set<string>()
      const categoryCount = new Map<string, number>()

      // 1ì°¨: ì¹´í…Œê³ ë¦¬ ë‹¤ì–‘ì„± ì ìš©
      for (const job of sorted) {
        if (result.length >= 10) break
        const category = job.ksco_major || job.attributes?.ksco_major || 'ê¸°íƒ€'
        const count = categoryCount.get(category) || 0
        if (count >= maxPerCategory) continue

        result.push(job)
        selectedIds.add(job.job_id)
        categoryCount.set(category, count + 1)
      }

      // 2ì°¨ fallback: 10ê°œ ë¯¸ë§Œì´ë©´ ì¹´í…Œê³ ë¦¬ ì œí•œ ì—†ì´ ì ìˆ˜ìˆœìœ¼ë¡œ ì±„ì›€
      if (result.length < 10) {
        for (const job of sorted) {
          if (result.length >= 10) break
          if (selectedIds.has(job.job_id)) continue
          result.push(job)
          selectedIds.add(job.job_id)
        }
      }

      return result
    }

    const jobToDto = (job: any) => ({
      job_id: job.job_id,
      job_name: job.job_name,
      job_description: job.job_description || null,
      slug: job.slug,
      image_url: job.image_url || null,
      fit_score: job.final_score || job.fit_score || 50,
      like_score: job.like_score || 50,
      can_score: job.can_score || 50,
      feasibility_score: job.feasibility_score || 0,
      rationale: job.rationale || null,
      like_reason: job.like_reason || null,
      can_reason: job.can_reason || null,
    })

    // like_top10: like_score ê¸°ì¤€ + ì¹´í…Œê³ ë¦¬ ë‹¤ì–‘ì„±
    let likeTop10 = diverseTop10(topJobs, 'like_score').map(jobToDto)

    // can_top10: can_score ê¸°ì¤€ + ì¹´í…Œê³ ë¦¬ ë‹¤ì–‘ì„±
    let canTop10 = diverseTop10(topJobs, 'can_score').map(jobToDto)

    // v3.10.3: ìµœì¢… ê²°ê³¼ ì•„í‚¤íƒ€ì… ê°•ì œ ì‚½ì…
    // Judgeê°€ ì•„í‚¤íƒ€ì… ì§ì—…ì— ë‚®ì€ ì ìˆ˜ë¥¼ ì¤˜ì„œ top10ì— ëª» ë“¤ì–´ê°€ëŠ” ê²½ìš°,
    // ìµœì¢… ë¦¬ìŠ¤íŠ¸ì— ì§ì ‘ ì‚½ì…í•˜ì—¬ ìœ ì €ì˜ #1 í¥ë¯¸ì™€ ê´€ë ¨ëœ ì§ì—…ì´ ë°˜ë“œì‹œ í¬í•¨ë˜ë„ë¡ ë³´ì¥
    if (topJobs.length > 0 && mmInterests.length > 0) {
      const primaryInterest = mmInterests[0]
      const primaryConfig = ARCHETYPE_DB_QUERIES[primaryInterest]
      if (primaryConfig) {
        // topJobs(Judge ê²°ê³¼ ì „ì²´)ì—ì„œ ì•„í‚¤íƒ€ì… ë§¤ì¹­ ì§ì—… ì°¾ê¸°
        const archetypeFromJudge = topJobs
          .filter((j: any) => primaryConfig.patterns.some(p => j.job_name.includes(p)))
          .sort((a: any, b: any) => (b.like_score || 0) - (a.like_score || 0))

        const injectIntoList = (list: any[], sortKey: 'like_score' | 'can_score', minCount: number) => {
          const existingInList = list.filter(j => primaryConfig.patterns.some(p => j.job_name.includes(p)))
          if (existingInList.length >= minCount) return list

          const needed = minCount - existingInList.length
          const existingIds = new Set(list.map(j => j.job_id))

          // Judge ê²°ê³¼ì—ì„œ ì•„í‚¤íƒ€ì… ì§ì—… ì¤‘ ë¦¬ìŠ¤íŠ¸ì— ì—†ëŠ” ê²ƒ ì„ íƒ
          const toInject = archetypeFromJudge
            .filter((j: any) => !existingIds.has(j.job_id))
            .slice(0, needed)
            .map(jobToDto)

          if (toInject.length === 0) return list

          // ë¦¬ìŠ¤íŠ¸ ëì—ì„œë¶€í„° êµì²´ (ê°€ì¥ ë‚®ì€ ì ìˆ˜ ì§ì—…ì„ ëŒ€ì²´)
          const result = [...list]
          for (let i = 0; i < toInject.length && result.length > 0; i++) {
            result[result.length - 1 - i] = toInject[i]
          }
          return result
        }

        likeTop10 = injectIntoList(likeTop10, 'like_score', 2)
        canTop10 = injectIntoList(canTop10, 'can_score', 2)

        // fit_top3ìš©ë„ ì²´í¬: topJobsë¥¼ fit ìˆœìœ¼ë¡œ ì •ë ¬í•  ë•Œ ì•„í‚¤íƒ€ì… í¬í•¨ ì—¬ë¶€
        // (fit_top3ëŠ” resultToSaveì—ì„œ ì§ì ‘ êµ¬ì„±í•˜ë¯€ë¡œ ì•„ë˜ì„œ ì²˜ë¦¬)
      }
    }

    // ============================================
    // 6-1. Confidence ê³„ì‚° â†’ premiumReportì— ì£¼ì…
    // ============================================
    try {
      // 1) DB facts ì‹œë„
      let cfFacts: Array<{ fact_key: string; value_json: string }> = []
      try {
        const factsResult = await db.prepare(
          `SELECT fact_key, value_json FROM facts WHERE session_id = ?`
        ).bind(session_id).all<{ fact_key: string; value_json: string }>()
        cfFacts = factsResult.results || []
      } catch { /* facts í…Œì´ë¸” ì—†ì–´ë„ OK */ }

      // 2) DB factsê°€ ë¶€ì¡±í•˜ë©´ mini_module_resultì—ì„œ ë¹Œë“œ
      if (cfFacts.length < 3 && payload.mini_module_result) {
        cfFacts = buildConfidenceFactsFromMiniModule(payload.mini_module_result)
      }

      const topScores = [...topJobs]
        .sort((a, b) => (b.final_score || 0) - (a.final_score || 0))
        .slice(0, 10)
        .map(j => j.final_score || 0)
      const confidenceResult = calculateConfidenceScore(
        cfFacts.map(f => ({
          fact_key: f.fact_key,
          source: f.fact_key.startsWith('followup') ? 'followup' as const : undefined,
          value_json: f.value_json,
        })),
        roundAnswers.length,
        topScores
      )
      if (premiumReport) {
        premiumReport._confidence = confidenceResult.score
      }
    } catch (e) {
    }

    // DB ì „ì²´ ì§ì—… ìˆ˜ ì¡°íšŒ (UI í‘œì‹œìš©)
    if (premiumReport) {
      try {
        const totalJobCount = await db.prepare('SELECT COUNT(*) as cnt FROM jobs').first<{ cnt: number }>()
        premiumReport._totalJobCount = totalJobCount?.cnt || 0
      } catch (e) {
      }
    }

    // ============================================
    // 7. ê²°ê³¼ ì €ì¥ (ai_analysis_requests + ai_analysis_results)
    // ============================================
    const resultToSave = {
      engine_version: RECOMMENDATION_ENGINE_VERSION,
      mini_module_result: payload.mini_module_result || null,
      fit_top3: sanitizeJobListOutput([...topJobs].sort((a, b) => (b.final_score || 0) - (a.final_score || 0)).slice(0, 10).map(job => ({
        job_id: job.job_id,
        job_name: job.job_name,
        job_description: job.job_description || null,
        slug: job.slug,
        image_url: job.image_url || null,
        fit_score: job.final_score || job.fit_score || 50,
        like_score: job.like_score || 50,
        can_score: job.can_score || 50,
        feasibility_score: job.feasibility_score || 0,
        rationale: job.rationale || null,
        like_reason: job.like_reason || null,
        can_reason: job.can_reason || null,
      }))),
      like_top10: sanitizeJobListOutput(likeTop10),
      can_top10: sanitizeJobListOutput(canTop10),
      premium_report: premiumReport,
      search_profile: searchProfile,
      total_candidates: expansionResult.candidates.length,
      filtered_count: filteredJobs.length,
    }

    let savedRequestId: number | null = null
    try {
      // 1. ë¨¼ì € ai_analysis_requestsì— ë ˆì½”ë“œ ìƒì„± (ë˜ëŠ” ê¸°ì¡´ ê²ƒ ì¡°íšŒ)
      // user_id: ì¸ì¦ëœ ì‚¬ìš©ì ë˜ëŠ” draftì—ì„œ ê°€ì ¸ì˜´
      let effectiveUserId = userId

      // userIdê°€ ì—†ìœ¼ë©´ draftì—ì„œ user_id ì¡°íšŒ
      if (!effectiveUserId) {
        const draftOwner = await db.prepare(`
          SELECT user_id FROM analyzer_drafts WHERE session_id = ?
        `).bind(session_id).first<{ user_id: number | null }>()
        effectiveUserId = draftOwner?.user_id || null
      }

      // ê¸°ì¡´ request í™•ì¸
      const existingRequest = await db.prepare(`
        SELECT id FROM ai_analysis_requests WHERE session_id = ?
      `).bind(session_id).first<{ id: number }>()

      if (existingRequest) {
        savedRequestId = existingRequest.id
        // ê¸°ì¡´ request ìƒíƒœ ì—…ë°ì´íŠ¸ (user_idê°€ ì—†ìœ¼ë©´ effectiveUserIdë¡œ ì„¤ì •)
        await db.prepare(`
          UPDATE ai_analysis_requests
          SET status = 'completed',
              processed_at = CURRENT_TIMESTAMP,
              user_id = COALESCE(user_id, ?)
          WHERE id = ?
        `).bind(effectiveUserId, savedRequestId).run()
      } else {
        // ìƒˆ request ìƒì„±
        const insertResult = await db.prepare(`
          INSERT INTO ai_analysis_requests (session_id, user_id, analysis_type, status, processed_at, created_at)
          VALUES (?, ?, 'job', 'completed', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
        `).bind(session_id, effectiveUserId).run()
        savedRequestId = insertResult.meta?.last_row_id as number || null
      }

      if (savedRequestId) {
        // 2. ai_analysis_resultsì— ì €ì¥ (UPDATE ìš°ì„ , ì—†ìœ¼ë©´ INSERT)
        // NOTE: request_idì— UNIQUE ì œì•½ì´ ì—†ì–´ ON CONFLICT UPSERT ë¶ˆê°€ â†’ UPDATE+INSERT íŒ¨í„´ ì‚¬ìš©
        const resultJson = JSON.stringify(resultToSave)
        const premiumJson = JSON.stringify(premiumReport)

        const updateResult = await db.prepare(`
          UPDATE ai_analysis_results
          SET result_json = ?,
              engine_version = ?,
              premium_report_json = ?
          WHERE request_id = ?
        `).bind(resultJson, RECOMMENDATION_ENGINE_VERSION, premiumJson, savedRequestId).run()

        if (!updateResult.meta?.changes || updateResult.meta.changes === 0) {
          // ê¸°ì¡´ í–‰ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ INSERT
          await db.prepare(`
            INSERT INTO ai_analysis_results (request_id, result_json, engine_version, premium_report_json, created_at)
            VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)
          `).bind(savedRequestId, resultJson, RECOMMENDATION_ENGINE_VERSION, premiumJson).run()
        }

      }
    } catch (saveError) {
      // ì €ì¥ ì‹¤íŒ¨í•´ë„ ê²°ê³¼ëŠ” ë°˜í™˜ (ë¡œê·¸ë§Œ ë‚¨ê¹€)
    }

    return c.json({
      success: true,
      mode: 'recommendation',
      session_id,
      request_id: savedRequestId,  // ê²°ê³¼ í˜ì´ì§€ ì´ë™ìš©
      recommendations: {
        top_jobs: sanitizeJobListOutput(topJobs.map(job => ({
          job_id: job.job_id,
          job_name: job.job_name,
          job_description: job.job_description || null,
          slug: job.slug,
          image_url: job.image_url || null,
          fit_score: job.final_score || job.fit_score || job.like_score || 50,
          like_score: job.like_score || 50,
          can_score: job.can_score || 50,
          feasibility_score: job.feasibility_score || 0,
          risk_penalty: job.risk_penalty || 0,
          rationale: job.rationale || null,
          like_reason: job.like_reason || null,   // ì¢‹ì•„í•  ì´ìœ 
          can_reason: job.can_reason || null,     // ì˜í•  ì´ìœ 
          evidence_quotes: job.evidence_quotes || [],
        }))),
        like_top10: sanitizeJobListOutput(likeTop10),
        can_top10: sanitizeJobListOutput(canTop10),
        total_candidates: expansionResult.candidates.length,
        filtered_count: filteredJobs.length,
        search_duration_ms: expansionResult.search_duration_ms,
      },
      premium_report: premiumReport,
      engine_version: RECOMMENDATION_ENGINE_VERSION,
      report_mode: reportMode,  // 'llm' | 'fallback' | 'none'
      search_profile_used: searchProfile,
      debug_info: debug ? {
        vectorize_topK: topK,
        judge_topN: judgeTopN,
        cache_hit: expansionResult.cacheHit,
        fallback_used: expansionResult.fallback_used,
        has_narrative_facts: !!narrativeFacts,
        round_answers_count: roundAnswers.length,
      } : undefined,
      duration_ms: duration,
    })
    
  } catch (error) {
    logError('ANALYSIS_FAILED', error instanceof Error ? error.message : 'Recommendation failed', {
      stack: error instanceof Error ? error.stack : undefined
    })
    return c.json(createErrorResponse(
      'ANALYSIS_FAILED',
      'ì¶”ì²œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
    ), 500)
  }
})

// ============================================
// Phase 2: LLM Reporter ì „ìš© ì—”ë“œí¬ì¸íŠ¸
// /v3/recommendì—ì„œ skipReport=true í›„ í˜¸ì¶œ
// ============================================
analyzerRoutes.post('/v3/recommend/report', async (c) => {
  const env = c.env as Bindings
  const db = env.DB
  const openaiApiKey = c.env.OPENAI_API_KEY
  const { session_id } = await c.req.json<{ session_id: string }>()

  if (!session_id) {
    return c.json(createErrorResponse('VALIDATION_ERROR', 'session_id is required'), 400)
  }
  if (!openaiApiKey) {
    return c.json(createErrorResponse('INTERNAL_ERROR', 'OpenAI API key not configured'), 500)
  }

  try {
    const startTime = Date.now()

    // 1. DBì—ì„œ Phase 1 ê²°ê³¼ ë¡œë“œ
    const existingRequest = await db.prepare(
      `SELECT id FROM ai_analysis_requests WHERE session_id = ?`
    ).bind(session_id).first<{ id: number }>()
    if (!existingRequest) {
      return c.json(createErrorResponse('NOT_FOUND', 'Phase 1 ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. /v3/recommendë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.'), 404)
    }

    const savedResult = await db.prepare(
      `SELECT result_json FROM ai_analysis_results WHERE request_id = ?`
    ).bind(existingRequest.id).first<{ result_json: string }>()
    if (!savedResult?.result_json) {
      return c.json(createErrorResponse('NOT_FOUND', 'ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.'), 404)
    }

    const parsed = JSON.parse(savedResult.result_json)
    const miniModuleResult = parsed.mini_module_result
    const searchProfile = parsed.search_profile
    const topJobs = parsed.fit_top3 || []

    // 2-3. NarrativeFacts + RoundAnswers ë³‘ë ¬ ì¡°íšŒ
    let narrativeFacts: { highAliveMoment: string; lostMoment: string; existentialAnswer?: string } | undefined
    let roundAnswers: Array<{ roundNumber: 1 | 2 | 3; questionId: string; answer: string }> = []

    const [nfResult, raResult] = await Promise.allSettled([
      db.prepare(
        `SELECT high_alive_moment, lost_moment, existential_answer FROM narrative_facts WHERE session_id = ?`
      ).bind(session_id).first<{ high_alive_moment: string | null; lost_moment: string | null; existential_answer: string | null }>(),
      db.prepare(
        `SELECT round_number, question_id, answer FROM round_answers WHERE session_id = ? ORDER BY round_number, question_id`
      ).bind(session_id).all<{ round_number: number; question_id: string; answer: string }>(),
    ])

    if (nfResult.status === 'fulfilled' && nfResult.value) {
      const narrativeRow = nfResult.value
      if (narrativeRow.high_alive_moment || narrativeRow.lost_moment) {
        narrativeFacts = {
          highAliveMoment: narrativeRow.high_alive_moment || '',
          lostMoment: narrativeRow.lost_moment || '',
          existentialAnswer: narrativeRow.existential_answer || undefined,
        }
      }
    }
    if (raResult.status === 'fulfilled' && raResult.value?.results?.length) {
      roundAnswers = raResult.value.results.map(r => ({ roundNumber: r.round_number as 1|2|3, questionId: r.question_id, answer: r.answer }))
    }

    // 4. LLM Reporter í˜¸ì¶œ
    const reporterInput: ReporterInput = {
      sessionId: session_id,
      judgeResults: topJobs.map((job: any) => ({
        job_id: job.job_id,
        job_name: job.job_name,
        slug: job.slug || '',
        image_url: job.image_url || undefined,
        like_score: job.like_score || 50,
        can_score: job.can_score || 50,
        fit_verdict: job.like_score >= 70 ? 'STRONG_FIT' : 'MODERATE_FIT',
        fit_summary: job.job_description || `${job.job_name}ì€(ëŠ”) ë‹¹ì‹ ì˜ ê´€ì‹¬ì‚¬ì™€ ì˜ ë§ìŠµë‹ˆë‹¤.`,
        risk_note: job.risk_penalty > 0 ? 'ì¼ë¶€ ì œì•½ ì¡°ê±´ ê³ ë ¤ í•„ìš”' : undefined,
      })),
      searchProfile: searchProfile || { desiredThemes: [], dislikedThemes: [], strengthsHypothesis: [], environmentPreferences: [], hardConstraints: [], riskSignals: [], keywords: [] },
      narrativeFacts,
      roundAnswers,
      universalAnswers: {},
      hardCutList: [],
      miniModuleResult,
    }

    const premiumReport = await generateLLMPremiumReport(env?.AI || null, reporterInput, openaiApiKey)
    const reportMode = premiumReport?.metaCognition?._meta?.generated_by === 'rule' ? 'fallback' : 'llm'

    // 4-1. Confidence ê³„ì‚° â†’ premiumReportì— ì£¼ì…
    try {
      // 1) DB facts ì‹œë„
      let cfFacts: Array<{ fact_key: string; value_json: string }> = []
      try {
        const factsResult = await db.prepare(
          `SELECT fact_key, value_json FROM facts WHERE session_id = ?`
        ).bind(session_id).all<{ fact_key: string; value_json: string }>()
        cfFacts = factsResult.results || []
      } catch { /* facts í…Œì´ë¸” ì—†ì–´ë„ OK */ }

      // 2) DB factsê°€ ë¶€ì¡±í•˜ë©´ mini_module_resultì—ì„œ ë¹Œë“œ
      if (cfFacts.length < 3 && miniModuleResult) {
        cfFacts = buildConfidenceFactsFromMiniModule(miniModuleResult)
      }

      const topScores = topJobs.map((j: any) => j.fit_score || 0)
      const confidenceResult = calculateConfidenceScore(
        cfFacts.map(f => ({
          fact_key: f.fact_key,
          source: f.fact_key.startsWith('followup') ? 'followup' as const : undefined,
          value_json: f.value_json,
        })),
        roundAnswers.length,
        topScores
      )
      if (premiumReport) {
        premiumReport._confidence = confidenceResult.score
      }
    } catch (e) {
    }

    // 5. DBì— ë¦¬í¬íŠ¸ ì €ì¥
    try {
      const premiumJson = JSON.stringify(premiumReport)
      const updatedResult = { ...parsed, premium_report: premiumReport }
      await db.prepare(
        `UPDATE ai_analysis_results SET result_json = ?, premium_report_json = ? WHERE request_id = ?`
      ).bind(JSON.stringify(updatedResult), premiumJson, existingRequest.id).run()
    } catch (saveErr) {
    }

    return c.json({
      success: true,
      session_id,
      premium_report: premiumReport,
      report_mode: reportMode,
      duration_ms: Date.now() - startTime,
    })
  } catch (error) {
    return c.json(createErrorResponse(
      'REPORT_FAILED',
      error instanceof Error ? error.message : 'Report generation failed'
    ), 500)
  }
})

// ============================================
// Freeze v1.1: Interview Mode - QSP ìƒì„± API
// ============================================
// ì„¤ë¬¸ ì¤‘ Vectorize ì„¼ì„œìš© QSP ìƒì„±
// ============================================
analyzerRoutes.post('/v3/interview/qsp', async (c) => {
  const env = c.env as Bindings
  const db = env.DB
  const openaiApiKey = c.env.OPENAI_API_KEY
  
  const payload = await c.req.json<{
    session_id: string
    round?: 1 | 2 | 3
    draft_id?: number
  }>()
  
  const { session_id, round = 1, draft_id } = payload
  
  if (!session_id) {
    return c.json(createErrorResponse('VALIDATION_ERROR', 'session_id required'), 400)
  }
  
  if (!openaiApiKey) {
    return c.json(createErrorResponse('INTERNAL_ERROR', 'OpenAI API key not configured'), 500)
  }
  
  try {
    // Draftì—ì„œ í”„ë¡œí•„ ë¹Œë“œ (ìˆìœ¼ë©´)
    let axisCoverage = createEmptyAxisCoverage()
    
    if (draft_id) {
      const draft = await db.prepare(`
        SELECT * FROM ai_analysis_drafts WHERE id = ?
      `).bind(draft_id).first<AggDraftData>()
      
      if (draft) {
        const aggregated = buildAggregatedProfile(draft)
        // AggregatedProfileì—ì„œ AxisCoverage ì¶”ì¶œ
        const a = aggregated.anchors
        if (a.interest_top?.length) {
          axisCoverage = updateAxisCoverage(axisCoverage, 'interest', {
            confidence: Math.min(a.interest_top.length / 3, 1),
            evidence: a.interest_top.slice(0, 5),
          })
        }
        if (a.strength_top?.length) {
          axisCoverage = updateAxisCoverage(axisCoverage, 'strength', {
            confidence: Math.min(a.strength_top.length / 3, 1),
            evidence: a.strength_top.slice(0, 5),
          })
        }
        if (a.value_top?.length) {
          axisCoverage = updateAxisCoverage(axisCoverage, 'values', {
            confidence: Math.min(a.value_top.length / 3, 1),
            evidence: a.value_top.slice(0, 5),
          })
        }
        if (a.energy_drain_flags?.length || a.execution_style) {
          axisCoverage = updateAxisCoverage(axisCoverage, 'work_style', {
            confidence: 0.5,
            evidence: [...(a.energy_drain_flags || []), a.execution_style].filter(Boolean).slice(0, 5) as string[],
          })
        }
        if (a.impact_scope || a.external_expectation) {
          axisCoverage = updateAxisCoverage(axisCoverage, 'people', {
            confidence: 0.4,
            evidence: [a.impact_scope, a.external_expectation].filter(Boolean) as string[],
          })
        }
      }
    }
    
    // Vectorize ì„¼ì„œ ì¿¼ë¦¬ (topK=500, ì§ì—…ëª… ë¹„ë…¸ì¶œ)
    const expansionResult = await expandCandidatesV3WithCache(
      db,
      env.VECTORIZE,
      openaiApiKey,
      {
        narrativeFacts: undefined,
        roundAnswers: [],
        universalAnswers: {},
      },
      {
        sessionId: session_id,
        targetSize: 500,  // ì„¼ì„œìš©
      }
    )
    
    // QSP ìƒì„±
    const qsp = generateQSP({
      vectorResults: expansionResult.candidates,
      axisCoverage,
      round,
    })
    
    return c.json({
      success: true,
      qsp,
      prompt_hints: qspToPromptHints(qsp),
      vectorize_stats: {
        total_candidates: expansionResult.candidates.length,
        cache_hit: expansionResult.cacheHit,
      },
    })
    
  } catch (error) {
    return c.json(createErrorResponse(
      'ANALYSIS_FAILED',
      error instanceof Error ? error.message : 'QSP generation failed'
    ), 500)
  }
})

// ============================================
// Freeze v1.1: ì¸ë±ì‹± ìƒíƒœ í™•ì¸ API
// ============================================
analyzerRoutes.get('/admin/indexing-status', async (c) => {
  const authError = checkAdminAuth(c)
  if (authError) return authError
  const env = c.env as Bindings
  const db = env.DB
  
  try {
    const status = await countJobsNeedingIndexing(db)
    
    return c.json({
      success: true,
      ...status,
      current_version: `JPC_${JOB_PROFILE_COMPACT_VERSION}`,
      percentage_indexed: status.total > 0 
        ? Math.round((status.upToDate / status.total) * 100) 
        : 0,
    })
    
  } catch (error) {
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error',
    }, 500)
  }
})

// ============================================
// Freeze v1.1: ì¦ë¶„ ì—…ì„œíŠ¸ API
// ============================================
analyzerRoutes.post('/admin/incremental-upsert', async (c) => {
  const authError = checkAdminAuth(c)
  if (authError) return authError
  const env = c.env as Bindings
  const db = env.DB
  const openaiApiKey = c.env.OPENAI_API_KEY
  
  if (!env.VECTORIZE) {
    return c.json({ success: false, error: 'VECTORIZE_NOT_AVAILABLE' }, 503)
  }
  
  if (!openaiApiKey) {
    return c.json({ success: false, error: 'OPENAI_API_KEY_NOT_SET' }, 503)
  }
  
  const payload = await c.req.json<{ max_jobs?: number }>().catch(() => ({}))
  const maxJobs = payload.max_jobs || 100
  
  try {
    const result = await incrementalUpsertToVectorize(
      db,
      env.VECTORIZE,
      openaiApiKey,
      { maxJobs }
    )
    
    return c.json({
      success: true,
      ...result,
    })
    
  } catch (error) {
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error',
    }, 500)
  }
})

import { JOB_PROFILE_COMPACT_VERSION } from '../../constants/embedding-versions'

// ============================================
// ì „ê³µ ì¦ë¶„ ì—…ì„œíŠ¸ API
// ============================================
analyzerRoutes.post('/admin/incremental-upsert-majors', async (c) => {
  const authError = checkAdminAuth(c)
  if (authError) return authError
  const env = c.env as Bindings
  const db = env.DB
  const openaiApiKey = c.env.OPENAI_API_KEY

  if (!env.VECTORIZE) {
    return c.json({ success: false, error: 'VECTORIZE_NOT_AVAILABLE' }, 503)
  }
  if (!openaiApiKey) {
    return c.json({ success: false, error: 'OPENAI_API_KEY_NOT_SET' }, 503)
  }

  const payload = await c.req.json<{ max_items?: number }>().catch(() => ({}))
  const maxItems = payload.max_items || 100

  try {
    const result = await incrementalUpsertMajorsToVectorize(
      db, env.VECTORIZE, openaiApiKey, { maxItems }
    )
    return c.json({ success: true, ...result })
  } catch (error) {
    return c.json({ success: false, error: error instanceof Error ? error.message : 'Unknown error' }, 500)
  }
})

// ============================================
// HowTo ì¦ë¶„ ì—…ì„œíŠ¸ API
// ============================================
analyzerRoutes.post('/admin/incremental-upsert-howtos', async (c) => {
  const authError = checkAdminAuth(c)
  if (authError) return authError
  const env = c.env as Bindings
  const db = env.DB
  const openaiApiKey = c.env.OPENAI_API_KEY

  if (!env.VECTORIZE) {
    return c.json({ success: false, error: 'VECTORIZE_NOT_AVAILABLE' }, 503)
  }
  if (!openaiApiKey) {
    return c.json({ success: false, error: 'OPENAI_API_KEY_NOT_SET' }, 503)
  }

  const payload = await c.req.json<{ max_items?: number }>().catch(() => ({}))
  const maxItems = payload.max_items || 100

  try {
    const result = await incrementalUpsertHowtosToVectorize(
      db, env.VECTORIZE, openaiApiKey, { maxItems }
    )
    return c.json({ success: true, ...result })
  } catch (error) {
    return c.json({ success: false, error: error instanceof Error ? error.message : 'Unknown error' }, 500)
  }
})

// ============================================
// ìë™í™” ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ API
// P0/P1/P2/P3 ì „ì²´ ê¸°ëŠ¥ ìë™ ê²€ì¦
// ============================================

// ì‹œë‚˜ë¦¬ì˜¤ ëª©ë¡ ì¡°íšŒ
analyzerRoutes.get('/test/scenarios', async (c) => {
  const authError = checkAdminAuth(c)
  if (authError) return authError
  const scenarios = getAllScenarioSummary()
  return c.json({
    success: true,
    scenarios,
    total: scenarios.length,
  })
})

// íŠ¹ì • ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
analyzerRoutes.post('/test/run-scenario', async (c) => {
  const authError = checkAdminAuth(c)
  if (authError) return authError
  const env = c.env as Bindings
  const db = env.DB

  const payload = await c.req.json<{ scenario_id: string }>().catch(() => ({ scenario_id: '' }))
  const { scenario_id } = payload

  if (!scenario_id) {
    return c.json({ success: false, error: 'scenario_id required' }, 400)
  }

  const scenario = getScenarioById(scenario_id)
  if (!scenario) {
    return c.json({ success: false, error: `Scenario not found: ${scenario_id}` }, 404)
  }


  try {
    // 1. í…ŒìŠ¤íŠ¸ìš© ì„¸ì…˜ ID ìƒì„±
    const testSessionId = `test_${scenario_id}_${Date.now()}`

    // 2. Mini Module ê¸°ë°˜ ë¶„ì„ ì‹¤í–‰ (V3 Analyze ë¡œì§ ì¬ì‚¬ìš©)
    const miniModule = scenario.miniModule

    // 3. Facts ìƒì„± (Can ê²€ì¦ ë‹µë³€ ê¸°ë°˜)
    const facts: Array<{ fact_key: string; value_json: string }> = []

    // Can ê²€ì¦ ë‹µë³€ì„ factsë¡œ ë³€í™˜
    for (const [questionId, answer] of Object.entries(scenario.canValidationAnswers)) {
      const canToken = questionId.replace('can_', '')
      const canBoostMap: Record<string, number> = {
        'work_experience_3plus': 25,
        'work_experience_1to3': 18,
        'project_experience': 12,
        'study_only': 5,
        'none': 0,
      }
      const boost = canBoostMap[answer] || 5
      facts.push({
        fact_key: `can_verified.${canToken}`,
        value_json: JSON.stringify({ boost, answer }),
      })
    }

    // Risk ê°•ë„ ë‹µë³€ì„ factsë¡œ ë³€í™˜
    for (const [questionId, intensity] of Object.entries(scenario.constraintIntensityAnswers)) {
      facts.push({
        fact_key: `constraint.${questionId.replace('intensity_', '')}.intensity`,
        value_json: JSON.stringify(intensity),
      })
    }

    // 4. ì§ì—… ë°ì´í„° ì¡°íšŒ (jobs í…Œì´ë¸”ê³¼ ì¡°ì¸)
    const jobAttrs = await db.prepare(`
      SELECT
        ja.job_id,
        j.name as job_name,
        j.slug,
        j.image_url,
        j.api_data_json,
        j.merged_profile_json,
        COALESCE(ja.wlb, 50) as wlb,
        COALESCE(ja.growth, 50) as growth,
        COALESCE(ja.stability, 50) as stability,
        COALESCE(ja.income, 50) as income,
        COALESCE(ja.teamwork, 50) as teamwork,
        COALESCE(ja.solo_deep, 50) as solo_deep,
        COALESCE(ja.analytical, 50) as analytical,
        COALESCE(ja.creative, 50) as creative,
        COALESCE(ja.execution, 50) as execution,
        COALESCE(ja.people_facing, 50) as people_facing,
        COALESCE(ja.work_hours, 'normal') as work_hours,
        COALESCE(ja.shift_work, 'rare') as shift_work,
        COALESCE(ja.travel, 'rare') as travel,
        COALESCE(ja.remote_possible, 'possible') as remote_possible,
        COALESCE(ja.degree_required, 'none') as degree_required,
        COALESCE(ja.license_required, 'none') as license_required
      FROM job_attributes ja
      INNER JOIN jobs j ON ja.job_id = j.id
      LIMIT 200
    `).all<{
      job_id: string
      job_name: string
      slug: string | null
      image_url: string | null
      api_data_json: string | null
      merged_profile_json: string | null
      wlb: number
      growth: number
      stability: number
      income: number
      teamwork: number
      solo_deep: number
      analytical: number
      creative: number
      execution: number
      people_facing: number
      work_hours: string
      shift_work: string
      travel: string
      remote_possible: string
      degree_required: string
      license_required: string
    }>()

    if (!jobAttrs.results || jobAttrs.results.length === 0) {
      return c.json({ success: false, error: 'No job data available' }, 500)
    }

    // 5. ì ìˆ˜ ê³„ì‚° (ì „ì²´ íŒŒì´í”„ë¼ì¸ ì ìš©)
    const sampleJobs = jobAttrs.results.map(j => ({
      job_id: j.job_id,
      job_name: j.job_name,
      slug: j.slug || j.job_id,
      image_url: j.image_url,
      job_description: extractJobDescription(j.api_data_json, j.merged_profile_json, j.job_name),
      base_like: Math.round((j.wlb + j.growth + j.stability + j.income) / 4),
      base_can: Math.round((j.teamwork + j.analytical * 0.7 + j.creative) / 3),
      base_risk: 10,
      attributes: {
        wlb: j.wlb,
        growth: j.growth,
        stability: j.stability,
        income: j.income,
        teamwork: j.teamwork,
        solo_deep: j.solo_deep,
        analytical: j.analytical,
        creative: j.creative,
        execution: j.execution,
        people_facing: j.people_facing,
        work_hours: j.work_hours,
        shift_work: j.shift_work,
        travel: j.travel,
        remote_possible: j.remote_possible,
        degree_required: j.degree_required,
        license_required: j.license_required,
      },
    }))

    // Background Feasibility ê³„ì‚° í•¨ìˆ˜ (E2E ì „ìš©: LLM ì—†ì´ ê²°ì •ì  ê³„ì‚°)
    function calculateE2EFeasibility(
      jobAttrs: Record<string, string | number>,
      bgFlags: string[],
      langSkills: Array<{ language: string; level: string }>,
    ): number {
      let score = 60 // ê¸°ë³¸ê°’

      for (const flag of bgFlags) {
        switch (flag) {
          case 'research_academic':
            // ë¶„ì„/ì—°êµ¬ ê´€ë ¨ ì§ì—…ì— ë³´ë„ˆìŠ¤
            score += ((Number(jobAttrs.analytical) || 50) - 50) * 0.3
            break
          case 'license_cert':
            // ìê²©ì¦ í•„ìš” ì§ì—…ì— ë³´ë„ˆìŠ¤, ì•ˆì •ì  ì§ì—…ì—ë„ ì†Œí­ ë³´ë„ˆìŠ¤
            score += (Number(jobAttrs.license_required) || 0) > 50 ? 12 : 0
            score += ((Number(jobAttrs.stability) || 50) - 50) * 0.1
            break
          case 'startup_experience':
            // ì„±ì¥ ë†’ê³  ì•ˆì • ë‚®ì€ ì§ì—…ì— ë³´ë„ˆìŠ¤ (ìŠ¤íƒ€íŠ¸ì—… ì í•©)
            score += ((Number(jobAttrs.growth) || 50) - 50) * 0.2
            score += (50 - (Number(jobAttrs.stability) || 50)) * 0.1
            break
          case 'overseas_living':
            // ì›ê²©/ê¸€ë¡œë²Œ ì§ì—…ì— ë³´ë„ˆìŠ¤
            score += (Number(jobAttrs.remote_possible) || 0) > 50 ? 8 : 0
            score += ((Number(jobAttrs.creative) || 50) - 50) * 0.1
            break
          case 'volunteer_ngo':
            // ì‚¬ëŒ ëŒ€ë©´/ì„íŒ©íŠ¸ ì§ì—…ì— ë³´ë„ˆìŠ¤
            score += ((Number(jobAttrs.people_facing) || 50) - 50) * 0.2
            break
        }
      }

      // ì–¸ì–´ ëŠ¥ë ¥ ë³´ë„ˆìŠ¤
      for (const lang of langSkills) {
        const levelBonus = lang.level === 'native' ? 8 : lang.level === 'business' ? 5 : 2
        score += levelBonus
      }

      return Math.max(35, Math.min(95, Math.round(score)))
    }

    // Mini Module Hard Filter ì ìš©
    const { filtered: filteredJobs } = applyMiniModuleHardFilter(sampleJobs, miniModule)
    const jobsToScore = filteredJobs.length > 0 ? filteredJobs : sampleJobs

    // Fact boosts ê³„ì‚°
    const factBoosts = calculateFactBoosts(facts)

    // Verified Can ì¶”ì¶œ
    const verifiedCan = extractVerifiedCanFromFacts(facts)

    // ì„±ì¥ê³¡ì„  ì„ í˜¸ë„ ì¶”ì¶œ
    const growthPreference = extractGrowthPreference(miniModule)

    // ë‚´ë©´ê°ˆë“± ì‹¬ê°ë„ í™•ì¸
    const conflictSeverity = calculateConflictSeverity(miniModule)

    // ì¶”ì  ë³€ìˆ˜
    let growthCurveApplied = false
    let conflictRiskApplied = false
    let canFilterApplied = false
    let balanceCapApplied = false

    // ê° ì§ì—… ì ìˆ˜ ê³„ì‚°
    const scoredJobs = jobsToScore.map(job => {
      const baseScores: JobScores = {
        like: job.base_like,
        can: job.base_can,
        risk_penalty: job.base_risk,
      }

      // Fact boosts ì ìš©
      const adjusted = applyFactBoostsToJob(baseScores, job.attributes, factBoosts)

      // ì¶”ê°€ í˜ë„í‹° ê³„ì‚°
      let additionalPenalty = 0

      // Mini Module Risk Penalty
      const miniModuleRisk = calculateMiniModuleRiskPenalty(miniModule, job.attributes)
      additionalPenalty += miniModuleRisk.penalty

      // Can ê¸°ë°˜ í•„í„° Penalty
      const canFilterResult = applyCanBasedFilter(job.attributes, verifiedCan)
      additionalPenalty += canFilterResult.totalPenalty
      if (canFilterResult.totalPenalty > 0 || canFilterResult.appliedRules.length > 0) {
        canFilterApplied = true
      }

      // ì„±ì¥ê³¡ì„  ë§¤ì¹­
      const growthMatch = matchGrowthCurves(growthPreference, job.attributes, job.job_name)
      additionalPenalty += growthMatch.riskPenalty
      if (growthMatch.riskPenalty > 0 || growthMatch.likeBoost > 0) {
        growthCurveApplied = true
      }

      // ë‚´ë©´ê°ˆë“± Risk ì¡°ì •
      const conflictRisk = calculateConflictRisk(miniModule, job.attributes)
      additionalPenalty += conflictRisk.totalRiskAdjust
      if (conflictRisk.totalRiskAdjust > 0) {
        conflictRiskApplied = true
      }

      // Likeì— ì„±ì¥ê³¡ì„  ë¶€ìŠ¤íŠ¸ ì ìš©
      const likeWithGrowthBoost = adjusted.like + growthMatch.likeBoost

      // Balance Cap ì ìš©
      const balanced = applyBalanceCap(likeWithGrowthBoost, adjusted.can)
      if (balanced.balance_cap_applied) {
        balanceCapApplied = true
      }

      // Background Feasibility ê³„ì‚°
      const feasibility = calculateE2EFeasibility(
        job.attributes,
        miniModule.background_flags || [],
        miniModule.language_skills || [],
      )

      // ìµœì¢… Fit ê³„ì‚° (LLM Judgeì™€ ë™ì¼í•œ 50/40/10 ê³µì‹)
      const totalRiskPenalty = adjusted.risk_penalty + additionalPenalty
      const fit = Math.round(0.50 * balanced.like + 0.40 * balanced.can + 0.10 * feasibility - totalRiskPenalty)

      return {
        job_id: job.job_id,
        job_name: job.job_name,
        scores: {
          fit: Math.max(0, fit),
          like: balanced.like,
          can: balanced.can,
          risk_penalty: totalRiskPenalty,
          feasibility,
        },
      }
    })

    // ì ìˆ˜ìˆœ ì •ë ¬
    scoredJobs.sort((a, b) => b.scores.fit - a.scores.fit)

    // 6. ê²°ê³¼ ê²€ì¦
    const verificationResult = verifyTestResults(scenario, {
      topJobs: scoredJobs.slice(0, 10),
      excludedJobs: sampleJobs
        .filter(j => !filteredJobs.some(f => f.job_id === j.job_id))
        .slice(0, 10)
        .map(j => ({ job_name: j.job_name, reason: 'Hard Filter' })),
      appliedFeatures: {
        growthCurveApplied,
        conflictRiskApplied,
        canFilterApplied,
        balanceCapApplied,
      },
    })


    // 7. ê²°ê³¼ë¥¼ DBì— ì €ì¥í•˜ì—¬ ê²°ê³¼ í˜ì´ì§€ì—ì„œ ë³¼ ìˆ˜ ìˆë„ë¡
    const top10WithDetails = scoredJobs.slice(0, 10).map(j => {
      const original = sampleJobs.find(s => s.job_id === j.job_id)
      return {
        job_id: j.job_id,
        job_name: j.job_name,
        slug: original?.slug || j.job_id,
        image_url: original?.image_url || null,
        job_description: original?.job_description || null,
        fit_score: j.scores.fit,
        like_score: j.scores.like,
        can_score: j.scores.can,
        risk_penalty: j.scores.risk_penalty,
        feasibility_score: j.scores.feasibility,
        rationale: `${scenario.name} ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ê²°ê³¼`,
      }
    })

    // ë¯¸ë‹ˆëª¨ë“ˆ ê¸°ë°˜ ìš”ì•½ ìƒì„±
    const mm = scenario.miniModule
    const interestLabels = {
      data_numbers: 'ë°ì´í„° ë¶„ì„', problem_solving: 'ë¬¸ì œ í•´ê²°', research: 'ì—°êµ¬',
      creative: 'ì°½ì˜ì  í™œë™', design: 'ë””ìì¸', art: 'ì˜ˆìˆ ',
      helping: 'ì‚¬ëŒ ë•ê¸°', organizing: 'ì¡°ì§/ê´€ë¦¬', routine: 'ì •í•´ì§„ ì—…ë¬´',
      tech: 'ê¸°ìˆ /IT',
    }
    const valueLabels = {
      autonomy: 'ììœ¨ì„±', growth: 'ì„±ì¥', expertise: 'ì „ë¬¸ì„±',
      stability: 'ì•ˆì •', wlb: 'ì›Œë¼ë°¸', income: 'ìˆ˜ì…',
      creativity: 'ì°½ì˜ì„±', recognition: 'ì¸ì •',
    }
    const strengthLabels = {
      analytical: 'ë¶„ì„ë ¥', fast_learning: 'ë¹ ë¥¸ í•™ìŠµ', persistence: 'ëˆê¸°',
      creative: 'ì°½ì˜ì„±', communication: 'ì†Œí†µ', structured_execution: 'ì²´ê³„ì  ì‹¤í–‰',
    }

    const interestStr = (mm.interest_top || []).map(i => interestLabels[i] || i).join(', ')
    const valueStr = (mm.value_top || []).map(v => valueLabels[v] || v).join(', ')
    const strengthStr = (mm.strength_top || []).map(s => strengthLabels[s] || s).join(', ')

    const resultToSave = {
      engine_version: 'v3-test',
      fit_top3: top10WithDetails,
      like_top10: top10WithDetails,
      can_top10: top10WithDetails,
      test_scenario: {
        id: scenario.id,
        name: scenario.name,
        verification: verificationResult,
      },
      // í”„ë¡ íŠ¸ì—”ë“œ ê²°ê³¼ í˜ì´ì§€ í˜¸í™˜ì„ ìœ„í•œ premium_report
      premium_report: {
        executiveSummary: `[í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤: ${scenario.name}] ${scenario.description}`,
        workStyleNarrative: `ë‹¹ì‹ ì€ ${interestStr}ì— ê´€ì‹¬ì´ ìˆê³ , ${valueStr}${ì„ë¥¼(valueStr)} ì¤‘ìš”í•˜ê²Œ ìƒê°í•©ë‹ˆë‹¤. ${strengthStr}${ì´ê°€(strengthStr)} ê°•ì ì…ë‹ˆë‹¤.`,
        lifeVersionStatement: {
          oneLiner: scenario.description,
          expanded: [`í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤: ${scenario.id}`, `ê²€ì¦ ì ìˆ˜: ${verificationResult.score}/100`],
        },
        workStyleMap: {
          socialStyle: mm.workstyle_top?.[0] || 'balanced',
          decisionStyle: mm.execution_style || 'planner',
        },
        innerConflictAnalysis: mm.internal_conflict_flags?.length
          ? `ë‚´ë©´ ê°ˆë“± ê°ì§€: ${mm.internal_conflict_flags.join(', ')}`
          : 'íŠ¹ë³„í•œ ë‚´ë©´ ê°ˆë“±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
        growthCurveType: mm.persistence_anchor === 'growth_anchor' ? 'ë„ì „ ì„±ì¥í˜•' : 'ì•ˆì • ì„±ì¥í˜•',
        growthCurveDescription: mm.persistence_anchor === 'growth_anchor'
          ? 'ì„±ì¥ ì§€í–¥ì ì¸ ì»¤ë¦¬ì–´ íŒ¨ìŠ¤ë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤.'
          : 'ì•ˆì •ì ì¸ ì»¤ë¦¬ì–´ íŒ¨ìŠ¤ë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤.',
        stressProfile: mm.energy_drain_flags?.length
          ? `ì—ë„ˆì§€ ì†Œëª¨ ìš”ì¸: ${mm.energy_drain_flags.join(', ')}`
          : 'íŠ¹ë³„í•œ ìŠ¤íŠ¸ë ˆìŠ¤ ìš”ì¸ì´ ì—†ìŠµë‹ˆë‹¤.',
        stressTriggers: mm.energy_drain_flags || [],
        expertGuidance: {
          doNow: [`${scenario.name} ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ê²€í† í•˜ì„¸ìš”.`],
        },
        jobRecommendations: {
          overallTop5: top10WithDetails.slice(0, 5),
        },
        // í”„ë¡œí•„ í•´ì„ (Quick Testìš©)
        profileInterpretation: {
          interests: (mm.interest_top || []).map((t: string) => ({
            token: t,
            label: interestLabels[t] || t,
            meaning: `${interestLabels[t] || t}ì— ê´€ì‹¬ì´ ìˆìŠµë‹ˆë‹¤.`
          })),
          interests_summary: interestStr ? `ë‹¹ì‹ ì€ ${interestStr}ì— ê´€ì‹¬ì´ ìˆìŠµë‹ˆë‹¤.` : '',
          strengths: (mm.strength_top || []).map((t: string) => ({
            token: t,
            label: strengthLabels[t] || t,
            meaning: (() => { const l = strengthLabels[t] || t; return `${l}${ì´ê°€(l)} ê°•ì ì…ë‹ˆë‹¤.` })()
          })),
          strengths_summary: strengthStr ? `ë‹¹ì‹ ì€ ${strengthStr}ì— ê°•ì ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.` : '',
          values: (mm.value_top || []).map((t: string) => ({
            token: t,
            label: valueLabels[t] || t,
            meaning: (() => { const l = valueLabels[t] || t; return `${l}${ì„ë¥¼(l)} ì¤‘ìš”í•˜ê²Œ ìƒê°í•©ë‹ˆë‹¤.` })()
          })),
          values_summary: valueStr ? `ë‹¹ì‹ ì—ê²Œ ${valueStr}ëŠ” ì¤‘ìš”í•œ ê°€ì¹˜ì…ë‹ˆë‹¤.` : '',
          constraints: (mm.constraint_flags || []).map((t: string) => ({
            token: t,
            label: t,
            meaning: `${t}${ì„ë¥¼(t)} í”¼í•˜ê³  ì‹¶ì–´í•©ë‹ˆë‹¤.`
          })),
          constraints_summary: (() => { const flags = mm.constraint_flags || []; if (!flags.length) return ''; const last = flags[flags.length - 1]; return `ë‹¹ì‹ ì€ ${flags.join(', ')}${ì„ë¥¼(last)} í”¼í•˜ê³  ì‹¶ì–´í•©ë‹ˆë‹¤.` })(),
          overall_profile: `${scenario.name} ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ í”„ë¡œí•„ì…ë‹ˆë‹¤.`
        },
      },
      user_insight: {
        summary: scenario.description,
        traits: [
          { name: 'ê´€ì‹¬ì‚¬', values: mm.interest_top || [] },
          { name: 'ê°€ì¹˜', values: mm.value_top || [] },
          { name: 'ê°•ì ', values: mm.strength_top || [] },
        ],
      },
    }

    let savedRequestId: number | null = null
    try {
      // 1. ë¨¼ì € ai_sessionsì— í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ìƒì„± (ì™¸ë˜ í‚¤ ì œì•½ ì¡°ê±´ ì¶©ì¡±)
      await db.prepare(`
        INSERT OR IGNORE INTO ai_sessions (id, user_identifier, traits_snapshot, created_at, last_active_at)
        VALUES (?, 'test_scenario', ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
      `).bind(testSessionId, JSON.stringify(scenario.miniModule)).run()

      // 2. ai_analysis_requestsì— ì €ì¥ (prompt_payloadëŠ” í•„ìˆ˜)
      const promptPayload = JSON.stringify({
        test_scenario: scenario.id,
        miniModule: scenario.miniModule,
      })
      const insertResult = await db.prepare(`
        INSERT INTO ai_analysis_requests (session_id, analysis_type, pricing_tier, prompt_payload, status, processed_at, requested_at)
        VALUES (?, 'job', 'free', ?, 'completed', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
      `).bind(testSessionId, promptPayload).run()
      savedRequestId = insertResult.meta?.last_row_id as number || null

      if (savedRequestId) {
        // 3. ai_analysis_resultsì— ì €ì¥ (ì‹¤ì œ í”„ë¡œë•ì…˜ ìŠ¤í‚¤ë§ˆ: result_json ì‚¬ìš©)
        await db.prepare(`
          INSERT INTO ai_analysis_results (request_id, result_json, engine_version, created_at)
          VALUES (?, ?, 'v3-test', CURRENT_TIMESTAMP)
        `).bind(savedRequestId, JSON.stringify(resultToSave)).run()
      }
    } catch (saveError) {
    }

    return c.json({
      success: true,
      scenario: {
        id: scenario.id,
        name: scenario.name,
        description: scenario.description,
        category: scenario.category,
      },
      test_session_id: testSessionId,
      request_id: savedRequestId,
      result_page_url: savedRequestId
        ? `/analyzer/job?request_id=${savedRequestId}`
        : null,
      result_api_url: savedRequestId
        ? `/api/ai-analyzer/result/${savedRequestId}`
        : null,
      results: {
        top_jobs: scoredJobs.slice(0, 5).map(j => {
          const original = sampleJobs.find(s => s.job_id === j.job_id)
          return {
            job_id: j.job_id,
            job_name: j.job_name,
            slug: original?.slug || j.job_id,
            image_url: original?.image_url || null,
            fit: j.scores.fit,
            like: j.scores.like,
            can: j.scores.can,
            risk: j.scores.risk_penalty,
          }
        }),
        excluded_count: sampleJobs.length - filteredJobs.length,
        total_scored: scoredJobs.length,
        applied_features: {
          growth_curve: growthCurveApplied,
          conflict_risk: conflictRiskApplied,
          can_filter: canFilterApplied,
          balance_cap: balanceCapApplied,
        },
      },
      verification: verificationResult,
      fact_boosts_applied: factBoosts.applied_rules,
    })

  } catch (error) {
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Test execution failed',
    }, 500)
  }
})

// ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ ì¼ê´„ ì‹¤í–‰
analyzerRoutes.post('/test/run-all', async (c) => {
  const authError = checkAdminAuth(c)
  if (authError) return authError
  const env = c.env as Bindings
  const db = env.DB

  const results: Array<{
    scenario_id: string
    scenario_name: string
    passed: boolean
    score: number
    summary: string
  }> = []

  for (const scenario of TEST_SCENARIOS) {
    try {
      // ê°„ì†Œí™”ëœ í…ŒìŠ¤íŠ¸ (ìœ„ì˜ ë¡œì§ì„ í•¨ìˆ˜ë¡œ ì¶”ì¶œí•´ì„œ ì¬ì‚¬ìš©í•˜ë©´ ë” ì¢‹ìŒ)
      // ì—¬ê¸°ì„œëŠ” ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰ ê²°ê³¼ë§Œ ìš”ì•½
      const testUrl = `/api/ai-analyzer/test/run-scenario`
      // ì‹¤ì œë¡œëŠ” ë‚´ë¶€ í˜¸ì¶œí•˜ê±°ë‚˜ ë¡œì§ ì¬ì‚¬ìš©

      results.push({
        scenario_id: scenario.id,
        scenario_name: scenario.name,
        passed: true,  // ì‹¤ì œ ê²€ì¦ í•„ìš”
        score: 0,      // ì‹¤ì œ ê²€ì¦ í•„ìš”
        summary: `${scenario.name} í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•„ìš”`,
      })
    } catch (error) {
      results.push({
        scenario_id: scenario.id,
        scenario_name: scenario.name,
        passed: false,
        score: 0,
        summary: error instanceof Error ? error.message : 'Failed',
      })
    }
  }

  const passedCount = results.filter(r => r.passed).length
  const totalScore = results.reduce((sum, r) => sum + r.score, 0) / results.length

  return c.json({
    success: true,
    summary: {
      total: results.length,
      passed: passedCount,
      failed: results.length - passedCount,
      average_score: totalScore.toFixed(1),
    },
    results,
  })
})

// ============================================
// E2E í…ŒìŠ¤íŠ¸ìš© LLM ë‹µë³€ ìƒì„± ì—”ë“œí¬ì¸íŠ¸
// ============================================
analyzerRoutes.post('/test/generate-answer', async (c) => {
  const authError = checkAdminAuth(c)
  if (authError) return authError
  const env = c.env as Bindings
  const openaiKey = env.OPENAI_API_KEY

  if (!openaiKey) {
    return c.json({ success: false, error: 'OPENAI_API_KEY not configured' }, 500)
  }

  try {
    const body = await c.req.json() as {
      question: string
      round: number
      persona: {
        name: string
        career_state: string
        interests: string[]
        strengths: string[]
        values: string[]
        constraints: string[]
        narrative_context?: string
      }
      previous_answers?: string[]
    }

    const { question, round, persona, previous_answers = [] } = body

    if (!question || !persona) {
      return c.json({ success: false, error: 'Missing question or persona' }, 400)
    }

    // í˜ë¥´ì†Œë‚˜ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    const personaContext = `
ë‹¹ì‹ ì€ ë‹¤ìŒê³¼ ê°™ì€ í”„ë¡œí•„ì„ ê°€ì§„ êµ¬ì§ìì…ë‹ˆë‹¤:
- ì´ë¦„: ${persona.name}
- í˜„ì¬ ìƒíƒœ: ${persona.career_state === 'employed' ? 'ì¬ì§ ì¤‘' : persona.career_state === 'job_seeker' ? 'êµ¬ì§ ì¤‘' : persona.career_state === 'student' ? 'í•™ìƒ' : 'ì´ì§ ê³ ë ¤ ì¤‘'}
- ê´€ì‹¬ ë¶„ì•¼: ${persona.interests?.join(', ') || 'ë‹¤ì–‘í•œ ë¶„ì•¼'}
- ê°•ì : ${persona.strengths?.join(', ') || 'ë¶„ì„ë ¥, ë¬¸ì œí•´ê²°'}
- ì¤‘ìš” ê°€ì¹˜: ${persona.values?.join(', ') || 'ì„±ì¥, ì•ˆì •'}
- í”¼í•˜ê³  ì‹¶ì€ ê²ƒ: ${persona.constraints?.join(', ') || 'ì•¼ê·¼, ë¶ˆê·œì¹™í•œ ê·¼ë¬´'}
${persona.narrative_context ? `\nì¶”ê°€ ë°°ê²½:\n${persona.narrative_context}` : ''}
`.trim()

    // ë¼ìš´ë“œë³„ ë‹µë³€ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ
    const roundGuide = round === 1
      ? 'ìš•ë§ê³¼ ëª©í‘œì— ëŒ€í•´ ì†”ì§í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”. ë¬´ì—‡ì„ ì›í•˜ëŠ”ì§€, ì–´ë–¤ ë¯¸ë˜ë¥¼ ê¿ˆê¾¸ëŠ”ì§€.'
      : round === 2
      ? 'í”¼í•˜ê³  ì‹¶ì€ ê²ƒ, ìŠ¤íŠ¸ë ˆìŠ¤ ìš”ì¸ì— ëŒ€í•´ ë‹µë³€í•˜ì„¸ìš”. ì–´ë–¤ í™˜ê²½ì´ ë§ì§€ ì•ŠëŠ”ì§€.'
      : 'í˜„ì‹¤ì  ì œì•½ê³¼ íƒ€í˜‘ì ì— ëŒ€í•´ ë‹µë³€í•˜ì„¸ìš”. ì„±ì¥ì„ ìœ„í•´ ë¬´ì—‡ì„ ê°ìˆ˜í•  ìˆ˜ ìˆëŠ”ì§€.'

    const systemPrompt = `${personaContext}

ì»¤ë¦¬ì–´ ìƒë‹´ì‚¬ì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
ë¼ìš´ë“œ ${round}: ${roundGuide}

ë‹µë³€ ê·œì¹™:
1. 1~3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
2. í˜ë¥´ì†Œë‚˜ì˜ íŠ¹ì„±ì— ë§ê²Œ ì¼ê´€ì„± ìˆê²Œ ë‹µë³€í•˜ì„¸ìš”
3. êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ê²½í—˜ì„ ì–¸ê¸‰í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤
4. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ì„¸ìš”`

    const messages: Array<{ role: 'system' | 'user' | 'assistant', content: string }> = [
      { role: 'system', content: systemPrompt }
    ]

    // ì´ì „ ë‹µë³€ë“¤ì„ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
    if (previous_answers.length > 0) {
      messages.push({
        role: 'user',
        content: `ì´ì „ ë‹µë³€ë“¤:\n${previous_answers.map((a, i) => `${i + 1}. ${a}`).join('\n')}`
      })
    }

    messages.push({ role: 'user', content: `ì§ˆë¬¸: ${question}` })

    // OpenAI í˜¸ì¶œ
    const response = await fetch('https://gateway.ai.cloudflare.com/v1/3587865378649966bfb0a814fce73c77/careerwiki/openai/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${openaiKey}`,
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages,
        temperature: 0.8,
        max_tokens: 200,
      }),
    })

    if (!response.ok) {
      const error = await response.text()
      return c.json({ success: false, error: 'OpenAI API error' }, 500)
    }

    const data = await response.json() as {
      choices: Array<{ message: { content: string } }>
      usage: { total_tokens: number }
    }

    const answer = data.choices[0]?.message?.content?.trim() || ''


    return c.json({
      success: true,
      answer,
      usage: data.usage,
    })
  } catch (error) {
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error',
    }, 500)
  }
})

// ============================================
// ê³µìœ  ê¸°ëŠ¥: í† í° ìƒì„± / í•´ì œ / extractShareData
// ============================================

// HTML escape (XSS ë°©ì§€)
function escapeHtml(s: string): string {
  return s.replace(/&/g, '&amp;').replace(/</g, '&lt;').replace(/>/g, '&gt;')
          .replace(/"/g, '&quot;').replace(/'/g, '&#39;')
}

// ë¬¸ìì—´ ì•ˆì „ ì ˆë‹¨ + HTML escape
const safeStr = (s: any, maxLen = 50): string =>
  typeof s === 'string' ? escapeHtml(s.slice(0, maxLen)) : ''
const safeArr = (arr: any, maxItems = 3, maxLen = 20): string[] =>
  Array.isArray(arr) ? arr.slice(0, maxItems).map((s: any) => safeStr(s, maxLen)) : []

// nanoid ëŒ€ì²´: crypto ê¸°ë°˜ 16ì í† í° ìƒì„±
function generateShareToken(): string {
  const bytes = new Uint8Array(12)
  crypto.getRandomValues(bytes)
  return Array.from(bytes).map(b => b.toString(36).padStart(2, '0')).join('').slice(0, 16)
}

interface ShareData {
  v: number
  type?: 'job' | 'major'
  jobs: Array<{ name: string; fit: number; slug: string; image_url?: string }>
  vision: string
  meta: {
    strengths: string[]
    values: string[]
    cautions: string[]
    likes: string[]
    avoid: string[]
  }
  createdAt: string
}

function extractShareData(
  resultJson: any,
  premiumReport: any,
  analysisType: string = 'job',
): ShareData {
  // í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸: ì´ í•¨ìˆ˜ ë°–ì˜ ë°ì´í„°ëŠ” ì ˆëŒ€ ê³µìœ  í˜ì´ì§€ì— ë„ë‹¬ ë¶ˆê°€
  const isMajor = analysisType === 'major'
  const sourceList = isMajor
    ? (resultJson.fit_top_majors || resultJson.fit_top3 || resultJson.recommendations || [])
    : (resultJson.fit_top3 || [])
  const top5 = sourceList.slice(0, 5).map((j: any) => ({
    name: safeStr(j.major_name || j.name || j.job_name, 30),
    fit: Math.min(100, Math.max(0, Math.round(Number(j.fit_score || j.final_score) || 0))),
    slug: safeStr(j.slug, 60),
    ...(j.image_url ? { image_url: safeStr(j.image_url, 200) } : {}),
  }))

  const vision = safeStr(premiumReport?.lifeVersionStatement?.oneLiner, 200)

  const mm = resultJson.mini_module_result || {}
  const meta = {
    strengths: safeArr(mm.strength_top, 3, 30),
    values: safeArr(mm.value_top, 3, 30),
    cautions: safeArr(premiumReport?.stressTriggers, 3, 60),
    likes: safeArr(mm.interest_top, 3, 30),
    avoid: safeArr(mm.dealbreaker || mm.constraint_flags, 3, 60),
  }

  return { v: 1, type: isMajor ? 'major' : 'job', jobs: top5, vision, meta, createdAt: new Date().toISOString().split('T')[0] }
}

// POST /share - ê³µìœ  í† í° ìƒì„±/ì¬ë°œê¸‰
analyzerRoutes.post('/share', async (c) => {
  const db = c.env.DB
  const authUser = (c as any).get('user') as { id: number } | null

  if (!authUser) {
    return c.json({ success: false, error: 'Login required' }, 401)
  }

  const userId = String(authUser.id)
  const body = await c.req.json<{ request_id: number }>().catch(() => ({ request_id: 0 }))
  const { request_id } = body

  if (!request_id || isNaN(request_id)) {
    return c.json(createErrorResponse('VALIDATION_ERROR', 'Valid request_id required'), 400)
  }

  try {
    // 1. ë³¸ì¸ ê²°ê³¼ì¸ì§€ í™•ì¸
    const request = await db.prepare(`
      SELECT id, user_id, analysis_type FROM ai_analysis_requests WHERE id = ?
    `).bind(request_id).first<{ id: number; user_id: string; analysis_type: string }>()

    if (!request) {
      return c.json(createErrorResponse('REQUEST_NOT_FOUND', 'Analysis request not found'), 404)
    }

    // ë³¸ì¸ ê²°ê³¼ì´ê±°ë‚˜ adminì´ë©´ í—ˆìš© (E2E í…ŒìŠ¤íŠ¸ ê²°ê³¼ëŠ” user_idê°€ NULL)
    const authRole = (c as any).get('user')?.role as string | undefined
    const isAdmin = authRole === 'admin' || authRole === 'super-admin' || authRole === 'operator'
    if (!isAdmin && request.user_id && String(request.user_id) !== userId) {
      return c.json({ success: false, error: 'Not your result' }, 403)
    }

    // 2. ê¸°ì¡´ í† í° í™•ì¸ (request_id UNIQUEì´ë¯€ë¡œ ìµœëŒ€ 1ê°œ)
    const existing = await db.prepare(`
      SELECT share_token, is_revoked, expires_at
      FROM share_tokens WHERE request_id = ?
    `).bind(request_id).first<{ share_token: string; is_revoked: number; expires_at: string }>()

    if (existing && !existing.is_revoked && existing.expires_at && new Date(existing.expires_at) > new Date()) {
      // í™œì„± í† í° ì¬ì‚¬ìš©
      return c.json({
        success: true,
        share_url: `https://careerwiki.org/share/${existing.share_token}`,
        token: existing.share_token,
        reused: true,
      })
    }

    // 3. ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (share_data_json ìƒì„±ìš©)
    const analysisResult = await db.prepare(`
      SELECT result_json, premium_report_json
      FROM ai_analysis_results WHERE request_id = ?
    `).bind(request_id).first<{ result_json: string; premium_report_json: string | null }>()

    if (!analysisResult) {
      return c.json(createErrorResponse('RESULT_NOT_FOUND', 'Analysis result not found'), 404)
    }

    const resultJson = JSON.parse(analysisResult.result_json)
    const premiumReport = analysisResult.premium_report_json
      ? JSON.parse(analysisResult.premium_report_json)
      : null

    const shareData = extractShareData(resultJson, premiumReport, request.analysis_type)
    const shareDataJson = JSON.stringify(shareData)

    // 4. í† í° ìƒì„± (UNIQUE ì¶©ëŒ ìµœëŒ€ 2íšŒ ì¬ì‹œë„)
    let token = ''
    let saved = false

    for (let attempt = 0; attempt < 3; attempt++) {
      token = generateShareToken()

      try {
        if (existing) {
          // revoked/expired â†’ UPDATE ì¬ë°œê¸‰
          await db.prepare(`
            UPDATE share_tokens SET
              share_token = ?,
              share_data_json = ?,
              is_revoked = 0,
              revoked_at = NULL,
              expires_at = datetime('now', '+30 days'),
              view_count = 0,
              created_at = CURRENT_TIMESTAMP
            WHERE request_id = ? AND user_id = ?
          `).bind(token, shareDataJson, request_id, userId).run()
        } else {
          // ì‹ ê·œ INSERT
          await db.prepare(`
            INSERT INTO share_tokens (share_token, request_id, user_id, share_data_json, expires_at)
            VALUES (?, ?, ?, ?, datetime('now', '+30 days'))
          `).bind(token, request_id, userId, shareDataJson).run()
        }
        saved = true
        break
      } catch (e) {
        // UNIQUE ì¶©ëŒì´ë©´ ì¬ì‹œë„
        const msg = e instanceof Error ? e.message : ''
        if (msg.includes('UNIQUE') && attempt < 2) continue
        throw e
      }
    }

    if (!saved) {
      return c.json(createErrorResponse('INTERNAL_ERROR', 'Failed to generate unique token'), 500)
    }


    return c.json({
      success: true,
      share_url: `https://careerwiki.org/share/${token}`,
      token,
      reused: false,
    })

  } catch (error) {
    return c.json(createErrorResponse(
      'DB_ERROR',
      error instanceof Error ? error.message : 'Share creation failed'
    ), 500)
  }
})

// POST /share/revoke - ê³µìœ  í•´ì œ
analyzerRoutes.post('/share/revoke', async (c) => {
  const db = c.env.DB
  const authUser = (c as any).get('user') as { id: number } | null

  if (!authUser) {
    return c.json({ success: false, error: 'Login required' }, 401)
  }

  const userId = String(authUser.id)
  const body = await c.req.json<{ request_id?: number; token?: string }>().catch(() => ({}))

  try {
    let result
    if (body.token) {
      result = await db.prepare(`
        UPDATE share_tokens SET is_revoked = 1, revoked_at = CURRENT_TIMESTAMP
        WHERE share_token = ? AND user_id = ?
      `).bind(body.token, userId).run()
    } else if (body.request_id) {
      result = await db.prepare(`
        UPDATE share_tokens SET is_revoked = 1, revoked_at = CURRENT_TIMESTAMP
        WHERE request_id = ? AND user_id = ?
      `).bind(body.request_id, userId).run()
    } else {
      return c.json(createErrorResponse('VALIDATION_ERROR', 'request_id or token required'), 400)
    }

    const changes = result.meta?.changes || 0

    return c.json({ success: true, revoked: changes > 0 })

  } catch (error) {
    return c.json(createErrorResponse('DB_ERROR', 'Revoke failed'), 500)
  }
})

// GET /share/status/:requestId - ê³µìœ  ìƒíƒœ í™•ì¸ (ê²°ê³¼ í˜ì´ì§€ì—ì„œ ì‚¬ìš©)
analyzerRoutes.get('/share/status/:requestId', async (c) => {
  const db = c.env.DB
  const authUser = (c as any).get('user') as { id: number } | null

  if (!authUser) {
    return c.json({ success: false, error: 'Login required' }, 401)
  }

  const userId = String(authUser.id)
  const requestId = parseInt(c.req.param('requestId'), 10)

  if (isNaN(requestId)) {
    return c.json(createErrorResponse('VALIDATION_ERROR', 'Invalid request_id'), 400)
  }

  try {
    const existing = await db.prepare(`
      SELECT share_token, is_revoked, expires_at, view_count, created_at
      FROM share_tokens WHERE request_id = ? AND user_id = ?
    `).bind(requestId, userId).first<{
      share_token: string
      is_revoked: number
      expires_at: string
      view_count: number
      created_at: string
    }>()

    if (!existing) {
      return c.json({ success: true, shared: false })
    }

    const isActive = !existing.is_revoked && existing.expires_at && new Date(existing.expires_at) > new Date()

    return c.json({
      success: true,
      shared: isActive,
      token: isActive ? existing.share_token : null,
      share_url: isActive ? `https://careerwiki.org/share/${existing.share_token}` : null,
      view_count: existing.view_count,
      created_at: existing.created_at,
      is_revoked: !!existing.is_revoked,
    })
  } catch (error) {
    return c.json(createErrorResponse('DB_ERROR', 'Status check failed'), 500)
  }
})

// ============================================
// V3 Major Recommendation: ì „ê³µ ì¶”ì²œ íŒŒì´í”„ë¼ì¸
// /v3/recommendì˜ ì „ê³µ ë²„ì „ â€” ëª¨ë“  ë‹¨ê³„ê°€ major ì „ìš© í•¨ìˆ˜ ì‚¬ìš©
// ============================================
analyzerRoutes.post('/v3/recommend-major', async (c) => {
  const env = c.env as Bindings
  const db = env.DB
  const openaiApiKey = c.env.OPENAI_API_KEY
  const payload = await c.req.json<any>()

  const authUser = c.get('user') as { id: number } | undefined
  const userId = authUser?.id || null

  const { session_id, draft_id, topK = 800, judgeTopN = 20, debug = false, skipReport = false } = payload

  if (!session_id) {
    return c.json(createErrorResponse('VALIDATION_ERROR', 'session_id is required'), 400)
  }
  if (!openaiApiKey) {
    return c.json(createErrorResponse('INTERNAL_ERROR', 'OpenAI API key not configured'), 500)
  }

  try {
    const startTime = Date.now()

    // 1. SearchProfile í™•ì • (job ë²„ì „ê³¼ ë™ì¼ ë¡œì§)
    let searchProfile = payload.searchProfile

    if (!searchProfile && draft_id) {
      const draft = await db.prepare(
        `SELECT * FROM ai_analysis_drafts WHERE id = ?`
      ).bind(draft_id).first<any>()

      if (draft) {
        const aggregated = buildAggregatedProfile(draft)
        searchProfile = {
          desiredThemes: [...aggregated.anchors.interest_top, ...aggregated.anchors.value_top],
          dislikedThemes: aggregated.universals.dislikes || [],
          strengthsHypothesis: aggregated.anchors.strength_top,
          environmentPreferences: [],
          hardConstraints: aggregated.anchors.constraint_flags,
          riskSignals: [],
          keywords: [...aggregated.anchors.interest_top, ...aggregated.anchors.strength_top],
        }
      }
    }

    if (!searchProfile && payload.mini_module_result) {
      searchProfile = buildSearchProfileFromMiniModule(payload.mini_module_result)
    }

    if (!searchProfile) {
      return c.json(createErrorResponse('VALIDATION_ERROR', 'searchProfile or draft_id or mini_module_result required'), 400)
    }

    // 2. Vectorize ê²€ìƒ‰ (ì „ê³µ ì „ìš© â€” major: prefixë§Œ í¬í•¨)
    let vectorSearchProfile = searchProfile
    if (payload.mini_module_result) {
      vectorSearchProfile = buildSearchProfileFromMiniModule(payload.mini_module_result)
    }

    const expansionResult = await expandCandidatesV3ForMajors(
      db,
      env.VECTORIZE,
      openaiApiKey,
      vectorSearchProfile,
      {
        targetSize: topK,
        miniModule: payload.mini_module_result,
      }
    )

    // 3. TAG Hard Filter (ì „ê³µ ì „ìš©)
    const constraintMap: Record<string, string | string[]> = {}
    for (const c of (payload.mini_module_result?.constraint_flags || [])) {
      constraintMap[c] = 'true'
    }
    const majorUserConstraints = extractMajorUserConstraints(constraintMap)

    let tagFilterResult
    try {
      tagFilterResult = await applyMajorTagFilter(db, expansionResult.candidates, majorUserConstraints)
    } catch (tagError) {
      throw tagError
    }

    // 3-2. í•„í„° í†µê³¼í•œ í›„ë³´ë¥¼ ScoredMajorë¡œ ë³€í™˜
    const tagPassedAsVectorResults = tagFilterResult.passed.map((p: any) => ({
      major_id: p.major_id,
      major_name: p.major_name,
      score: p.score,
    }))

    let scoredMajors
    try {
      scoredMajors = await vectorResultsToScoredMajors(db, tagPassedAsVectorResults, payload.mini_module_result)
    } catch (scoreError) {
      throw scoreError
    }

    // 3-3. MiniModule Hard Filter (ì „ê³µ ì „ìš©)
    let filteredMajors = scoredMajors
    try {
      const mmResult = applyMajorMiniModuleHardFilter(scoredMajors, payload.mini_module_result)
      filteredMajors = mmResult.filtered
    } catch (mmError) {
      // MiniModule í•„í„° ì‹¤íŒ¨ ì‹œ ì›ë³¸ ìœ ì§€
    }

    // 4. ì•„í‚¤íƒ€ì… ì „ê³µ ì£¼ì… (ë²¡í„° ê²€ìƒ‰ ë¯¸ìŠ¤ ëŒ€ë¹„)
    const existingMajorIdSet = new Set<string | number>(filteredMajors.map(m => m.major_id))
    const mmInterests = (payload.mini_module_result?.interest_top || []) as string[]
    try {
      const injectedMajors = await injectArchetypeMajors(
        db, existingMajorIdSet, mmInterests
      )
      filteredMajors = [...filteredMajors, ...injectedMajors]
    } catch (injErr) {
      // ì£¼ì… ì‹¤íŒ¨ ì‹œ ì›ë³¸ ìœ ì§€
    }

    // 4-1. Diversity Guard (ê°™ì€ field_category 3ê°œ ì´í•˜)
    const diversityResult = enforceMajorDiversity(filteredMajors)
    filteredMajors = diversityResult.diversified

    // 4-2. ì‚¬ì „ í•„í„°ëœ ìƒìœ„ í›„ë³´êµ° (Like/Can/Final 3ì¶• ë¶„ë¦¬)
    const likeBiased = [...filteredMajors]
      .sort((a, b) => (b.like_score || 0) - (a.like_score || 0))
      .slice(0, 20)
    const canBiased = [...filteredMajors]
      .sort((a, b) => (b.can_score || 0) - (a.can_score || 0))
      .slice(0, 20)
    const finalBiased = [...filteredMajors]
      .sort((a, b) => (b.final_score || 0) - (a.final_score || 0))
      .slice(0, 20)

    const preFilterIdSet = new Set<string>()
    const preFilteredMajors: typeof filteredMajors = []
    for (const major of [...likeBiased, ...canBiased, ...finalBiased]) {
      const id = String(major.major_id)
      if (!preFilterIdSet.has(id)) {
        preFilterIdSet.add(id)
        preFilteredMajors.push(major)
      }
    }

    // ScoredMajor â†’ FilteredMajorCandidate ë³€í™˜
    const candidatesForJudge = preFilteredMajors.map(major => ({
      major_id: major.major_id,
      major_name: major.major_name,
      score: major.final_score || major.like_score || 0,
      riskPenalty: major.risk_penalty || 0,
      riskWarnings: [] as string[],
      tagSource: (major.tag_source || 'tagged') as 'tagged' | 'untagged',
      attributes: major.attributes,
    }))

    // 5. LLM Judge (ì „ê³µ ì „ìš©)
    let topMajors: any[]

    if (openaiApiKey && candidatesForJudge.length > 0) {
      try {
        const judgeInput: MajorJudgeInput = {
          candidates: candidatesForJudge,
          searchProfile,
          miniModuleResult: payload.mini_module_result,
          academicState: payload.academic_state,
        }

        const judgeResults = await judgeMajorCandidates(openaiApiKey, db, judgeInput)

        topMajors = judgeResults.results.map(result => {
          const originalMajor = preFilteredMajors.find(m => String(m.major_id) === String(result.major_id))
          return {
            ...originalMajor,
            major_id: result.major_id,
            major_name: result.major_name,
            like_score: result.desireScore,
            can_score: result.fitScore,
            fit_score: result.overallScore,
            final_score: result.overallScore,
            risk_penalty: result.riskPenalty,
            feasibility_score: result.feasibilityScore,
            rationale: result.rationale,
            like_reason: result.likeReason,
            can_reason: result.canReason,
            risk_reason: result.riskReason,
            evidence_quotes: result.evidenceQuotes,
            semester_plan: result.semesterPlan,
          }
        })
      } catch (judgeError) {
        const errorMessage = judgeError instanceof Error ? judgeError.message : String(judgeError)
        return c.json(createErrorResponse(
          'ANALYSIS_FAILED',
          `ì „ê³µ LLM ë¶„ì„ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ${errorMessage}`
        ), 500)
      }
    } else {
      return c.json(createErrorResponse('INTERNAL_ERROR', 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'), 500)
    }

    // 6. LLM Reporter (ì „ê³µ ì „ìš© â€” skipReport ì‹œ ê±´ë„ˆëœ€)
    let premiumReport: any = null
    let reportMode: 'llm' | 'fallback' | 'none' | 'deferred' = skipReport ? 'deferred' : 'none'
    let narrativeFacts: { highAliveMoment: string; lostMoment: string; existentialAnswer?: string } | undefined
    let roundAnswers: RoundAnswer[] = []

    if (!skipReport) {
      const [narrativeResult, roundAnswersResult] = await Promise.allSettled([
        db.prepare(`SELECT high_alive_moment, lost_moment, existential_answer FROM narrative_facts WHERE session_id = ?`)
          .bind(session_id).first<{ high_alive_moment: string | null; lost_moment: string | null; existential_answer: string | null }>(),
        db.prepare(`SELECT round_number, question_id, answer FROM round_answers WHERE session_id = ? ORDER BY round_number, question_id`)
          .bind(session_id).all<{ round_number: number; question_id: string; answer: string }>(),
      ])

      if (narrativeResult.status === 'fulfilled' && narrativeResult.value) {
        const row = narrativeResult.value
        if (row.high_alive_moment || row.lost_moment) {
          narrativeFacts = {
            highAliveMoment: row.high_alive_moment || '',
            lostMoment: row.lost_moment || '',
            existentialAnswer: row.existential_answer || undefined,
          }
        }
      }
      if (roundAnswersResult.status === 'fulfilled' && roundAnswersResult.value?.results?.length) {
        roundAnswers = roundAnswersResult.value.results.map(r => ({
          roundNumber: r.round_number as 1 | 2 | 3,
          questionId: r.question_id,
          answer: r.answer,
          answeredAt: new Date().toISOString(),
        }))
      }

      if (openaiApiKey && topMajors.length > 0) {
        try {
          const topMajorsForReporter = [...topMajors]
            .sort((a, b) => (b.final_score || 0) - (a.final_score || 0))
            .slice(0, judgeTopN)

          const reporterInput: MajorReporterInput = {
            sessionId: session_id,
            judgeResults: topMajorsForReporter.map((major: any) => ({
              major_id: major.major_id,
              major_name: major.major_name,
              fitScore: major.can_score || 50,
              desireScore: major.like_score || 50,
              feasibilityScore: major.feasibility_score || 50,
              overallScore: major.final_score || 50,
              riskFlags: [],
              riskPenalty: major.risk_penalty || 0,
              evidenceQuotes: major.evidence_quotes || [],
              rationale: major.rationale || '',
              likeReason: major.like_reason,
              canReason: major.can_reason,
              riskReason: major.risk_reason,
              semesterPlan: major.semester_plan,
            })),
            searchProfile,
            narrativeFacts,
            roundAnswers,
            universalAnswers: {},
            hardCutList: [],
            miniModuleResult: payload.mini_module_result,
          }

          premiumReport = await generateMajorPremiumReport(
            env?.AI || null,
            reporterInput,
            openaiApiKey
          )
          reportMode = 'llm'
        } catch (reporterError) {
          reportMode = 'fallback'
          premiumReport = { error: 'Reporter failed', fallback: true }
        }
      }
    }

    // 7. ê²°ê³¼ êµ¬ì„±
    const majorToDto = (major: any) => ({
      major_id: major.major_id,
      major_name: major.major_name,
      major_description: major.major_description || null,
      slug: major.slug || null,
      image_url: major.image_url || null,
      fit_score: major.final_score || major.fit_score || 50,
      like_score: major.like_score || 50,
      can_score: major.can_score || 50,
      feasibility_score: major.feasibility_score || 0,
      field_category: major.field_category || major.attributes?.field_category || null,
      rationale: major.rationale || null,
      like_reason: major.like_reason || null,
      can_reason: major.can_reason || null,
      risk_reason: major.risk_reason || null,
      semester_plan: major.semester_plan || [],
    })

    // Like/Can Top 10 (field_category ë‹¤ì–‘ì„± ì ìš©)
    const diverseMajorTop10 = (majors: any[], scoreKey: 'like_score' | 'can_score', maxPerCategory = 3) => {
      const sorted = [...majors]
        .filter(m => (m.final_score || 0) >= 25)
        .sort((a, b) => (b[scoreKey] || 0) - (a[scoreKey] || 0))

      const result: any[] = []
      const selectedIds = new Set<string>()
      const categoryCount = new Map<string, number>()

      for (const major of sorted) {
        if (result.length >= 10) break
        const cat = major.field_category || major.attributes?.field_category || 'general'
        const count = categoryCount.get(cat) || 0
        if (count >= maxPerCategory) continue
        result.push(major)
        selectedIds.add(String(major.major_id))
        categoryCount.set(cat, count + 1)
      }

      if (result.length < 10) {
        for (const major of sorted) {
          if (result.length >= 10) break
          if (selectedIds.has(String(major.major_id))) continue
          result.push(major)
          selectedIds.add(String(major.major_id))
        }
      }

      return result
    }

    const likeTop10 = diverseMajorTop10(topMajors, 'like_score').map(majorToDto)
    const canTop10 = diverseMajorTop10(topMajors, 'can_score').map(majorToDto)

    const fitTop10 = [...topMajors]
      .sort((a, b) => (b.final_score || 0) - (a.final_score || 0))
      .slice(0, 10)
      .map(majorToDto)

    // 8. DB ì €ì¥ (analysis_type='major')
    let savedRequestId: number | null = null
    try {
      let effectiveUserId = userId
      if (!effectiveUserId) {
        const draftOwner = await db.prepare(`SELECT user_id FROM analyzer_drafts WHERE session_id = ?`)
          .bind(session_id).first<{ user_id: number | null }>()
        effectiveUserId = draftOwner?.user_id || null
      }

      const existingRequest = await db.prepare(`SELECT id FROM ai_analysis_requests WHERE session_id = ? AND analysis_type = 'major'`)
        .bind(session_id).first<{ id: number }>()

      if (existingRequest) {
        savedRequestId = existingRequest.id
        await db.prepare(`UPDATE ai_analysis_requests SET status = 'completed', processed_at = CURRENT_TIMESTAMP, user_id = COALESCE(user_id, ?) WHERE id = ?`)
          .bind(effectiveUserId, savedRequestId).run()
      } else {
        const insertResult = await db.prepare(`INSERT INTO ai_analysis_requests (session_id, user_id, analysis_type, status, processed_at, created_at) VALUES (?, ?, 'major', 'completed', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)`)
          .bind(session_id, effectiveUserId).run()
        savedRequestId = insertResult.meta?.last_row_id as number || null
      }

      if (savedRequestId) {
        const resultToSave = {
          engine_version: RECOMMENDATION_ENGINE_VERSION,
          analysis_type: 'major',
          mini_module_result: payload.mini_module_result || null,
          fit_top_majors: fitTop10,
          like_top10: likeTop10,
          can_top10: canTop10,
          premium_report: premiumReport,
          search_profile: searchProfile,
          total_candidates: expansionResult.candidates.length,
          filtered_count: filteredMajors.length,
        }

        const resultJson = JSON.stringify(resultToSave)
        const premiumJson = JSON.stringify(premiumReport)

        const updateResult = await db.prepare(`UPDATE ai_analysis_results SET result_json = ?, engine_version = ?, premium_report_json = ? WHERE request_id = ?`)
          .bind(resultJson, RECOMMENDATION_ENGINE_VERSION, premiumJson, savedRequestId).run()

        if (!updateResult.meta?.changes || updateResult.meta.changes === 0) {
          await db.prepare(`INSERT INTO ai_analysis_results (request_id, result_json, engine_version, premium_report_json, created_at) VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)`)
            .bind(savedRequestId, resultJson, RECOMMENDATION_ENGINE_VERSION, premiumJson).run()
        }
      }
    } catch (saveError) {
      console.error('[recommend-major] Result save failed:', saveError)
    }

    // 9. ì‘ë‹µ ë°˜í™˜
    const duration = Date.now() - startTime
    return c.json({
      success: true,
      mode: 'major_recommendation',
      session_id,
      request_id: savedRequestId,
      recommendations: {
        top_majors: topMajors.map(majorToDto),
        fit_top10: fitTop10,
        like_top10: likeTop10,
        can_top10: canTop10,
        total_candidates: expansionResult.candidates.length,
        filtered_count: filteredMajors.length,
        search_duration_ms: expansionResult.search_duration_ms,
      },
      premium_report: premiumReport,
      engine_version: RECOMMENDATION_ENGINE_VERSION,
      report_mode: reportMode,
      search_profile_used: searchProfile,
      debug_info: debug ? {
        vectorize_topK: topK,
        judge_topN: judgeTopN,
        fallback_used: expansionResult.fallback_used,
        has_narrative_facts: !!narrativeFacts,
        round_answers_count: roundAnswers.length,
      } : undefined,
      duration_ms: duration,
    })

  } catch (error) {
    return c.json(createErrorResponse(
      'ANALYSIS_FAILED',
      error instanceof Error ? `${error.message} | ${error.stack?.split('\n')[1] || ''}` : 'Major recommendation failed'
    ), 500)
  }
})

// ============================================
// ì €ì¥ëœ ê²°ê³¼ ì¡°íšŒ API (ë¦¬í¬íŠ¸ ë·°ì–´ìš©)
// ============================================
// ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ë¥¼ displayResults() í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ (ë¦¬í¬íŠ¸ ë·°ìš©)
analyzerRoutes.get('/saved-result/:requestId', async (c) => {
  const requestId = parseInt(c.req.param('requestId'), 10)
  if (!requestId || isNaN(requestId)) {
    return c.json({ error: 'Invalid request_id' }, 400)
  }

  try {
    const row = await c.env.DB.prepare(`
      SELECT r.result_json, r.premium_report_json, r.confidence_score,
             req.id as request_id, req.analysis_type, r.engine_version
      FROM ai_analysis_results r
      JOIN ai_analysis_requests req ON r.request_id = req.id
      WHERE req.id = ?
    `).bind(requestId).first<{
      result_json: string
      premium_report_json: string | null
      confidence_score: number | null
      request_id: number
      analysis_type: string
      engine_version: string | null
    }>()

    if (!row) {
      return c.json({ error: 'Result not found' }, 404)
    }

    let result: any = {}
    try { result = JSON.parse(row.result_json) } catch {}

    let premiumReport: any = null
    if (row.premium_report_json) {
      try { premiumReport = JSON.parse(row.premium_report_json) } catch {}
    }

    // premium_reportë¥¼ resultì— ë³‘í•© (displayResultsê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹)
    if (premiumReport) {
      result.premium_report = premiumReport
    } else if (result.premium_report) {
      // result_json ë‚´ë¶€ì— premium_reportê°€ í¬í•¨ëœ ê²½ìš° (premium_report_json ì»¬ëŸ¼ì´ nullì¼ ë•Œ)
      premiumReport = result.premium_report
    }
    if (row.engine_version) {
      result.engine_version = row.engine_version
    }
    if (row.confidence_score) {
      result.confidence = { score: row.confidence_score }
    }

    // ì „ê³µ ê²°ê³¼ ì •ê·œí™”: displayResults()ê°€ result.recommendations ë°°ì—´ì„ ê¸°ëŒ€í•¨
    if (row.analysis_type === 'major' && !result.recommendations) {
      const majors = result.fit_top_majors || result.fit_top3 || []
      result.recommendations = majors.map((m: any) => ({
        major_name: m.major_name || m.name || 'ì¶”ì²œ ì „ê³µ',
        name: m.name || m.major_name || 'ì¶”ì²œ ì „ê³µ',
        slug: m.slug || '',
        major_id: m.major_id || null,
        reason: m.rationale || m.reason || m.match_reason || '',
        fit_score: m.fit_score || m.final_score || 0,
        like_score: m.like_score || 0,
        can_score: m.can_score || 0,
        image_url: m.image_url || '',
      }))
    }

    return c.json({
      success: true,
      request_id: row.request_id,
      analysis_type: row.analysis_type,
      result,
    })
  } catch (error) {
    return c.json({ error: 'Failed to fetch result' }, 500)
  }
})

export { analyzerRoutes }
